{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c6af5c-86f8-4a56-8fb2-d436d083ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import train_test_split_edges, negative_sampling, to_dense_adj\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from scipy.linalg import sqrtm\n",
    "import os\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ac936b-2306-4f28-89ea-36999b75f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 加载数据\n",
    "def load_data():\n",
    "    dataset = Planetoid(root='data/Cora', name='Cora')\n",
    "    data = dataset[0]\n",
    "    data = train_test_split_edges(data)\n",
    "    \n",
    "    return data, dataset.num_node_features, dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72ecfd1-abb2-496a-9063-310f8a497978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 定义生成器网络 - 生成节点嵌入\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim), nn.LeakyReLU(0.2), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim*2), nn.LeakyReLU(0.2), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim*2, hidden_dim*4), nn.LeakyReLU(0.2), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim*4, hidden_dim*2), nn.LeakyReLU(0.2), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim*2, hidden_dim), nn.LeakyReLU(0.2), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, output_dim), \n",
    "            nn.Tanh()   # 将生成的嵌入归一化到[-1, 1]范围\n",
    "        )\n",
    "        \n",
    "    def forward(self, z): \n",
    "        return self.model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a207774e-1909-4a04-a11e-532541237a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 定义判别器网络 - 判别节点对是否有边连接\n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, dropout=0.3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim*2, hidden_dim), nn.LeakyReLU(0.2), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim*2), nn.LeakyReLU(0.2), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim*2, hidden_dim*4), nn.LeakyReLU(0.2), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim*4, hidden_dim*2), nn.LeakyReLU(0.2), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim*2, hidden_dim), nn.LeakyReLU(0.2), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1), \n",
    "            nn.Sigmoid()    #输出二分类概率\n",
    "        )\n",
    "        \n",
    "    def forward(self, x1, x2): \n",
    "        # 拼接两个节点的嵌入\n",
    "        return self.model(torch.cat([x1, x2], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "637e5d54-55e0-4f8c-963a-26e6e6889212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 计算FID指标（适配图嵌入）\n",
    "def calculate_fid(real_features, generated_features):\n",
    "    # 计算均值和协方差矩阵\n",
    "    mu1, sigma1 = np.mean(real_features, 0), np.cov(real_features, rowvar=False)\n",
    "    mu2, sigma2 = np.mean(generated_features, 0), np.cov(generated_features, rowvar=False)\n",
    "    \n",
    "    # 计算均值差的平方和\n",
    "    diff = np.sum((mu1 - mu2)** 2)\n",
    "    \n",
    "    # 计算协方差矩阵的平方根\n",
    "    covmean, _ = sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    \n",
    "    # 数值稳定性处理\n",
    "    if not np.isfinite(covmean).all():\n",
    "        covmean = sqrtm((sigma1 + 1e-6*np.eye(sigma1.shape[0])).dot(sigma2 + 1e-6*np.eye(sigma2.shape[0])))\n",
    "        \n",
    "    # 如果存在虚数部分，取实部    \n",
    "    if np.iscomplexobj(covmean): \n",
    "        covmean = covmean.real\n",
    "    \n",
    "    return diff + np.trace(sigma1 + sigma2 - 2 * covmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f587124-351d-4e70-9b31-b0202f35413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 判别器训练函数\n",
    "def train_discriminator(generator, discriminator, optimizer_D, criterion, \n",
    "                        real_features, z, pos_x1, pos_x2, neg_x1, neg_x2, device):\n",
    "    \n",
    "    optimizer_D.zero_grad()\n",
    "    fake_features = generator(z)\n",
    "    batch_size = z.size(0)\n",
    "    idx1, idx2 = torch.randperm(batch_size), torch.randperm(batch_size)\n",
    "    fake_x1, fake_x2 = fake_features[idx1], fake_features[idx2]\n",
    "    real_pred = discriminator(pos_x1, pos_x2)\n",
    "    fake_pred = discriminator(fake_x1, fake_x2)\n",
    "    real_loss = criterion(real_pred, torch.ones_like(real_pred))\n",
    "    fake_loss = criterion(fake_pred, torch.zeros_like(fake_pred))\n",
    "    d_loss = (real_loss + fake_loss) / 2\n",
    "    d_loss.backward()\n",
    "    optimizer_D.step()\n",
    "    \n",
    "    return d_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146e465e-c442-49d7-947f-c9b767f0844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 生成器训练函数\n",
    "def train_generator(generator, discriminator, optimizer_G, criterion, z, device):\n",
    "    \n",
    "    optimizer_G.zero_grad()\n",
    "    fake_features = generator(z)\n",
    "    batch_size = z.size(0)\n",
    "    idx1, idx2 = torch.randperm(batch_size), torch.randperm(batch_size)\n",
    "    fake_x1, fake_x2 = fake_features[idx1], fake_features[idx2]\n",
    "    fake_pred = discriminator(fake_x1, fake_x2)\n",
    "    g_loss = criterion(fake_pred, torch.ones_like(fake_pred))\n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "    \n",
    "    return g_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d85660fb-707a-416a-9a17-bf7ef7de38e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 绘图函数\n",
    "def plot_training_metrics(g_losses, d_losses, auc_scores, ap_scores, epochs):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(g_losses, label='Generator Loss')\n",
    "    plt.plot(d_losses, label='Discriminator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training Losses')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(0, epochs, 10), auc_scores, label='AUC')\n",
    "    plt.plot(range(0, epochs, 10), ap_scores, label='AP')\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.title('Validation Performance')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('training_metrics.png')\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5e69033-c711-4519-94bc-4a54c2dd65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 训练函数（分离绘图）\n",
    "def train_gan(data, num_features, device, epochs=200, batch_size=64, latent_dim=128):\n",
    "    \n",
    "    generator = Generator(latent_dim, 128, num_features).to(device)\n",
    "    discriminator = Discriminator(num_features, 128).to(device)\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    real_features = data.x.to(device)\n",
    "    g_losses, d_losses, auc_scores, ap_scores = [], [], [], []\n",
    "    val_pos = data.val_pos_edge_index.to(device)\n",
    "    val_neg = data.val_neg_edge_index.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        generator.train(), discriminator.train()\n",
    "        pos_edge = data.train_pos_edge_index.to(device)\n",
    "        neg_edge = data.train_neg_edge_index.to(device)\n",
    "        num_batches = pos_edge.size(1) // batch_size\n",
    "        epoch_g, epoch_d = 0, 0\n",
    "        \n",
    "        for batch in range(num_batches):\n",
    "            pos_idx = torch.randperm(pos_edge.size(1))[:batch_size]\n",
    "            neg_idx = torch.randperm(neg_edge.size(1))[:batch_size]\n",
    "            pos_pairs, neg_pairs = pos_edge[:, pos_idx], neg_edge[:, neg_idx]\n",
    "            pos_x1, pos_x2 = real_features[pos_pairs[0]], real_features[pos_pairs[1]]\n",
    "            neg_x1, neg_x2 = real_features[neg_pairs[0]], real_features[neg_pairs[1]]\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            \n",
    "            d_loss = train_discriminator(generator, discriminator, optimizer_D, criterion,\n",
    "                                        real_features, z, pos_x1, pos_x2, neg_x1, neg_x2, device)\n",
    "            g_loss = train_generator(generator, discriminator, optimizer_G, criterion, z, device)\n",
    "            epoch_d += d_loss\n",
    "            epoch_g += g_loss\n",
    "        \n",
    "        epoch_d, epoch_g = epoch_d/num_batches, epoch_g/num_batches\n",
    "        g_losses.append(epoch_g)\n",
    "        d_losses.append(epoch_d)\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            generator.eval()\n",
    "            with torch.no_grad():\n",
    "                z = torch.randn(real_features.size(0), latent_dim).to(device)\n",
    "                gen_features = generator(z)\n",
    "                pos_scores = discriminator(gen_features[val_pos[0]], gen_features[val_pos[1]]).squeeze().cpu()\n",
    "                neg_scores = discriminator(gen_features[val_neg[0]], gen_features[val_neg[1]]).squeeze().cpu()\n",
    "                y_true = np.concatenate([np.ones_like(pos_scores), np.zeros_like(neg_scores)])\n",
    "                y_scores = np.concatenate([pos_scores.numpy(), neg_scores.numpy()])\n",
    "                auc, ap = roc_auc_score(y_true, y_scores), average_precision_score(y_true, y_scores)\n",
    "                real_np = real_features.cpu().numpy()\n",
    "                gen_np = gen_features.cpu().numpy()\n",
    "                fid = calculate_fid(real_np, gen_np)\n",
    "                print(f'Epoch {epoch+1} | G:{epoch_g:.4f} D:{epoch_d:.4f} | AUC:{auc:.4f} AP:{ap:.4f} FID:{fid:.4f}')\n",
    "                auc_scores.append(auc)\n",
    "                ap_scores.append(ap)\n",
    "    \n",
    "    return generator, discriminator, g_losses, d_losses, auc_scores, ap_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38ab61a4-6c67-4112-936a-69789cadf2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 生成与评估\n",
    "def generate_and_evaluate(generator, data, num_features, device, num_samples=5000, latent_dim=128):\n",
    "    generator.eval()\n",
    "    gen_features = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_samples, 100):\n",
    "            batch = min(100, num_samples - i)\n",
    "            z = torch.randn(batch, latent_dim).to(device)\n",
    "            gen_features.append(generator(z).cpu().numpy())\n",
    "    gen_features = np.concatenate(gen_features, 0)[:num_samples]\n",
    "    np.save('generated_features.npy', gen_features)\n",
    "    \n",
    "    real_features = data.x.cpu().numpy()\n",
    "    fid = calculate_fid(real_features, gen_features)\n",
    "    \n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(2)\n",
    "    real_pca = pca.fit_transform(real_features)\n",
    "    gen_pca = pca.transform(gen_features[:len(real_features)])\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(real_pca[:, 0], real_pca[:, 1], alpha=0.5, label='Real')\n",
    "    plt.scatter(gen_pca[:, 0], gen_pca[:, 1], alpha=0.5, label='Generated')\n",
    "    plt.title('PCA Visualization')\n",
    "    plt.legend()\n",
    "    plt.savefig('feature_visualization.png')\n",
    "    \n",
    "    plt.close()\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c35eca88-feda-4a3f-8b29-c2dc38696d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_negative_edges(data, num_neg_samples=None, is_undirected=True):\n",
    "    \"\"\"\n",
    "    为Cora数据集手动构造负边\n",
    "    \n",
    "    参数:\n",
    "        data: Cora数据集的Data对象\n",
    "        num_neg_samples: 要构造的负边数量，默认与正边数量相同\n",
    "        is_undirected: 是否为无向图\n",
    "    \"\"\"\n",
    "    # 获取节点数量\n",
    "    num_nodes = data.num_nodes\n",
    "    \n",
    "    # 获取训练集正边索引\n",
    "    pos_edge_index = data.train_pos_edge_index\n",
    "    \n",
    "    # 如果未指定负边数量，默认与正边数量相同\n",
    "    if num_neg_samples is None:\n",
    "        num_neg_samples = pos_edge_index.size(1)\n",
    "    \n",
    "    # 构造负边（使用PyG的negative_sampling函数）\n",
    "    # 注意：需传入排除的边索引（即正边），避免采样到已存在的边\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=pos_edge_index,  # 基于现有边结构采样\n",
    "        num_nodes=num_nodes,        # 节点总数\n",
    "        num_neg_samples=num_neg_samples,  # 负边数量\n",
    "        method='sparse'             # 稀疏采样方法，适用于大图\n",
    "    )\n",
    "    \n",
    "    # 如果是无向图，确保负边对称性（可选）\n",
    "    if is_undirected:\n",
    "        # 将负边转换为对称形式（i->j 和 j->i 都作为负边）\n",
    "        neg_edge_index = torch.cat([neg_edge_index, neg_edge_index.flip(0)], dim=1)\n",
    "    \n",
    "    # 将构造的负边添加到data对象\n",
    "    data.train_neg_edge_index = neg_edge_index\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "172f8ad9-b23a-4e06-ba0f-8744412616d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主函数\n",
    "\n",
    "def main():\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    data, num_features, _ = load_data()\n",
    "    data = construct_negative_edges(data)\n",
    "    data = data.to(device)\n",
    "    \n",
    "    gen, dis, g_losses, d_losses, auc_scores, ap_scores = train_gan(data, num_features, device, epochs=200, batch_size=64, latent_dim=128)\n",
    "    \n",
    "    fid = generate_and_evaluate(gen, data, num_features, device)\n",
    "    print(f\"Final FID: {fid:.4f}\")\n",
    "    \n",
    "    plot_training_metrics(g_losses, d_losses, auc_scores, ap_scores, 200)\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    torch.save(gen.state_dict(), 'models/generator.pth')\n",
    "    torch.save(dis.state_dict(), 'models/discriminator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5462f5f2-0060-4a57-8fa6-505de2222260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | G:5.0283 D:0.0720 | AUC:0.4511 AP:0.4730 FID:19.4291\n",
      "Epoch 20 | G:5.8503 D:0.0622 | AUC:0.5109 AP:0.5290 FID:19.4626\n",
      "Epoch 30 | G:6.7200 D:0.0354 | AUC:0.4662 AP:0.4840 FID:20.2776\n",
      "Epoch 40 | G:6.7650 D:0.0402 | AUC:0.4835 AP:0.4873 FID:20.3234\n",
      "Epoch 50 | G:7.3365 D:0.0379 | AUC:0.5770 AP:0.5662 FID:22.7833\n",
      "Epoch 60 | G:7.5749 D:0.0358 | AUC:0.4925 AP:0.5021 FID:21.5222\n",
      "Epoch 70 | G:7.5576 D:0.0426 | AUC:0.4801 AP:0.4877 FID:22.4408\n",
      "Epoch 80 | G:6.9788 D:0.0564 | AUC:0.4963 AP:0.5064 FID:24.4092\n",
      "Epoch 90 | G:6.5951 D:0.0603 | AUC:0.4709 AP:0.4837 FID:25.6409\n",
      "Epoch 100 | G:6.5935 D:0.0701 | AUC:0.4562 AP:0.4824 FID:27.6551\n",
      "Epoch 110 | G:6.4599 D:0.0794 | AUC:0.5008 AP:0.4986 FID:28.7429\n",
      "Epoch 120 | G:6.3825 D:0.0859 | AUC:0.4815 AP:0.4948 FID:32.9534\n",
      "Epoch 130 | G:5.8165 D:0.0965 | AUC:0.5066 AP:0.5228 FID:31.9429\n",
      "Epoch 140 | G:6.3037 D:0.0904 | AUC:0.5413 AP:0.5355 FID:31.2433\n",
      "Epoch 150 | G:5.6318 D:0.0969 | AUC:0.4759 AP:0.4894 FID:31.4751\n",
      "Epoch 160 | G:5.6821 D:0.0984 | AUC:0.5096 AP:0.5023 FID:29.2023\n",
      "Epoch 170 | G:5.5258 D:0.1037 | AUC:0.5255 AP:0.5468 FID:28.0839\n",
      "Epoch 180 | G:5.6941 D:0.1018 | AUC:0.4953 AP:0.4829 FID:28.4905\n",
      "Epoch 190 | G:5.5766 D:0.0996 | AUC:0.4994 AP:0.5114 FID:28.3261\n",
      "Epoch 200 | G:5.5325 D:0.1090 | AUC:0.5075 AP:0.5079 FID:29.6192\n",
      "Final FID: 29.3973\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344748e2-36ec-4ea1-b7ec-f543fdb4a39c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
