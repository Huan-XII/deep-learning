{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d06bdca-1db0-471c-9524-87f40402c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from torchvision.models import inception_v3, Inception_V3_Weights\n",
    "import torch.nn.functional as F\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils import spectral_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc04c02-9609-409d-8726-6eb6f82c375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 数据加载和预处理\n",
    "def load_data():\n",
    "    \n",
    "    # 数据预处理：归一化到[-1, 1]区间\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    # 加载MNIST数据集\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    val_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71b59336-d86b-494a-9a7f-a06c0fef82e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 定义生成器网络\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        #定义模型各连接层结构\n",
    "        self.model = nn.Sequential(\n",
    "            \n",
    "            # 输入层：潜在空间维度\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            \n",
    "            # 隐藏层1\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            \n",
    "            # 隐藏层2\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            \n",
    "            # 输出层：生成784维(28x28)的图像\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()  # 输出范围归一化到[-1, 1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 1, 28, 28)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e023a9e-a352-4545-9a30-b59cfb34b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 定义判别器网络\n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # 输入层：784维(28x28)的图像\n",
    "            nn.Linear(784, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 隐藏层1\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 输出层：二分类(真/假)\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()  # 输出概率值\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ade869f1-cd88-4065-9eec-66b30281bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 计算FID (Fréchet Inception Distance)指标\n",
    "def calculate_fid(real_images, generated_images, inception_model, device, batch_size=64):\n",
    "    \n",
    "    # 转换为3通道图像以适应Inception模型\n",
    "    real_images = convert_to_3_channels(real_images)\n",
    "    generated_images = convert_to_3_channels(generated_images)\n",
    "    \n",
    "    # 将图像移动到与模型相同的设备\n",
    "    real_images = real_images.to(device)\n",
    "    generated_images = generated_images.to(device)\n",
    "    \n",
    "    # 提取真实图像和生成图像的特征\n",
    "    real_features = extract_features(real_images, inception_model, device, batch_size)\n",
    "    gen_features = extract_features(generated_images, inception_model, device, batch_size)\n",
    "    \n",
    "    # 计算均值和协方差\n",
    "    mu1, sigma1 = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n",
    "    mu2, sigma2 = np.mean(gen_features, axis=0), np.cov(gen_features, rowvar=False)\n",
    "    \n",
    "    # 计算FID\n",
    "    fid = calculate_frechet_distance(mu1, sigma1, mu2, sigma2)\n",
    "    return fid\n",
    "\n",
    "def convert_to_3_channels(images):\n",
    "    \"\"\"将1通道图像转换为3通道图像\"\"\"\n",
    "    # 检查图像是否已经是3通道\n",
    "    if images.shape[1] == 3:\n",
    "        return images\n",
    "    \n",
    "    # 将1通道复制为3通道\n",
    "    return images.repeat(1, 3, 1, 1)\n",
    "\n",
    "def extract_features(images, inception_model, device, batch_size):\n",
    "    # 提取图像特征的实现\n",
    "    features = []\n",
    "    inception_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(images), batch_size):\n",
    "            batch = images[i:i+batch_size]\n",
    "            \n",
    "            # 调整图像大小为Inception模型的输入尺寸\n",
    "            batch = F.interpolate(batch, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "            \n",
    "            # 将批次数据移动到与模型相同的设备\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            batch_features = inception_model(batch)\n",
    "            features.append(batch_features.cpu().numpy()) # 转回CPU以存储为numpy数组\n",
    "    return np.concatenate(features)\n",
    "\n",
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    # 计算Fréchet距离\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "    \n",
    "    diff = mu1 - mu2\n",
    "    \n",
    "    # 计算协方差矩阵的平方根\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    \n",
    "    # 检查数值问题\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    \n",
    "    fid = diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * np.trace(covmean)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd5fef3-33ee-44f9-b459-63d31642f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 训练GAN模型\n",
    "def train_gan(epochs = 100):\n",
    "    # 设置设备\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"使用设备: {device}\")\n",
    "    \n",
    "    # 加载数据\n",
    "    train_loader, val_loader = load_data()\n",
    "    \n",
    "    # 初始化模型\n",
    "    generator = Generator().to(device)\n",
    "    discriminator = Discriminator().to(device)\n",
    "    \n",
    "    # 定义损失函数和优化器\n",
    "    adversarial_loss = nn.BCELoss().to(device)\n",
    "    \n",
    "    lr = 0.0002\n",
    "    betas = (0.5, 0.95)\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=betas)\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=betas)\n",
    "    \n",
    "    # 加载Inception模型用于FID计算\n",
    "    inception_model = inception_v3(weights=Inception_V3_Weights.DEFAULT, transform_input=False)\n",
    "    inception_model.fc = nn.Identity()  # 移除最后的全连接层\n",
    "    inception_model = inception_model.to(device)\n",
    "    inception_model.eval()\n",
    "    \n",
    "    # 训练参数\n",
    "    latent_dim = 100\n",
    "    sample_interval = 10\n",
    "    \n",
    "    # 训练损失记录\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    fid_scores = []\n",
    "    \n",
    "    # 训练循环\n",
    "    for epoch in range(epochs):\n",
    "        for i, (real_imgs, _) in enumerate(train_loader):\n",
    "            real_imgs = real_imgs.to(device)\n",
    "            batch_size = real_imgs.size(0)\n",
    "            \n",
    "            # 真实样本标签为1，生成样本标签为0\n",
    "            valid = torch.ones(batch_size, 1).to(device)\n",
    "            fake = torch.zeros(batch_size, 1).to(device)\n",
    "            \n",
    "            # ---------------------\n",
    "            #  训练生成器\n",
    "            # ---------------------\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # 生成随机噪声\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            \n",
    "            # 生成假图像\n",
    "            gen_imgs = generator(z)\n",
    "            \n",
    "            # 生成器损失：希望判别器将生成的图像判断为真实的\n",
    "            g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "            \n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            # ---------------------\n",
    "            #  训练判别器\n",
    "            # ---------------------\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            # 判别器损失：正确分类真实图像和生成图像\n",
    "            real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "            fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            \n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # 记录损失\n",
    "            g_losses.append(g_loss.item())\n",
    "            d_losses.append(d_loss.item())\n",
    "            \n",
    "            # 打印训练进度\n",
    "            if i % 100 == 0:\n",
    "                print(\n",
    "                    f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(train_loader)}] \"\n",
    "                    f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\"\n",
    "                )\n",
    "        \n",
    "        # 每个epoch结束后计算FID\n",
    "        if (epoch + 1) % sample_interval == 0:\n",
    "            # 生成5k个样本\n",
    "            generated_samples = generate_samples(generator, 5000, latent_dim, device)\n",
    "            \n",
    "            # 获取验证集样本\n",
    "            val_samples = get_val_samples(val_loader, 5000, device)\n",
    "            \n",
    "            # 计算FID\n",
    "            fid = calculate_fid(val_samples, generated_samples, inception_model, device)\n",
    "            fid_scores.append(fid)\n",
    "            print(f\"[Epoch {epoch}/{epochs}] [FID score: {fid:.4f}]\")\n",
    "            \n",
    "            # 保存生成的样本\n",
    "            save_samples(generated_samples, f\"./结果汇总/samples_epoch_{epoch}.png\")\n",
    "    \n",
    "    # 训练结束后生成5k个样本并保存\n",
    "    final_samples = generate_samples(generator, 5000, latent_dim, device)\n",
    "    save_samples(final_samples, \"./结果汇总/final_generated_samples.png\")\n",
    "    \n",
    "    # 计算最终FID分数\n",
    "    val_samples = get_val_samples(val_loader, 5000, device)\n",
    "    final_fid = calculate_fid(val_samples, final_samples, inception_model, device)\n",
    "    print(f\"Final FID score: {final_fid:.4f}\")\n",
    "    \n",
    "    # 绘制损失曲线\n",
    "    plot_losses(g_losses, d_losses, fid_scores, final_fid)\n",
    "    \n",
    "    # 保存模型\n",
    "    torch.save(generator.state_dict(), \"./结果汇总/generator_model.pth\")\n",
    "    torch.save(discriminator.state_dict(), \"./结果汇总/discriminator_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0303f90d-651a-47f0-a7d2-812b7cf7d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辅助函数\n",
    "def generate_samples(generator, num_samples, latent_dim, device):\n",
    "    \"\"\"生成指定数量的样本\"\"\"\n",
    "    z = torch.randn(num_samples, latent_dim).to(device)\n",
    "    with torch.no_grad():\n",
    "        samples = generator(z)\n",
    "    return samples.cpu() # 转回CPU以便保存和处理\n",
    "\n",
    "def get_val_samples(val_loader, num_samples, device):\n",
    "    \"\"\"从验证集中获取指定数量的样本\"\"\"\n",
    "    samples = []\n",
    "    for batch, _ in val_loader:\n",
    "        samples.append(batch)\n",
    "        if len(samples) * batch.size(0) >= num_samples:\n",
    "            break\n",
    "    samples = torch.cat(samples)[:num_samples].to(device)\n",
    "    return samples\n",
    "\n",
    "def save_samples(samples, filename):\n",
    "    \"\"\"保存生成的样本图像\"\"\"\n",
    "    # 实现样本图像保存功能\n",
    "    from torchvision.utils import save_image\n",
    "    # 确保像素值在[0,1]范围内\n",
    "    samples = (samples + 1) / 2\n",
    "    save_image(samples, filename, nrow=25, normalize=True)\n",
    "\n",
    "def plot_losses(g_losses, d_losses, fid_scores, final_fid):\n",
    "    \"\"\"绘制损失曲线和FID分数\"\"\"\n",
    "    plt.figure(figsize=(9, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(g_losses, label='Generator Loss')\n",
    "    plt.plot(d_losses, label='Discriminator Loss')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(0, len(fid_scores) * 10, 10), fid_scores)\n",
    "    plt.axhline(y=final_fid, color='r', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    plt.axhline(y=min(fid_scores), color='r', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    \n",
    "    # 标注水平虚线的值\n",
    "    plt.text(x=0, y=final_fid, s=f'{round(final_fid,2)}', fontsize=8, color='red')\n",
    "    plt.text(x=0, y=min(fid_scores), s=f'{round(min(fid_scores),2)}', fontsize=8, color='red')\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('FID Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./结果汇总/training_curves.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d829d54f-8034-46f7-a5b3-d4792779ba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "[Epoch 0/500] [Batch 0/469] [D loss: 0.6924] [G loss: 0.7131]\n",
      "[Epoch 0/500] [Batch 100/469] [D loss: 0.0857] [G loss: 2.1900]\n",
      "[Epoch 0/500] [Batch 200/469] [D loss: 0.1326] [G loss: 2.5792]\n",
      "[Epoch 0/500] [Batch 300/469] [D loss: 0.2026] [G loss: 1.3799]\n",
      "[Epoch 0/500] [Batch 400/469] [D loss: 0.5106] [G loss: 1.7811]\n",
      "[Epoch 1/500] [Batch 0/469] [D loss: 0.7467] [G loss: 0.3512]\n",
      "[Epoch 1/500] [Batch 100/469] [D loss: 0.9000] [G loss: 0.2552]\n",
      "[Epoch 1/500] [Batch 200/469] [D loss: 0.8391] [G loss: 0.3193]\n",
      "[Epoch 1/500] [Batch 300/469] [D loss: 0.8416] [G loss: 0.2853]\n",
      "[Epoch 1/500] [Batch 400/469] [D loss: 0.8382] [G loss: 0.3125]\n",
      "[Epoch 2/500] [Batch 0/469] [D loss: 0.8025] [G loss: 0.3364]\n",
      "[Epoch 2/500] [Batch 100/469] [D loss: 0.7783] [G loss: 0.3759]\n",
      "[Epoch 2/500] [Batch 200/469] [D loss: 0.6800] [G loss: 0.5777]\n",
      "[Epoch 2/500] [Batch 300/469] [D loss: 0.7054] [G loss: 0.8172]\n",
      "[Epoch 2/500] [Batch 400/469] [D loss: 0.6854] [G loss: 0.6591]\n",
      "[Epoch 3/500] [Batch 0/469] [D loss: 0.6148] [G loss: 0.8264]\n",
      "[Epoch 3/500] [Batch 100/469] [D loss: 0.7469] [G loss: 0.3759]\n",
      "[Epoch 3/500] [Batch 200/469] [D loss: 0.7722] [G loss: 0.3325]\n",
      "[Epoch 3/500] [Batch 300/469] [D loss: 0.6936] [G loss: 0.5881]\n",
      "[Epoch 3/500] [Batch 400/469] [D loss: 0.6163] [G loss: 0.8162]\n",
      "[Epoch 4/500] [Batch 0/469] [D loss: 0.6695] [G loss: 0.7892]\n",
      "[Epoch 4/500] [Batch 100/469] [D loss: 0.6816] [G loss: 0.8567]\n",
      "[Epoch 4/500] [Batch 200/469] [D loss: 0.6688] [G loss: 0.6783]\n",
      "[Epoch 4/500] [Batch 300/469] [D loss: 0.6003] [G loss: 0.8876]\n",
      "[Epoch 4/500] [Batch 400/469] [D loss: 0.6162] [G loss: 1.1935]\n",
      "[Epoch 5/500] [Batch 0/469] [D loss: 0.5890] [G loss: 0.8852]\n",
      "[Epoch 5/500] [Batch 100/469] [D loss: 0.6107] [G loss: 0.9810]\n",
      "[Epoch 5/500] [Batch 200/469] [D loss: 0.6161] [G loss: 0.8138]\n",
      "[Epoch 5/500] [Batch 300/469] [D loss: 0.6051] [G loss: 0.8780]\n",
      "[Epoch 5/500] [Batch 400/469] [D loss: 0.8014] [G loss: 0.2965]\n",
      "[Epoch 6/500] [Batch 0/469] [D loss: 0.5797] [G loss: 0.7209]\n",
      "[Epoch 6/500] [Batch 100/469] [D loss: 0.6316] [G loss: 0.5743]\n",
      "[Epoch 6/500] [Batch 200/469] [D loss: 0.6211] [G loss: 0.7843]\n",
      "[Epoch 6/500] [Batch 300/469] [D loss: 0.7039] [G loss: 1.3228]\n",
      "[Epoch 6/500] [Batch 400/469] [D loss: 0.5837] [G loss: 0.7038]\n",
      "[Epoch 7/500] [Batch 0/469] [D loss: 0.5660] [G loss: 0.9905]\n",
      "[Epoch 7/500] [Batch 100/469] [D loss: 0.5933] [G loss: 0.5338]\n",
      "[Epoch 7/500] [Batch 200/469] [D loss: 0.5972] [G loss: 1.0276]\n",
      "[Epoch 7/500] [Batch 300/469] [D loss: 0.5336] [G loss: 1.0010]\n",
      "[Epoch 7/500] [Batch 400/469] [D loss: 0.6447] [G loss: 0.7178]\n",
      "[Epoch 8/500] [Batch 0/469] [D loss: 0.5900] [G loss: 0.8632]\n",
      "[Epoch 8/500] [Batch 100/469] [D loss: 0.6244] [G loss: 0.5799]\n",
      "[Epoch 8/500] [Batch 200/469] [D loss: 0.6089] [G loss: 0.6137]\n",
      "[Epoch 8/500] [Batch 300/469] [D loss: 0.6019] [G loss: 0.6421]\n",
      "[Epoch 8/500] [Batch 400/469] [D loss: 0.5939] [G loss: 0.8745]\n",
      "[Epoch 9/500] [Batch 0/469] [D loss: 0.5755] [G loss: 1.0359]\n",
      "[Epoch 9/500] [Batch 100/469] [D loss: 0.5824] [G loss: 0.9115]\n",
      "[Epoch 9/500] [Batch 200/469] [D loss: 0.6289] [G loss: 0.5738]\n",
      "[Epoch 9/500] [Batch 300/469] [D loss: 0.6077] [G loss: 0.7175]\n",
      "[Epoch 9/500] [Batch 400/469] [D loss: 0.5843] [G loss: 0.8249]\n",
      "[Epoch 9/500] [FID score: 185.4730]\n",
      "[Epoch 10/500] [Batch 0/469] [D loss: 0.6360] [G loss: 1.0273]\n",
      "[Epoch 10/500] [Batch 100/469] [D loss: 0.6125] [G loss: 0.9570]\n",
      "[Epoch 10/500] [Batch 200/469] [D loss: 0.6712] [G loss: 1.3546]\n",
      "[Epoch 10/500] [Batch 300/469] [D loss: 0.6459] [G loss: 1.1760]\n",
      "[Epoch 10/500] [Batch 400/469] [D loss: 0.6442] [G loss: 1.2734]\n",
      "[Epoch 11/500] [Batch 0/469] [D loss: 0.6592] [G loss: 1.2516]\n",
      "[Epoch 11/500] [Batch 100/469] [D loss: 0.5846] [G loss: 1.0209]\n",
      "[Epoch 11/500] [Batch 200/469] [D loss: 0.9335] [G loss: 2.2460]\n",
      "[Epoch 11/500] [Batch 300/469] [D loss: 0.5975] [G loss: 0.9658]\n",
      "[Epoch 11/500] [Batch 400/469] [D loss: 0.6099] [G loss: 0.6650]\n",
      "[Epoch 12/500] [Batch 0/469] [D loss: 0.6101] [G loss: 0.7469]\n",
      "[Epoch 12/500] [Batch 100/469] [D loss: 0.6790] [G loss: 1.2143]\n",
      "[Epoch 12/500] [Batch 200/469] [D loss: 0.5881] [G loss: 0.8208]\n",
      "[Epoch 12/500] [Batch 300/469] [D loss: 0.5619] [G loss: 0.9512]\n",
      "[Epoch 12/500] [Batch 400/469] [D loss: 0.7497] [G loss: 0.3730]\n",
      "[Epoch 13/500] [Batch 0/469] [D loss: 0.7099] [G loss: 0.4336]\n",
      "[Epoch 13/500] [Batch 100/469] [D loss: 0.6153] [G loss: 1.0598]\n",
      "[Epoch 13/500] [Batch 200/469] [D loss: 0.7791] [G loss: 0.3320]\n",
      "[Epoch 13/500] [Batch 300/469] [D loss: 0.6419] [G loss: 0.6831]\n",
      "[Epoch 13/500] [Batch 400/469] [D loss: 0.6446] [G loss: 0.6096]\n",
      "[Epoch 14/500] [Batch 0/469] [D loss: 0.6371] [G loss: 0.5700]\n",
      "[Epoch 14/500] [Batch 100/469] [D loss: 0.5949] [G loss: 1.0739]\n",
      "[Epoch 14/500] [Batch 200/469] [D loss: 0.5701] [G loss: 0.7936]\n",
      "[Epoch 14/500] [Batch 300/469] [D loss: 0.6014] [G loss: 0.7572]\n",
      "[Epoch 14/500] [Batch 400/469] [D loss: 0.5966] [G loss: 1.1273]\n",
      "[Epoch 15/500] [Batch 0/469] [D loss: 0.6219] [G loss: 0.7132]\n",
      "[Epoch 15/500] [Batch 100/469] [D loss: 0.6092] [G loss: 0.8219]\n",
      "[Epoch 15/500] [Batch 200/469] [D loss: 0.6128] [G loss: 0.7538]\n",
      "[Epoch 15/500] [Batch 300/469] [D loss: 0.6067] [G loss: 1.1470]\n",
      "[Epoch 15/500] [Batch 400/469] [D loss: 0.6677] [G loss: 1.1717]\n",
      "[Epoch 16/500] [Batch 0/469] [D loss: 0.5988] [G loss: 0.9647]\n",
      "[Epoch 16/500] [Batch 100/469] [D loss: 0.5191] [G loss: 0.8654]\n",
      "[Epoch 16/500] [Batch 200/469] [D loss: 0.6066] [G loss: 0.9318]\n",
      "[Epoch 16/500] [Batch 300/469] [D loss: 0.5948] [G loss: 0.5907]\n",
      "[Epoch 16/500] [Batch 400/469] [D loss: 0.6991] [G loss: 0.4402]\n",
      "[Epoch 17/500] [Batch 0/469] [D loss: 0.6346] [G loss: 1.1725]\n",
      "[Epoch 17/500] [Batch 100/469] [D loss: 0.5972] [G loss: 0.6584]\n",
      "[Epoch 17/500] [Batch 200/469] [D loss: 0.6049] [G loss: 0.7354]\n",
      "[Epoch 17/500] [Batch 300/469] [D loss: 0.6494] [G loss: 0.5783]\n",
      "[Epoch 17/500] [Batch 400/469] [D loss: 0.6567] [G loss: 1.4501]\n",
      "[Epoch 18/500] [Batch 0/469] [D loss: 0.5799] [G loss: 0.7370]\n",
      "[Epoch 18/500] [Batch 100/469] [D loss: 0.5811] [G loss: 1.0826]\n",
      "[Epoch 18/500] [Batch 200/469] [D loss: 0.6095] [G loss: 0.8951]\n",
      "[Epoch 18/500] [Batch 300/469] [D loss: 0.6271] [G loss: 1.1548]\n",
      "[Epoch 18/500] [Batch 400/469] [D loss: 0.5739] [G loss: 0.8571]\n",
      "[Epoch 19/500] [Batch 0/469] [D loss: 0.5830] [G loss: 0.9347]\n",
      "[Epoch 19/500] [Batch 100/469] [D loss: 0.5454] [G loss: 0.9876]\n",
      "[Epoch 19/500] [Batch 200/469] [D loss: 0.6444] [G loss: 1.2752]\n",
      "[Epoch 19/500] [Batch 300/469] [D loss: 0.6032] [G loss: 0.8354]\n",
      "[Epoch 19/500] [Batch 400/469] [D loss: 0.6129] [G loss: 0.7757]\n",
      "[Epoch 19/500] [FID score: 148.5970]\n",
      "[Epoch 20/500] [Batch 0/469] [D loss: 0.6032] [G loss: 1.0079]\n",
      "[Epoch 20/500] [Batch 100/469] [D loss: 0.6009] [G loss: 1.4016]\n",
      "[Epoch 20/500] [Batch 200/469] [D loss: 0.7654] [G loss: 1.6524]\n",
      "[Epoch 20/500] [Batch 300/469] [D loss: 0.6204] [G loss: 0.9831]\n",
      "[Epoch 20/500] [Batch 400/469] [D loss: 0.5551] [G loss: 0.8439]\n",
      "[Epoch 21/500] [Batch 0/469] [D loss: 0.5849] [G loss: 0.8758]\n",
      "[Epoch 21/500] [Batch 100/469] [D loss: 0.5965] [G loss: 0.9191]\n",
      "[Epoch 21/500] [Batch 200/469] [D loss: 0.5512] [G loss: 1.0901]\n",
      "[Epoch 21/500] [Batch 300/469] [D loss: 0.6003] [G loss: 0.7109]\n",
      "[Epoch 21/500] [Batch 400/469] [D loss: 0.5523] [G loss: 0.9235]\n",
      "[Epoch 22/500] [Batch 0/469] [D loss: 0.5739] [G loss: 0.9281]\n",
      "[Epoch 22/500] [Batch 100/469] [D loss: 0.5903] [G loss: 1.0134]\n",
      "[Epoch 22/500] [Batch 200/469] [D loss: 0.5663] [G loss: 0.7169]\n",
      "[Epoch 22/500] [Batch 300/469] [D loss: 0.6815] [G loss: 0.4661]\n",
      "[Epoch 22/500] [Batch 400/469] [D loss: 0.6011] [G loss: 0.6636]\n",
      "[Epoch 23/500] [Batch 0/469] [D loss: 0.6128] [G loss: 1.2594]\n",
      "[Epoch 23/500] [Batch 100/469] [D loss: 0.5969] [G loss: 0.8177]\n",
      "[Epoch 23/500] [Batch 200/469] [D loss: 0.5523] [G loss: 0.9831]\n",
      "[Epoch 23/500] [Batch 300/469] [D loss: 0.6030] [G loss: 0.8869]\n",
      "[Epoch 23/500] [Batch 400/469] [D loss: 0.6442] [G loss: 0.5334]\n",
      "[Epoch 24/500] [Batch 0/469] [D loss: 0.6179] [G loss: 1.1437]\n",
      "[Epoch 24/500] [Batch 100/469] [D loss: 0.6004] [G loss: 0.8267]\n",
      "[Epoch 24/500] [Batch 200/469] [D loss: 0.5679] [G loss: 1.0092]\n",
      "[Epoch 24/500] [Batch 300/469] [D loss: 0.6772] [G loss: 0.4677]\n",
      "[Epoch 24/500] [Batch 400/469] [D loss: 0.6178] [G loss: 0.7658]\n",
      "[Epoch 25/500] [Batch 0/469] [D loss: 0.5895] [G loss: 0.9972]\n",
      "[Epoch 25/500] [Batch 100/469] [D loss: 0.5848] [G loss: 0.6771]\n",
      "[Epoch 25/500] [Batch 200/469] [D loss: 0.6028] [G loss: 1.0134]\n",
      "[Epoch 25/500] [Batch 300/469] [D loss: 0.5920] [G loss: 1.1393]\n",
      "[Epoch 25/500] [Batch 400/469] [D loss: 0.6100] [G loss: 1.2420]\n",
      "[Epoch 26/500] [Batch 0/469] [D loss: 0.6052] [G loss: 1.1606]\n",
      "[Epoch 26/500] [Batch 100/469] [D loss: 0.6097] [G loss: 0.6389]\n",
      "[Epoch 26/500] [Batch 200/469] [D loss: 0.5559] [G loss: 0.7136]\n",
      "[Epoch 26/500] [Batch 300/469] [D loss: 0.5695] [G loss: 1.0345]\n",
      "[Epoch 26/500] [Batch 400/469] [D loss: 0.6066] [G loss: 1.3117]\n",
      "[Epoch 27/500] [Batch 0/469] [D loss: 0.6188] [G loss: 1.4499]\n",
      "[Epoch 27/500] [Batch 100/469] [D loss: 0.6083] [G loss: 1.0309]\n",
      "[Epoch 27/500] [Batch 200/469] [D loss: 0.5868] [G loss: 1.2110]\n",
      "[Epoch 27/500] [Batch 300/469] [D loss: 0.5948] [G loss: 1.0444]\n",
      "[Epoch 27/500] [Batch 400/469] [D loss: 0.5883] [G loss: 1.2733]\n",
      "[Epoch 28/500] [Batch 0/469] [D loss: 0.5629] [G loss: 0.8084]\n",
      "[Epoch 28/500] [Batch 100/469] [D loss: 0.5774] [G loss: 1.0104]\n",
      "[Epoch 28/500] [Batch 200/469] [D loss: 0.6017] [G loss: 1.2597]\n",
      "[Epoch 28/500] [Batch 300/469] [D loss: 0.7066] [G loss: 1.3994]\n",
      "[Epoch 28/500] [Batch 400/469] [D loss: 0.6209] [G loss: 1.2115]\n",
      "[Epoch 29/500] [Batch 0/469] [D loss: 0.5890] [G loss: 0.8076]\n",
      "[Epoch 29/500] [Batch 100/469] [D loss: 0.5946] [G loss: 0.8728]\n",
      "[Epoch 29/500] [Batch 200/469] [D loss: 0.6807] [G loss: 0.5691]\n",
      "[Epoch 29/500] [Batch 300/469] [D loss: 0.5807] [G loss: 0.8410]\n",
      "[Epoch 29/500] [Batch 400/469] [D loss: 0.5639] [G loss: 0.7464]\n",
      "[Epoch 29/500] [FID score: 114.3465]\n",
      "[Epoch 30/500] [Batch 0/469] [D loss: 0.5591] [G loss: 0.7661]\n",
      "[Epoch 30/500] [Batch 100/469] [D loss: 0.5997] [G loss: 0.7146]\n",
      "[Epoch 30/500] [Batch 200/469] [D loss: 0.5860] [G loss: 1.2564]\n",
      "[Epoch 30/500] [Batch 300/469] [D loss: 0.5703] [G loss: 0.9104]\n",
      "[Epoch 30/500] [Batch 400/469] [D loss: 0.5812] [G loss: 1.3291]\n",
      "[Epoch 31/500] [Batch 0/469] [D loss: 0.5801] [G loss: 1.0887]\n",
      "[Epoch 31/500] [Batch 100/469] [D loss: 0.5688] [G loss: 1.0340]\n",
      "[Epoch 31/500] [Batch 200/469] [D loss: 0.6027] [G loss: 1.0791]\n",
      "[Epoch 31/500] [Batch 300/469] [D loss: 0.5724] [G loss: 1.3849]\n",
      "[Epoch 31/500] [Batch 400/469] [D loss: 0.6744] [G loss: 0.4965]\n",
      "[Epoch 32/500] [Batch 0/469] [D loss: 0.6060] [G loss: 0.7669]\n",
      "[Epoch 32/500] [Batch 100/469] [D loss: 0.6390] [G loss: 0.6069]\n",
      "[Epoch 32/500] [Batch 200/469] [D loss: 0.5395] [G loss: 1.2581]\n",
      "[Epoch 32/500] [Batch 300/469] [D loss: 0.6010] [G loss: 0.9996]\n",
      "[Epoch 32/500] [Batch 400/469] [D loss: 0.6376] [G loss: 0.5898]\n",
      "[Epoch 33/500] [Batch 0/469] [D loss: 0.6601] [G loss: 0.5901]\n",
      "[Epoch 33/500] [Batch 100/469] [D loss: 0.5823] [G loss: 0.7297]\n",
      "[Epoch 33/500] [Batch 200/469] [D loss: 0.6112] [G loss: 0.9834]\n",
      "[Epoch 33/500] [Batch 300/469] [D loss: 0.5743] [G loss: 0.9587]\n",
      "[Epoch 33/500] [Batch 400/469] [D loss: 0.5704] [G loss: 1.1875]\n",
      "[Epoch 34/500] [Batch 0/469] [D loss: 0.5706] [G loss: 0.9940]\n",
      "[Epoch 34/500] [Batch 100/469] [D loss: 0.5650] [G loss: 0.8255]\n",
      "[Epoch 34/500] [Batch 200/469] [D loss: 0.6922] [G loss: 1.4467]\n",
      "[Epoch 34/500] [Batch 300/469] [D loss: 0.6045] [G loss: 0.8665]\n",
      "[Epoch 34/500] [Batch 400/469] [D loss: 0.5956] [G loss: 1.4346]\n",
      "[Epoch 35/500] [Batch 0/469] [D loss: 0.5817] [G loss: 0.6979]\n",
      "[Epoch 35/500] [Batch 100/469] [D loss: 0.5719] [G loss: 1.0707]\n",
      "[Epoch 35/500] [Batch 200/469] [D loss: 0.6531] [G loss: 1.2662]\n",
      "[Epoch 35/500] [Batch 300/469] [D loss: 0.5729] [G loss: 0.7666]\n",
      "[Epoch 35/500] [Batch 400/469] [D loss: 0.5448] [G loss: 1.0702]\n",
      "[Epoch 36/500] [Batch 0/469] [D loss: 0.5998] [G loss: 0.6899]\n",
      "[Epoch 36/500] [Batch 100/469] [D loss: 0.5982] [G loss: 0.8999]\n",
      "[Epoch 36/500] [Batch 200/469] [D loss: 0.5723] [G loss: 0.9064]\n",
      "[Epoch 36/500] [Batch 300/469] [D loss: 0.6204] [G loss: 1.4499]\n",
      "[Epoch 36/500] [Batch 400/469] [D loss: 0.5914] [G loss: 0.7005]\n",
      "[Epoch 37/500] [Batch 0/469] [D loss: 0.7078] [G loss: 0.4950]\n",
      "[Epoch 37/500] [Batch 100/469] [D loss: 0.5630] [G loss: 1.1473]\n",
      "[Epoch 37/500] [Batch 200/469] [D loss: 0.5904] [G loss: 1.0892]\n",
      "[Epoch 37/500] [Batch 300/469] [D loss: 0.5576] [G loss: 0.9881]\n",
      "[Epoch 37/500] [Batch 400/469] [D loss: 0.5437] [G loss: 0.9302]\n",
      "[Epoch 38/500] [Batch 0/469] [D loss: 0.6283] [G loss: 1.3476]\n",
      "[Epoch 38/500] [Batch 100/469] [D loss: 0.5562] [G loss: 0.7833]\n",
      "[Epoch 38/500] [Batch 200/469] [D loss: 0.6108] [G loss: 1.2529]\n",
      "[Epoch 38/500] [Batch 300/469] [D loss: 0.6040] [G loss: 1.0543]\n",
      "[Epoch 38/500] [Batch 400/469] [D loss: 0.5965] [G loss: 1.1171]\n",
      "[Epoch 39/500] [Batch 0/469] [D loss: 0.5050] [G loss: 1.0113]\n",
      "[Epoch 39/500] [Batch 100/469] [D loss: 0.5885] [G loss: 1.0687]\n",
      "[Epoch 39/500] [Batch 200/469] [D loss: 0.5619] [G loss: 0.9970]\n",
      "[Epoch 39/500] [Batch 300/469] [D loss: 0.6064] [G loss: 1.2097]\n",
      "[Epoch 39/500] [Batch 400/469] [D loss: 0.5786] [G loss: 1.2646]\n",
      "[Epoch 39/500] [FID score: 100.5975]\n",
      "[Epoch 40/500] [Batch 0/469] [D loss: 0.5934] [G loss: 0.9269]\n",
      "[Epoch 40/500] [Batch 100/469] [D loss: 0.5695] [G loss: 1.1355]\n",
      "[Epoch 40/500] [Batch 200/469] [D loss: 0.6210] [G loss: 1.2028]\n",
      "[Epoch 40/500] [Batch 300/469] [D loss: 0.5346] [G loss: 1.1465]\n",
      "[Epoch 40/500] [Batch 400/469] [D loss: 0.5567] [G loss: 0.9074]\n",
      "[Epoch 41/500] [Batch 0/469] [D loss: 0.5722] [G loss: 0.8355]\n",
      "[Epoch 41/500] [Batch 100/469] [D loss: 0.6027] [G loss: 0.7770]\n",
      "[Epoch 41/500] [Batch 200/469] [D loss: 0.5450] [G loss: 1.1602]\n",
      "[Epoch 41/500] [Batch 300/469] [D loss: 0.6013] [G loss: 0.7167]\n",
      "[Epoch 41/500] [Batch 400/469] [D loss: 0.6291] [G loss: 0.5628]\n",
      "[Epoch 42/500] [Batch 0/469] [D loss: 0.5270] [G loss: 1.2031]\n",
      "[Epoch 42/500] [Batch 100/469] [D loss: 0.6118] [G loss: 0.7171]\n",
      "[Epoch 42/500] [Batch 200/469] [D loss: 0.6584] [G loss: 0.5444]\n",
      "[Epoch 42/500] [Batch 300/469] [D loss: 0.6154] [G loss: 0.7663]\n",
      "[Epoch 42/500] [Batch 400/469] [D loss: 0.5654] [G loss: 1.0481]\n",
      "[Epoch 43/500] [Batch 0/469] [D loss: 0.6262] [G loss: 0.7196]\n",
      "[Epoch 43/500] [Batch 100/469] [D loss: 0.5778] [G loss: 0.8283]\n",
      "[Epoch 43/500] [Batch 200/469] [D loss: 0.6417] [G loss: 0.6330]\n",
      "[Epoch 43/500] [Batch 300/469] [D loss: 0.5809] [G loss: 1.1954]\n",
      "[Epoch 43/500] [Batch 400/469] [D loss: 0.6137] [G loss: 1.4926]\n",
      "[Epoch 44/500] [Batch 0/469] [D loss: 0.5875] [G loss: 1.3526]\n",
      "[Epoch 44/500] [Batch 100/469] [D loss: 0.5499] [G loss: 1.0339]\n",
      "[Epoch 44/500] [Batch 200/469] [D loss: 0.6818] [G loss: 0.5388]\n",
      "[Epoch 44/500] [Batch 300/469] [D loss: 0.7857] [G loss: 0.3533]\n",
      "[Epoch 44/500] [Batch 400/469] [D loss: 0.5107] [G loss: 1.0226]\n",
      "[Epoch 45/500] [Batch 0/469] [D loss: 0.5762] [G loss: 0.9125]\n",
      "[Epoch 45/500] [Batch 100/469] [D loss: 0.6434] [G loss: 0.5937]\n",
      "[Epoch 45/500] [Batch 200/469] [D loss: 0.6169] [G loss: 1.1185]\n",
      "[Epoch 45/500] [Batch 300/469] [D loss: 0.5746] [G loss: 0.8230]\n",
      "[Epoch 45/500] [Batch 400/469] [D loss: 0.6142] [G loss: 0.6310]\n",
      "[Epoch 46/500] [Batch 0/469] [D loss: 0.5908] [G loss: 0.7914]\n",
      "[Epoch 46/500] [Batch 100/469] [D loss: 0.6512] [G loss: 1.4769]\n",
      "[Epoch 46/500] [Batch 200/469] [D loss: 0.6041] [G loss: 0.8074]\n",
      "[Epoch 46/500] [Batch 300/469] [D loss: 0.5716] [G loss: 0.7984]\n",
      "[Epoch 46/500] [Batch 400/469] [D loss: 0.5643] [G loss: 1.0518]\n",
      "[Epoch 47/500] [Batch 0/469] [D loss: 0.5456] [G loss: 0.8471]\n",
      "[Epoch 47/500] [Batch 100/469] [D loss: 0.5864] [G loss: 0.7886]\n",
      "[Epoch 47/500] [Batch 200/469] [D loss: 0.5685] [G loss: 1.0727]\n",
      "[Epoch 47/500] [Batch 300/469] [D loss: 0.5903] [G loss: 1.1130]\n",
      "[Epoch 47/500] [Batch 400/469] [D loss: 0.6173] [G loss: 1.2602]\n",
      "[Epoch 48/500] [Batch 0/469] [D loss: 0.5906] [G loss: 0.7738]\n",
      "[Epoch 48/500] [Batch 100/469] [D loss: 0.5787] [G loss: 1.0050]\n",
      "[Epoch 48/500] [Batch 200/469] [D loss: 0.6397] [G loss: 0.5927]\n",
      "[Epoch 48/500] [Batch 300/469] [D loss: 0.5930] [G loss: 0.9909]\n",
      "[Epoch 48/500] [Batch 400/469] [D loss: 0.5750] [G loss: 0.7314]\n",
      "[Epoch 49/500] [Batch 0/469] [D loss: 0.5710] [G loss: 0.8022]\n",
      "[Epoch 49/500] [Batch 100/469] [D loss: 0.5864] [G loss: 0.7953]\n",
      "[Epoch 49/500] [Batch 200/469] [D loss: 0.5582] [G loss: 0.9464]\n",
      "[Epoch 49/500] [Batch 300/469] [D loss: 0.5857] [G loss: 0.7301]\n",
      "[Epoch 49/500] [Batch 400/469] [D loss: 0.5667] [G loss: 1.0175]\n",
      "[Epoch 49/500] [FID score: 75.1919]\n",
      "[Epoch 50/500] [Batch 0/469] [D loss: 0.6514] [G loss: 1.3312]\n",
      "[Epoch 50/500] [Batch 100/469] [D loss: 0.5720] [G loss: 0.8525]\n",
      "[Epoch 50/500] [Batch 200/469] [D loss: 0.5286] [G loss: 1.2073]\n",
      "[Epoch 50/500] [Batch 300/469] [D loss: 0.5591] [G loss: 0.8918]\n",
      "[Epoch 50/500] [Batch 400/469] [D loss: 0.6296] [G loss: 0.8161]\n",
      "[Epoch 51/500] [Batch 0/469] [D loss: 0.5454] [G loss: 1.0101]\n",
      "[Epoch 51/500] [Batch 100/469] [D loss: 0.5582] [G loss: 0.9506]\n",
      "[Epoch 51/500] [Batch 200/469] [D loss: 0.5674] [G loss: 1.0736]\n",
      "[Epoch 51/500] [Batch 300/469] [D loss: 0.5827] [G loss: 0.7446]\n",
      "[Epoch 51/500] [Batch 400/469] [D loss: 0.5962] [G loss: 1.3721]\n",
      "[Epoch 52/500] [Batch 0/469] [D loss: 0.5616] [G loss: 1.1973]\n",
      "[Epoch 52/500] [Batch 100/469] [D loss: 0.6308] [G loss: 1.2841]\n",
      "[Epoch 52/500] [Batch 200/469] [D loss: 0.5882] [G loss: 0.7867]\n",
      "[Epoch 52/500] [Batch 300/469] [D loss: 0.5838] [G loss: 1.0818]\n",
      "[Epoch 52/500] [Batch 400/469] [D loss: 0.6148] [G loss: 1.2943]\n",
      "[Epoch 53/500] [Batch 0/469] [D loss: 0.5591] [G loss: 0.8992]\n",
      "[Epoch 53/500] [Batch 100/469] [D loss: 0.5875] [G loss: 1.1845]\n",
      "[Epoch 53/500] [Batch 200/469] [D loss: 0.6569] [G loss: 0.5617]\n",
      "[Epoch 53/500] [Batch 300/469] [D loss: 0.5603] [G loss: 0.8994]\n",
      "[Epoch 53/500] [Batch 400/469] [D loss: 0.5454] [G loss: 0.9983]\n",
      "[Epoch 54/500] [Batch 0/469] [D loss: 0.6047] [G loss: 0.6577]\n",
      "[Epoch 54/500] [Batch 100/469] [D loss: 0.5515] [G loss: 0.8225]\n",
      "[Epoch 54/500] [Batch 200/469] [D loss: 0.6961] [G loss: 0.4990]\n",
      "[Epoch 54/500] [Batch 300/469] [D loss: 0.5977] [G loss: 0.8483]\n",
      "[Epoch 54/500] [Batch 400/469] [D loss: 0.5295] [G loss: 0.9822]\n",
      "[Epoch 55/500] [Batch 0/469] [D loss: 0.5736] [G loss: 0.9927]\n",
      "[Epoch 55/500] [Batch 100/469] [D loss: 0.6053] [G loss: 1.5270]\n",
      "[Epoch 55/500] [Batch 200/469] [D loss: 0.5853] [G loss: 0.9469]\n",
      "[Epoch 55/500] [Batch 300/469] [D loss: 0.6222] [G loss: 0.6385]\n",
      "[Epoch 55/500] [Batch 400/469] [D loss: 0.6260] [G loss: 0.6430]\n",
      "[Epoch 56/500] [Batch 0/469] [D loss: 0.5338] [G loss: 0.9073]\n",
      "[Epoch 56/500] [Batch 100/469] [D loss: 0.6825] [G loss: 0.4988]\n",
      "[Epoch 56/500] [Batch 200/469] [D loss: 0.5962] [G loss: 0.6897]\n",
      "[Epoch 56/500] [Batch 300/469] [D loss: 0.5594] [G loss: 0.8661]\n",
      "[Epoch 56/500] [Batch 400/469] [D loss: 0.5973] [G loss: 1.3502]\n",
      "[Epoch 57/500] [Batch 0/469] [D loss: 0.6085] [G loss: 0.6192]\n",
      "[Epoch 57/500] [Batch 100/469] [D loss: 0.6105] [G loss: 0.7608]\n",
      "[Epoch 57/500] [Batch 200/469] [D loss: 0.5562] [G loss: 0.9961]\n",
      "[Epoch 57/500] [Batch 300/469] [D loss: 0.5651] [G loss: 1.0943]\n",
      "[Epoch 57/500] [Batch 400/469] [D loss: 0.5503] [G loss: 0.9929]\n",
      "[Epoch 58/500] [Batch 0/469] [D loss: 0.6646] [G loss: 1.2940]\n",
      "[Epoch 58/500] [Batch 100/469] [D loss: 0.5645] [G loss: 0.9359]\n",
      "[Epoch 58/500] [Batch 200/469] [D loss: 0.5485] [G loss: 0.8890]\n",
      "[Epoch 58/500] [Batch 300/469] [D loss: 0.6937] [G loss: 1.8350]\n",
      "[Epoch 58/500] [Batch 400/469] [D loss: 0.5930] [G loss: 1.0517]\n",
      "[Epoch 59/500] [Batch 0/469] [D loss: 0.6073] [G loss: 0.7262]\n",
      "[Epoch 59/500] [Batch 100/469] [D loss: 0.6257] [G loss: 1.2915]\n",
      "[Epoch 59/500] [Batch 200/469] [D loss: 0.6294] [G loss: 0.6031]\n",
      "[Epoch 59/500] [Batch 300/469] [D loss: 0.5649] [G loss: 1.1894]\n",
      "[Epoch 59/500] [Batch 400/469] [D loss: 0.7001] [G loss: 0.4490]\n",
      "[Epoch 59/500] [FID score: 64.8660]\n",
      "[Epoch 60/500] [Batch 0/469] [D loss: 0.5899] [G loss: 1.5347]\n",
      "[Epoch 60/500] [Batch 100/469] [D loss: 0.5734] [G loss: 1.4969]\n",
      "[Epoch 60/500] [Batch 200/469] [D loss: 0.5624] [G loss: 1.0124]\n",
      "[Epoch 60/500] [Batch 300/469] [D loss: 0.5436] [G loss: 0.8507]\n",
      "[Epoch 60/500] [Batch 400/469] [D loss: 0.5813] [G loss: 0.8524]\n",
      "[Epoch 61/500] [Batch 0/469] [D loss: 0.6271] [G loss: 1.1321]\n",
      "[Epoch 61/500] [Batch 100/469] [D loss: 0.5743] [G loss: 0.6780]\n",
      "[Epoch 61/500] [Batch 200/469] [D loss: 0.5793] [G loss: 0.8605]\n",
      "[Epoch 61/500] [Batch 300/469] [D loss: 0.5866] [G loss: 1.2284]\n",
      "[Epoch 61/500] [Batch 400/469] [D loss: 0.5795] [G loss: 0.8472]\n",
      "[Epoch 62/500] [Batch 0/469] [D loss: 0.5854] [G loss: 1.1802]\n",
      "[Epoch 62/500] [Batch 100/469] [D loss: 0.5678] [G loss: 1.1826]\n",
      "[Epoch 62/500] [Batch 200/469] [D loss: 0.5881] [G loss: 0.9603]\n",
      "[Epoch 62/500] [Batch 300/469] [D loss: 0.6358] [G loss: 0.7991]\n",
      "[Epoch 62/500] [Batch 400/469] [D loss: 0.5719] [G loss: 0.8473]\n",
      "[Epoch 63/500] [Batch 0/469] [D loss: 0.5476] [G loss: 1.3444]\n",
      "[Epoch 63/500] [Batch 100/469] [D loss: 0.5407] [G loss: 1.1361]\n",
      "[Epoch 63/500] [Batch 200/469] [D loss: 0.5874] [G loss: 1.4149]\n",
      "[Epoch 63/500] [Batch 300/469] [D loss: 0.5839] [G loss: 0.7034]\n",
      "[Epoch 63/500] [Batch 400/469] [D loss: 0.5598] [G loss: 0.9735]\n",
      "[Epoch 64/500] [Batch 0/469] [D loss: 0.5571] [G loss: 1.0201]\n",
      "[Epoch 64/500] [Batch 100/469] [D loss: 0.5634] [G loss: 1.3949]\n",
      "[Epoch 64/500] [Batch 200/469] [D loss: 0.5443] [G loss: 1.1897]\n",
      "[Epoch 64/500] [Batch 300/469] [D loss: 0.6033] [G loss: 0.8040]\n",
      "[Epoch 64/500] [Batch 400/469] [D loss: 0.6038] [G loss: 0.9138]\n",
      "[Epoch 65/500] [Batch 0/469] [D loss: 0.5848] [G loss: 1.3376]\n",
      "[Epoch 65/500] [Batch 100/469] [D loss: 0.5791] [G loss: 0.8219]\n",
      "[Epoch 65/500] [Batch 200/469] [D loss: 0.5900] [G loss: 0.7383]\n",
      "[Epoch 65/500] [Batch 300/469] [D loss: 0.5872] [G loss: 0.6736]\n",
      "[Epoch 65/500] [Batch 400/469] [D loss: 0.5818] [G loss: 1.0450]\n",
      "[Epoch 66/500] [Batch 0/469] [D loss: 0.6137] [G loss: 0.7584]\n",
      "[Epoch 66/500] [Batch 100/469] [D loss: 0.5597] [G loss: 0.9877]\n",
      "[Epoch 66/500] [Batch 200/469] [D loss: 0.5530] [G loss: 0.8041]\n",
      "[Epoch 66/500] [Batch 300/469] [D loss: 0.6355] [G loss: 1.5252]\n",
      "[Epoch 66/500] [Batch 400/469] [D loss: 0.5401] [G loss: 1.0497]\n",
      "[Epoch 67/500] [Batch 0/469] [D loss: 0.5643] [G loss: 1.0439]\n",
      "[Epoch 67/500] [Batch 100/469] [D loss: 0.5907] [G loss: 0.7157]\n",
      "[Epoch 67/500] [Batch 200/469] [D loss: 0.5563] [G loss: 1.1983]\n",
      "[Epoch 67/500] [Batch 300/469] [D loss: 0.5613] [G loss: 1.3337]\n",
      "[Epoch 67/500] [Batch 400/469] [D loss: 0.5723] [G loss: 1.0539]\n",
      "[Epoch 68/500] [Batch 0/469] [D loss: 0.5622] [G loss: 1.2160]\n",
      "[Epoch 68/500] [Batch 100/469] [D loss: 0.5914] [G loss: 1.2801]\n",
      "[Epoch 68/500] [Batch 200/469] [D loss: 0.5572] [G loss: 0.9482]\n",
      "[Epoch 68/500] [Batch 300/469] [D loss: 0.5537] [G loss: 0.8467]\n",
      "[Epoch 68/500] [Batch 400/469] [D loss: 0.5901] [G loss: 0.7542]\n",
      "[Epoch 69/500] [Batch 0/469] [D loss: 0.5750] [G loss: 1.4744]\n",
      "[Epoch 69/500] [Batch 100/469] [D loss: 0.5998] [G loss: 1.0047]\n",
      "[Epoch 69/500] [Batch 200/469] [D loss: 0.5441] [G loss: 1.0883]\n",
      "[Epoch 69/500] [Batch 300/469] [D loss: 0.5654] [G loss: 1.3251]\n",
      "[Epoch 69/500] [Batch 400/469] [D loss: 0.5902] [G loss: 0.9604]\n",
      "[Epoch 69/500] [FID score: 57.9740]\n",
      "[Epoch 70/500] [Batch 0/469] [D loss: 0.6909] [G loss: 0.4991]\n",
      "[Epoch 70/500] [Batch 100/469] [D loss: 0.5511] [G loss: 1.2450]\n",
      "[Epoch 70/500] [Batch 200/469] [D loss: 0.5821] [G loss: 0.7955]\n",
      "[Epoch 70/500] [Batch 300/469] [D loss: 0.6220] [G loss: 0.6132]\n",
      "[Epoch 70/500] [Batch 400/469] [D loss: 0.5478] [G loss: 0.9794]\n",
      "[Epoch 71/500] [Batch 0/469] [D loss: 0.5993] [G loss: 0.7044]\n",
      "[Epoch 71/500] [Batch 100/469] [D loss: 0.5905] [G loss: 1.1189]\n",
      "[Epoch 71/500] [Batch 200/469] [D loss: 0.5826] [G loss: 0.8349]\n",
      "[Epoch 71/500] [Batch 300/469] [D loss: 0.5800] [G loss: 0.8759]\n",
      "[Epoch 71/500] [Batch 400/469] [D loss: 0.6554] [G loss: 0.5974]\n",
      "[Epoch 72/500] [Batch 0/469] [D loss: 0.5461] [G loss: 1.0804]\n",
      "[Epoch 72/500] [Batch 100/469] [D loss: 0.5908] [G loss: 1.1743]\n",
      "[Epoch 72/500] [Batch 200/469] [D loss: 0.5460] [G loss: 1.1514]\n",
      "[Epoch 72/500] [Batch 300/469] [D loss: 0.5490] [G loss: 1.0703]\n",
      "[Epoch 72/500] [Batch 400/469] [D loss: 0.5815] [G loss: 0.6875]\n",
      "[Epoch 73/500] [Batch 0/469] [D loss: 0.5630] [G loss: 1.0010]\n",
      "[Epoch 73/500] [Batch 100/469] [D loss: 0.5685] [G loss: 0.8971]\n",
      "[Epoch 73/500] [Batch 200/469] [D loss: 0.6261] [G loss: 1.5269]\n",
      "[Epoch 73/500] [Batch 300/469] [D loss: 0.5398] [G loss: 1.0070]\n",
      "[Epoch 73/500] [Batch 400/469] [D loss: 0.5455] [G loss: 0.8385]\n",
      "[Epoch 74/500] [Batch 0/469] [D loss: 0.5434] [G loss: 1.0355]\n",
      "[Epoch 74/500] [Batch 100/469] [D loss: 0.5997] [G loss: 0.7170]\n",
      "[Epoch 74/500] [Batch 200/469] [D loss: 0.5974] [G loss: 0.9602]\n",
      "[Epoch 74/500] [Batch 300/469] [D loss: 0.5833] [G loss: 0.8468]\n",
      "[Epoch 74/500] [Batch 400/469] [D loss: 0.5559] [G loss: 1.0141]\n",
      "[Epoch 75/500] [Batch 0/469] [D loss: 0.5450] [G loss: 1.2088]\n",
      "[Epoch 75/500] [Batch 100/469] [D loss: 0.5486] [G loss: 0.8270]\n",
      "[Epoch 75/500] [Batch 200/469] [D loss: 0.5888] [G loss: 0.8827]\n",
      "[Epoch 75/500] [Batch 300/469] [D loss: 0.6817] [G loss: 1.8286]\n",
      "[Epoch 75/500] [Batch 400/469] [D loss: 0.5699] [G loss: 0.9161]\n",
      "[Epoch 76/500] [Batch 0/469] [D loss: 0.6274] [G loss: 1.5055]\n",
      "[Epoch 76/500] [Batch 100/469] [D loss: 0.6046] [G loss: 1.0366]\n",
      "[Epoch 76/500] [Batch 200/469] [D loss: 0.6422] [G loss: 0.5598]\n",
      "[Epoch 76/500] [Batch 300/469] [D loss: 0.6135] [G loss: 0.6891]\n",
      "[Epoch 76/500] [Batch 400/469] [D loss: 0.5616] [G loss: 0.9181]\n",
      "[Epoch 77/500] [Batch 0/469] [D loss: 0.5891] [G loss: 1.1581]\n",
      "[Epoch 77/500] [Batch 100/469] [D loss: 0.5715] [G loss: 0.8779]\n",
      "[Epoch 77/500] [Batch 200/469] [D loss: 0.5896] [G loss: 1.0657]\n",
      "[Epoch 77/500] [Batch 300/469] [D loss: 0.5606] [G loss: 1.0803]\n",
      "[Epoch 77/500] [Batch 400/469] [D loss: 0.5387] [G loss: 1.2636]\n",
      "[Epoch 78/500] [Batch 0/469] [D loss: 0.5455] [G loss: 1.0417]\n",
      "[Epoch 78/500] [Batch 100/469] [D loss: 0.5100] [G loss: 1.0894]\n",
      "[Epoch 78/500] [Batch 200/469] [D loss: 0.5600] [G loss: 0.8289]\n",
      "[Epoch 78/500] [Batch 300/469] [D loss: 0.5536] [G loss: 0.9647]\n",
      "[Epoch 78/500] [Batch 400/469] [D loss: 0.6581] [G loss: 0.5512]\n",
      "[Epoch 79/500] [Batch 0/469] [D loss: 0.5544] [G loss: 0.7875]\n",
      "[Epoch 79/500] [Batch 100/469] [D loss: 0.5655] [G loss: 0.9751]\n",
      "[Epoch 79/500] [Batch 200/469] [D loss: 0.6561] [G loss: 0.5340]\n",
      "[Epoch 79/500] [Batch 300/469] [D loss: 0.6177] [G loss: 0.6957]\n",
      "[Epoch 79/500] [Batch 400/469] [D loss: 0.5824] [G loss: 1.0524]\n",
      "[Epoch 79/500] [FID score: 54.1018]\n",
      "[Epoch 80/500] [Batch 0/469] [D loss: 0.5620] [G loss: 1.0299]\n",
      "[Epoch 80/500] [Batch 100/469] [D loss: 0.6331] [G loss: 1.4683]\n",
      "[Epoch 80/500] [Batch 200/469] [D loss: 0.6312] [G loss: 1.6303]\n",
      "[Epoch 80/500] [Batch 300/469] [D loss: 0.6066] [G loss: 1.2970]\n",
      "[Epoch 80/500] [Batch 400/469] [D loss: 0.5591] [G loss: 1.5129]\n",
      "[Epoch 81/500] [Batch 0/469] [D loss: 0.5838] [G loss: 1.3306]\n",
      "[Epoch 81/500] [Batch 100/469] [D loss: 0.5467] [G loss: 1.2172]\n",
      "[Epoch 81/500] [Batch 200/469] [D loss: 0.6264] [G loss: 1.1075]\n",
      "[Epoch 81/500] [Batch 300/469] [D loss: 0.5666] [G loss: 1.1172]\n",
      "[Epoch 81/500] [Batch 400/469] [D loss: 0.5677] [G loss: 0.9214]\n",
      "[Epoch 82/500] [Batch 0/469] [D loss: 0.6463] [G loss: 1.5947]\n",
      "[Epoch 82/500] [Batch 100/469] [D loss: 0.5312] [G loss: 0.9689]\n",
      "[Epoch 82/500] [Batch 200/469] [D loss: 0.5756] [G loss: 1.3299]\n",
      "[Epoch 82/500] [Batch 300/469] [D loss: 0.5870] [G loss: 0.7311]\n",
      "[Epoch 82/500] [Batch 400/469] [D loss: 0.5626] [G loss: 0.9468]\n",
      "[Epoch 83/500] [Batch 0/469] [D loss: 0.5927] [G loss: 0.7475]\n",
      "[Epoch 83/500] [Batch 100/469] [D loss: 0.5518] [G loss: 0.9031]\n",
      "[Epoch 83/500] [Batch 200/469] [D loss: 0.5932] [G loss: 0.7479]\n",
      "[Epoch 83/500] [Batch 300/469] [D loss: 0.5892] [G loss: 1.1140]\n",
      "[Epoch 83/500] [Batch 400/469] [D loss: 0.5416] [G loss: 0.8637]\n",
      "[Epoch 84/500] [Batch 0/469] [D loss: 0.5755] [G loss: 1.0147]\n",
      "[Epoch 84/500] [Batch 100/469] [D loss: 0.5909] [G loss: 1.2105]\n",
      "[Epoch 84/500] [Batch 200/469] [D loss: 0.5348] [G loss: 1.1629]\n",
      "[Epoch 84/500] [Batch 300/469] [D loss: 0.5774] [G loss: 0.9512]\n",
      "[Epoch 84/500] [Batch 400/469] [D loss: 0.5620] [G loss: 1.0167]\n",
      "[Epoch 85/500] [Batch 0/469] [D loss: 0.5937] [G loss: 0.6629]\n",
      "[Epoch 85/500] [Batch 100/469] [D loss: 0.5621] [G loss: 1.1396]\n",
      "[Epoch 85/500] [Batch 200/469] [D loss: 0.5213] [G loss: 1.0773]\n",
      "[Epoch 85/500] [Batch 300/469] [D loss: 0.5938] [G loss: 0.8621]\n",
      "[Epoch 85/500] [Batch 400/469] [D loss: 0.6014] [G loss: 1.1244]\n",
      "[Epoch 86/500] [Batch 0/469] [D loss: 0.5985] [G loss: 1.0390]\n",
      "[Epoch 86/500] [Batch 100/469] [D loss: 0.5181] [G loss: 1.0941]\n",
      "[Epoch 86/500] [Batch 200/469] [D loss: 0.5516] [G loss: 1.1969]\n",
      "[Epoch 86/500] [Batch 300/469] [D loss: 0.5737] [G loss: 0.8893]\n",
      "[Epoch 86/500] [Batch 400/469] [D loss: 0.5922] [G loss: 0.9967]\n",
      "[Epoch 87/500] [Batch 0/469] [D loss: 0.6263] [G loss: 0.6503]\n",
      "[Epoch 87/500] [Batch 100/469] [D loss: 0.5518] [G loss: 0.9948]\n",
      "[Epoch 87/500] [Batch 200/469] [D loss: 0.6632] [G loss: 1.3970]\n",
      "[Epoch 87/500] [Batch 300/469] [D loss: 0.6231] [G loss: 1.1324]\n",
      "[Epoch 87/500] [Batch 400/469] [D loss: 0.6109] [G loss: 0.7075]\n",
      "[Epoch 88/500] [Batch 0/469] [D loss: 0.5923] [G loss: 1.3097]\n",
      "[Epoch 88/500] [Batch 100/469] [D loss: 0.5206] [G loss: 0.9844]\n",
      "[Epoch 88/500] [Batch 200/469] [D loss: 0.6121] [G loss: 1.3155]\n",
      "[Epoch 88/500] [Batch 300/469] [D loss: 0.6021] [G loss: 0.7791]\n",
      "[Epoch 88/500] [Batch 400/469] [D loss: 0.5608] [G loss: 0.9890]\n",
      "[Epoch 89/500] [Batch 0/469] [D loss: 0.5372] [G loss: 1.3317]\n",
      "[Epoch 89/500] [Batch 100/469] [D loss: 0.6189] [G loss: 0.7055]\n",
      "[Epoch 89/500] [Batch 200/469] [D loss: 0.5689] [G loss: 1.3504]\n",
      "[Epoch 89/500] [Batch 300/469] [D loss: 0.6371] [G loss: 1.7327]\n",
      "[Epoch 89/500] [Batch 400/469] [D loss: 0.5706] [G loss: 0.9178]\n",
      "[Epoch 89/500] [FID score: 46.9163]\n",
      "[Epoch 90/500] [Batch 0/469] [D loss: 0.5923] [G loss: 0.7984]\n",
      "[Epoch 90/500] [Batch 100/469] [D loss: 0.5894] [G loss: 1.4088]\n",
      "[Epoch 90/500] [Batch 200/469] [D loss: 0.6047] [G loss: 0.7669]\n",
      "[Epoch 90/500] [Batch 300/469] [D loss: 0.5352] [G loss: 0.8389]\n",
      "[Epoch 90/500] [Batch 400/469] [D loss: 0.5817] [G loss: 1.1812]\n",
      "[Epoch 91/500] [Batch 0/469] [D loss: 0.6402] [G loss: 1.4261]\n",
      "[Epoch 91/500] [Batch 100/469] [D loss: 0.5717] [G loss: 0.9195]\n",
      "[Epoch 91/500] [Batch 200/469] [D loss: 0.5740] [G loss: 1.0453]\n",
      "[Epoch 91/500] [Batch 300/469] [D loss: 0.5776] [G loss: 0.8470]\n",
      "[Epoch 91/500] [Batch 400/469] [D loss: 0.6015] [G loss: 0.9243]\n",
      "[Epoch 92/500] [Batch 0/469] [D loss: 0.5768] [G loss: 1.1284]\n",
      "[Epoch 92/500] [Batch 100/469] [D loss: 0.5457] [G loss: 1.2864]\n",
      "[Epoch 92/500] [Batch 200/469] [D loss: 0.5941] [G loss: 0.7900]\n",
      "[Epoch 92/500] [Batch 300/469] [D loss: 0.5487] [G loss: 0.9159]\n",
      "[Epoch 92/500] [Batch 400/469] [D loss: 0.5919] [G loss: 1.2499]\n",
      "[Epoch 93/500] [Batch 0/469] [D loss: 0.5552] [G loss: 0.9254]\n",
      "[Epoch 93/500] [Batch 100/469] [D loss: 0.5581] [G loss: 0.9704]\n",
      "[Epoch 93/500] [Batch 200/469] [D loss: 0.5723] [G loss: 0.8503]\n",
      "[Epoch 93/500] [Batch 300/469] [D loss: 0.6013] [G loss: 1.2870]\n",
      "[Epoch 93/500] [Batch 400/469] [D loss: 0.6158] [G loss: 1.4457]\n",
      "[Epoch 94/500] [Batch 0/469] [D loss: 0.5636] [G loss: 1.0680]\n",
      "[Epoch 94/500] [Batch 100/469] [D loss: 0.5611] [G loss: 1.1863]\n",
      "[Epoch 94/500] [Batch 200/469] [D loss: 0.5875] [G loss: 1.3031]\n",
      "[Epoch 94/500] [Batch 300/469] [D loss: 0.6213] [G loss: 0.7226]\n",
      "[Epoch 94/500] [Batch 400/469] [D loss: 0.5853] [G loss: 1.0346]\n",
      "[Epoch 95/500] [Batch 0/469] [D loss: 0.5631] [G loss: 1.0873]\n",
      "[Epoch 95/500] [Batch 100/469] [D loss: 0.5159] [G loss: 1.1921]\n",
      "[Epoch 95/500] [Batch 200/469] [D loss: 0.5564] [G loss: 1.4277]\n",
      "[Epoch 95/500] [Batch 300/469] [D loss: 0.5926] [G loss: 1.1645]\n",
      "[Epoch 95/500] [Batch 400/469] [D loss: 0.5595] [G loss: 1.2659]\n",
      "[Epoch 96/500] [Batch 0/469] [D loss: 0.5827] [G loss: 0.7214]\n",
      "[Epoch 96/500] [Batch 100/469] [D loss: 0.6175] [G loss: 0.7844]\n",
      "[Epoch 96/500] [Batch 200/469] [D loss: 0.5817] [G loss: 0.7810]\n",
      "[Epoch 96/500] [Batch 300/469] [D loss: 0.5962] [G loss: 1.2753]\n",
      "[Epoch 96/500] [Batch 400/469] [D loss: 0.6438] [G loss: 0.5836]\n",
      "[Epoch 97/500] [Batch 0/469] [D loss: 0.5686] [G loss: 1.3473]\n",
      "[Epoch 97/500] [Batch 100/469] [D loss: 0.5528] [G loss: 0.8750]\n",
      "[Epoch 97/500] [Batch 200/469] [D loss: 0.5591] [G loss: 1.0291]\n",
      "[Epoch 97/500] [Batch 300/469] [D loss: 0.5344] [G loss: 1.2055]\n",
      "[Epoch 97/500] [Batch 400/469] [D loss: 0.6158] [G loss: 0.8315]\n",
      "[Epoch 98/500] [Batch 0/469] [D loss: 0.5756] [G loss: 1.2656]\n",
      "[Epoch 98/500] [Batch 100/469] [D loss: 0.5791] [G loss: 0.7926]\n",
      "[Epoch 98/500] [Batch 200/469] [D loss: 0.5914] [G loss: 0.7237]\n",
      "[Epoch 98/500] [Batch 300/469] [D loss: 0.5521] [G loss: 0.8223]\n",
      "[Epoch 98/500] [Batch 400/469] [D loss: 0.6366] [G loss: 0.6364]\n",
      "[Epoch 99/500] [Batch 0/469] [D loss: 0.6102] [G loss: 0.6200]\n",
      "[Epoch 99/500] [Batch 100/469] [D loss: 0.5978] [G loss: 1.0489]\n",
      "[Epoch 99/500] [Batch 200/469] [D loss: 0.6152] [G loss: 1.1832]\n",
      "[Epoch 99/500] [Batch 300/469] [D loss: 0.5427] [G loss: 1.1642]\n",
      "[Epoch 99/500] [Batch 400/469] [D loss: 0.5759] [G loss: 1.0462]\n",
      "[Epoch 99/500] [FID score: 44.5067]\n",
      "[Epoch 100/500] [Batch 0/469] [D loss: 0.5744] [G loss: 0.8090]\n",
      "[Epoch 100/500] [Batch 100/469] [D loss: 0.5169] [G loss: 1.1267]\n",
      "[Epoch 100/500] [Batch 200/469] [D loss: 0.5637] [G loss: 0.9083]\n",
      "[Epoch 100/500] [Batch 300/469] [D loss: 0.5809] [G loss: 1.0006]\n",
      "[Epoch 100/500] [Batch 400/469] [D loss: 0.5795] [G loss: 0.8042]\n",
      "[Epoch 101/500] [Batch 0/469] [D loss: 0.5849] [G loss: 0.9262]\n",
      "[Epoch 101/500] [Batch 100/469] [D loss: 0.5996] [G loss: 0.6971]\n",
      "[Epoch 101/500] [Batch 200/469] [D loss: 0.5773] [G loss: 1.3036]\n",
      "[Epoch 101/500] [Batch 300/469] [D loss: 0.5548] [G loss: 0.9701]\n",
      "[Epoch 101/500] [Batch 400/469] [D loss: 0.5754] [G loss: 0.9346]\n",
      "[Epoch 102/500] [Batch 0/469] [D loss: 0.5538] [G loss: 1.4125]\n",
      "[Epoch 102/500] [Batch 100/469] [D loss: 0.5657] [G loss: 1.0440]\n",
      "[Epoch 102/500] [Batch 200/469] [D loss: 0.5697] [G loss: 1.0498]\n",
      "[Epoch 102/500] [Batch 300/469] [D loss: 0.5430] [G loss: 0.8884]\n",
      "[Epoch 102/500] [Batch 400/469] [D loss: 0.5704] [G loss: 0.8521]\n",
      "[Epoch 103/500] [Batch 0/469] [D loss: 0.5606] [G loss: 0.8548]\n",
      "[Epoch 103/500] [Batch 100/469] [D loss: 0.5542] [G loss: 0.8991]\n",
      "[Epoch 103/500] [Batch 200/469] [D loss: 0.5625] [G loss: 1.3154]\n",
      "[Epoch 103/500] [Batch 300/469] [D loss: 0.5441] [G loss: 1.1867]\n",
      "[Epoch 103/500] [Batch 400/469] [D loss: 0.5815] [G loss: 0.9078]\n",
      "[Epoch 104/500] [Batch 0/469] [D loss: 0.5684] [G loss: 0.8151]\n",
      "[Epoch 104/500] [Batch 100/469] [D loss: 0.5872] [G loss: 1.0274]\n",
      "[Epoch 104/500] [Batch 200/469] [D loss: 0.5586] [G loss: 1.0871]\n",
      "[Epoch 104/500] [Batch 300/469] [D loss: 0.5807] [G loss: 1.2224]\n",
      "[Epoch 104/500] [Batch 400/469] [D loss: 0.5784] [G loss: 0.7537]\n",
      "[Epoch 105/500] [Batch 0/469] [D loss: 0.5592] [G loss: 1.0764]\n",
      "[Epoch 105/500] [Batch 100/469] [D loss: 0.6041] [G loss: 0.9570]\n",
      "[Epoch 105/500] [Batch 200/469] [D loss: 0.5749] [G loss: 0.6693]\n",
      "[Epoch 105/500] [Batch 300/469] [D loss: 0.5870] [G loss: 1.4960]\n",
      "[Epoch 105/500] [Batch 400/469] [D loss: 0.5875] [G loss: 0.8792]\n",
      "[Epoch 106/500] [Batch 0/469] [D loss: 0.5746] [G loss: 1.0558]\n",
      "[Epoch 106/500] [Batch 100/469] [D loss: 0.5594] [G loss: 1.0999]\n",
      "[Epoch 106/500] [Batch 200/469] [D loss: 0.5242] [G loss: 1.0948]\n",
      "[Epoch 106/500] [Batch 300/469] [D loss: 0.6064] [G loss: 0.7513]\n",
      "[Epoch 106/500] [Batch 400/469] [D loss: 0.5554] [G loss: 1.2047]\n",
      "[Epoch 107/500] [Batch 0/469] [D loss: 0.5925] [G loss: 1.2916]\n",
      "[Epoch 107/500] [Batch 100/469] [D loss: 0.5825] [G loss: 0.8789]\n",
      "[Epoch 107/500] [Batch 200/469] [D loss: 0.5733] [G loss: 0.7587]\n",
      "[Epoch 107/500] [Batch 300/469] [D loss: 0.5553] [G loss: 1.2408]\n",
      "[Epoch 107/500] [Batch 400/469] [D loss: 0.5272] [G loss: 1.0159]\n",
      "[Epoch 108/500] [Batch 0/469] [D loss: 0.5929] [G loss: 0.9380]\n",
      "[Epoch 108/500] [Batch 100/469] [D loss: 0.6144] [G loss: 0.7410]\n",
      "[Epoch 108/500] [Batch 200/469] [D loss: 0.5690] [G loss: 1.3171]\n",
      "[Epoch 108/500] [Batch 300/469] [D loss: 0.5667] [G loss: 0.8170]\n",
      "[Epoch 108/500] [Batch 400/469] [D loss: 0.5619] [G loss: 1.0191]\n",
      "[Epoch 109/500] [Batch 0/469] [D loss: 0.5462] [G loss: 1.1387]\n",
      "[Epoch 109/500] [Batch 100/469] [D loss: 0.5337] [G loss: 1.2013]\n",
      "[Epoch 109/500] [Batch 200/469] [D loss: 0.5739] [G loss: 0.8067]\n",
      "[Epoch 109/500] [Batch 300/469] [D loss: 0.6117] [G loss: 1.6261]\n",
      "[Epoch 109/500] [Batch 400/469] [D loss: 0.5855] [G loss: 0.9795]\n",
      "[Epoch 109/500] [FID score: 41.9779]\n",
      "[Epoch 110/500] [Batch 0/469] [D loss: 0.5927] [G loss: 1.3751]\n",
      "[Epoch 110/500] [Batch 100/469] [D loss: 0.5311] [G loss: 1.0737]\n",
      "[Epoch 110/500] [Batch 200/469] [D loss: 0.5463] [G loss: 1.0476]\n",
      "[Epoch 110/500] [Batch 300/469] [D loss: 0.5664] [G loss: 1.2728]\n",
      "[Epoch 110/500] [Batch 400/469] [D loss: 0.5597] [G loss: 1.3019]\n",
      "[Epoch 111/500] [Batch 0/469] [D loss: 0.6174] [G loss: 0.6710]\n",
      "[Epoch 111/500] [Batch 100/469] [D loss: 0.5504] [G loss: 1.1247]\n",
      "[Epoch 111/500] [Batch 200/469] [D loss: 0.5959] [G loss: 0.9531]\n",
      "[Epoch 111/500] [Batch 300/469] [D loss: 0.5425] [G loss: 0.9631]\n",
      "[Epoch 111/500] [Batch 400/469] [D loss: 0.5396] [G loss: 1.0134]\n",
      "[Epoch 112/500] [Batch 0/469] [D loss: 0.6124] [G loss: 1.3464]\n",
      "[Epoch 112/500] [Batch 100/469] [D loss: 0.6183] [G loss: 0.7096]\n",
      "[Epoch 112/500] [Batch 200/469] [D loss: 0.5651] [G loss: 0.7975]\n",
      "[Epoch 112/500] [Batch 300/469] [D loss: 0.5553] [G loss: 0.8920]\n",
      "[Epoch 112/500] [Batch 400/469] [D loss: 0.6513] [G loss: 0.5956]\n",
      "[Epoch 113/500] [Batch 0/469] [D loss: 0.5334] [G loss: 0.8585]\n",
      "[Epoch 113/500] [Batch 100/469] [D loss: 0.5648] [G loss: 1.2378]\n",
      "[Epoch 113/500] [Batch 200/469] [D loss: 0.5345] [G loss: 1.1284]\n",
      "[Epoch 113/500] [Batch 300/469] [D loss: 0.5394] [G loss: 1.0782]\n",
      "[Epoch 113/500] [Batch 400/469] [D loss: 0.6252] [G loss: 1.4542]\n",
      "[Epoch 114/500] [Batch 0/469] [D loss: 0.5031] [G loss: 0.9794]\n",
      "[Epoch 114/500] [Batch 100/469] [D loss: 0.6931] [G loss: 0.4790]\n",
      "[Epoch 114/500] [Batch 200/469] [D loss: 0.5775] [G loss: 1.1179]\n",
      "[Epoch 114/500] [Batch 300/469] [D loss: 0.5644] [G loss: 1.0572]\n",
      "[Epoch 114/500] [Batch 400/469] [D loss: 0.5528] [G loss: 0.8322]\n",
      "[Epoch 115/500] [Batch 0/469] [D loss: 0.5458] [G loss: 1.0881]\n",
      "[Epoch 115/500] [Batch 100/469] [D loss: 0.5694] [G loss: 0.9753]\n",
      "[Epoch 115/500] [Batch 200/469] [D loss: 0.5775] [G loss: 1.3220]\n",
      "[Epoch 115/500] [Batch 300/469] [D loss: 0.5780] [G loss: 1.1719]\n",
      "[Epoch 115/500] [Batch 400/469] [D loss: 0.5702] [G loss: 1.2409]\n",
      "[Epoch 116/500] [Batch 0/469] [D loss: 0.5301] [G loss: 1.0322]\n",
      "[Epoch 116/500] [Batch 100/469] [D loss: 0.5357] [G loss: 1.2342]\n",
      "[Epoch 116/500] [Batch 200/469] [D loss: 0.5846] [G loss: 1.0836]\n",
      "[Epoch 116/500] [Batch 300/469] [D loss: 0.5276] [G loss: 1.0481]\n",
      "[Epoch 116/500] [Batch 400/469] [D loss: 0.5412] [G loss: 0.9390]\n",
      "[Epoch 117/500] [Batch 0/469] [D loss: 0.5600] [G loss: 1.1875]\n",
      "[Epoch 117/500] [Batch 100/469] [D loss: 0.5978] [G loss: 0.6124]\n",
      "[Epoch 117/500] [Batch 200/469] [D loss: 0.5562] [G loss: 1.0276]\n",
      "[Epoch 117/500] [Batch 300/469] [D loss: 0.5427] [G loss: 1.2488]\n",
      "[Epoch 117/500] [Batch 400/469] [D loss: 0.5719] [G loss: 1.0292]\n",
      "[Epoch 118/500] [Batch 0/469] [D loss: 0.6262] [G loss: 0.6497]\n",
      "[Epoch 118/500] [Batch 100/469] [D loss: 0.5320] [G loss: 1.0227]\n",
      "[Epoch 118/500] [Batch 200/469] [D loss: 0.5683] [G loss: 0.7805]\n",
      "[Epoch 118/500] [Batch 300/469] [D loss: 0.5867] [G loss: 1.4392]\n",
      "[Epoch 118/500] [Batch 400/469] [D loss: 0.5731] [G loss: 1.3400]\n",
      "[Epoch 119/500] [Batch 0/469] [D loss: 0.6267] [G loss: 0.7676]\n",
      "[Epoch 119/500] [Batch 100/469] [D loss: 0.5411] [G loss: 1.1206]\n",
      "[Epoch 119/500] [Batch 200/469] [D loss: 0.5416] [G loss: 1.2507]\n",
      "[Epoch 119/500] [Batch 300/469] [D loss: 0.6230] [G loss: 0.6844]\n",
      "[Epoch 119/500] [Batch 400/469] [D loss: 0.5631] [G loss: 1.1383]\n",
      "[Epoch 119/500] [FID score: 39.0992]\n",
      "[Epoch 120/500] [Batch 0/469] [D loss: 0.5763] [G loss: 0.8126]\n",
      "[Epoch 120/500] [Batch 100/469] [D loss: 0.4897] [G loss: 1.2891]\n",
      "[Epoch 120/500] [Batch 200/469] [D loss: 0.7007] [G loss: 0.4957]\n",
      "[Epoch 120/500] [Batch 300/469] [D loss: 0.5491] [G loss: 0.8833]\n",
      "[Epoch 120/500] [Batch 400/469] [D loss: 0.5242] [G loss: 1.1919]\n",
      "[Epoch 121/500] [Batch 0/469] [D loss: 0.5443] [G loss: 0.9272]\n",
      "[Epoch 121/500] [Batch 100/469] [D loss: 0.5777] [G loss: 1.2551]\n",
      "[Epoch 121/500] [Batch 200/469] [D loss: 0.5489] [G loss: 1.3149]\n",
      "[Epoch 121/500] [Batch 300/469] [D loss: 0.5855] [G loss: 0.9184]\n",
      "[Epoch 121/500] [Batch 400/469] [D loss: 0.5946] [G loss: 1.4232]\n",
      "[Epoch 122/500] [Batch 0/469] [D loss: 0.5354] [G loss: 0.9782]\n",
      "[Epoch 122/500] [Batch 100/469] [D loss: 0.5381] [G loss: 0.9598]\n",
      "[Epoch 122/500] [Batch 200/469] [D loss: 0.5530] [G loss: 0.9971]\n",
      "[Epoch 122/500] [Batch 300/469] [D loss: 0.5655] [G loss: 1.3322]\n",
      "[Epoch 122/500] [Batch 400/469] [D loss: 0.5679] [G loss: 0.8964]\n",
      "[Epoch 123/500] [Batch 0/469] [D loss: 0.5419] [G loss: 1.1107]\n",
      "[Epoch 123/500] [Batch 100/469] [D loss: 0.5854] [G loss: 1.6752]\n",
      "[Epoch 123/500] [Batch 200/469] [D loss: 0.5140] [G loss: 1.1514]\n",
      "[Epoch 123/500] [Batch 300/469] [D loss: 0.5580] [G loss: 0.9972]\n",
      "[Epoch 123/500] [Batch 400/469] [D loss: 0.5227] [G loss: 0.9718]\n",
      "[Epoch 124/500] [Batch 0/469] [D loss: 0.5845] [G loss: 0.7687]\n",
      "[Epoch 124/500] [Batch 100/469] [D loss: 0.5880] [G loss: 1.2072]\n",
      "[Epoch 124/500] [Batch 200/469] [D loss: 0.5212] [G loss: 1.0621]\n",
      "[Epoch 124/500] [Batch 300/469] [D loss: 0.5535] [G loss: 0.8965]\n",
      "[Epoch 124/500] [Batch 400/469] [D loss: 0.5700] [G loss: 0.9101]\n",
      "[Epoch 125/500] [Batch 0/469] [D loss: 0.5343] [G loss: 1.0421]\n",
      "[Epoch 125/500] [Batch 100/469] [D loss: 0.5596] [G loss: 1.2207]\n",
      "[Epoch 125/500] [Batch 200/469] [D loss: 0.5277] [G loss: 0.9867]\n",
      "[Epoch 125/500] [Batch 300/469] [D loss: 0.5648] [G loss: 1.3510]\n",
      "[Epoch 125/500] [Batch 400/469] [D loss: 0.6018] [G loss: 0.9178]\n",
      "[Epoch 126/500] [Batch 0/469] [D loss: 0.5143] [G loss: 1.2899]\n",
      "[Epoch 126/500] [Batch 100/469] [D loss: 0.5326] [G loss: 1.0451]\n",
      "[Epoch 126/500] [Batch 200/469] [D loss: 0.5611] [G loss: 0.9090]\n",
      "[Epoch 126/500] [Batch 300/469] [D loss: 0.5964] [G loss: 0.9070]\n",
      "[Epoch 126/500] [Batch 400/469] [D loss: 0.6042] [G loss: 1.2905]\n",
      "[Epoch 127/500] [Batch 0/469] [D loss: 0.6170] [G loss: 1.7730]\n",
      "[Epoch 127/500] [Batch 100/469] [D loss: 0.6128] [G loss: 0.7827]\n",
      "[Epoch 127/500] [Batch 200/469] [D loss: 0.5590] [G loss: 0.6879]\n",
      "[Epoch 127/500] [Batch 300/469] [D loss: 0.5911] [G loss: 0.9593]\n",
      "[Epoch 127/500] [Batch 400/469] [D loss: 0.5323] [G loss: 1.0131]\n",
      "[Epoch 128/500] [Batch 0/469] [D loss: 0.5918] [G loss: 0.7516]\n",
      "[Epoch 128/500] [Batch 100/469] [D loss: 0.5349] [G loss: 1.1754]\n",
      "[Epoch 128/500] [Batch 200/469] [D loss: 0.6198] [G loss: 0.6256]\n",
      "[Epoch 128/500] [Batch 300/469] [D loss: 0.5393] [G loss: 0.9303]\n",
      "[Epoch 128/500] [Batch 400/469] [D loss: 0.6064] [G loss: 0.7453]\n",
      "[Epoch 129/500] [Batch 0/469] [D loss: 0.5697] [G loss: 1.1751]\n",
      "[Epoch 129/500] [Batch 100/469] [D loss: 0.5250] [G loss: 1.1823]\n",
      "[Epoch 129/500] [Batch 200/469] [D loss: 0.5833] [G loss: 0.7223]\n",
      "[Epoch 129/500] [Batch 300/469] [D loss: 0.5128] [G loss: 1.0471]\n",
      "[Epoch 129/500] [Batch 400/469] [D loss: 0.5372] [G loss: 1.1958]\n",
      "[Epoch 129/500] [FID score: 36.4746]\n",
      "[Epoch 130/500] [Batch 0/469] [D loss: 0.5332] [G loss: 1.1371]\n",
      "[Epoch 130/500] [Batch 100/469] [D loss: 0.5233] [G loss: 1.1561]\n",
      "[Epoch 130/500] [Batch 200/469] [D loss: 0.5858] [G loss: 0.7282]\n",
      "[Epoch 130/500] [Batch 300/469] [D loss: 0.5339] [G loss: 1.1990]\n",
      "[Epoch 130/500] [Batch 400/469] [D loss: 0.5256] [G loss: 0.9998]\n",
      "[Epoch 131/500] [Batch 0/469] [D loss: 0.6213] [G loss: 0.6857]\n",
      "[Epoch 131/500] [Batch 100/469] [D loss: 0.5808] [G loss: 1.0827]\n",
      "[Epoch 131/500] [Batch 200/469] [D loss: 0.5426] [G loss: 1.2140]\n",
      "[Epoch 131/500] [Batch 300/469] [D loss: 0.5237] [G loss: 1.1311]\n",
      "[Epoch 131/500] [Batch 400/469] [D loss: 0.5449] [G loss: 1.1132]\n",
      "[Epoch 132/500] [Batch 0/469] [D loss: 0.5705] [G loss: 1.5440]\n",
      "[Epoch 132/500] [Batch 100/469] [D loss: 0.4936] [G loss: 1.0856]\n",
      "[Epoch 132/500] [Batch 200/469] [D loss: 0.5849] [G loss: 1.2202]\n",
      "[Epoch 132/500] [Batch 300/469] [D loss: 0.5727] [G loss: 1.3787]\n",
      "[Epoch 132/500] [Batch 400/469] [D loss: 0.5761] [G loss: 1.3345]\n",
      "[Epoch 133/500] [Batch 0/469] [D loss: 0.5375] [G loss: 1.3804]\n",
      "[Epoch 133/500] [Batch 100/469] [D loss: 0.5566] [G loss: 1.2156]\n",
      "[Epoch 133/500] [Batch 200/469] [D loss: 0.5759] [G loss: 0.9153]\n",
      "[Epoch 133/500] [Batch 300/469] [D loss: 0.5473] [G loss: 1.0683]\n",
      "[Epoch 133/500] [Batch 400/469] [D loss: 0.5254] [G loss: 1.2432]\n",
      "[Epoch 134/500] [Batch 0/469] [D loss: 0.6385] [G loss: 0.6863]\n",
      "[Epoch 134/500] [Batch 100/469] [D loss: 0.5609] [G loss: 1.3290]\n",
      "[Epoch 134/500] [Batch 200/469] [D loss: 0.5013] [G loss: 1.3854]\n",
      "[Epoch 134/500] [Batch 300/469] [D loss: 0.5434] [G loss: 1.0369]\n",
      "[Epoch 134/500] [Batch 400/469] [D loss: 0.5717] [G loss: 1.2393]\n",
      "[Epoch 135/500] [Batch 0/469] [D loss: 0.5187] [G loss: 1.1455]\n",
      "[Epoch 135/500] [Batch 100/469] [D loss: 0.5434] [G loss: 0.9491]\n",
      "[Epoch 135/500] [Batch 200/469] [D loss: 0.6529] [G loss: 0.6153]\n",
      "[Epoch 135/500] [Batch 300/469] [D loss: 0.5320] [G loss: 1.0958]\n",
      "[Epoch 135/500] [Batch 400/469] [D loss: 0.5807] [G loss: 0.7965]\n",
      "[Epoch 136/500] [Batch 0/469] [D loss: 0.5194] [G loss: 1.1768]\n",
      "[Epoch 136/500] [Batch 100/469] [D loss: 0.5354] [G loss: 0.8417]\n",
      "[Epoch 136/500] [Batch 200/469] [D loss: 0.5160] [G loss: 1.0817]\n",
      "[Epoch 136/500] [Batch 300/469] [D loss: 0.5626] [G loss: 1.1408]\n",
      "[Epoch 136/500] [Batch 400/469] [D loss: 0.6113] [G loss: 0.7515]\n",
      "[Epoch 137/500] [Batch 0/469] [D loss: 0.5719] [G loss: 0.8650]\n",
      "[Epoch 137/500] [Batch 100/469] [D loss: 0.5255] [G loss: 1.0378]\n",
      "[Epoch 137/500] [Batch 200/469] [D loss: 0.5330] [G loss: 0.9820]\n",
      "[Epoch 137/500] [Batch 300/469] [D loss: 0.5455] [G loss: 1.3239]\n",
      "[Epoch 137/500] [Batch 400/469] [D loss: 0.5207] [G loss: 1.1197]\n",
      "[Epoch 138/500] [Batch 0/469] [D loss: 0.4955] [G loss: 1.3165]\n",
      "[Epoch 138/500] [Batch 100/469] [D loss: 0.5699] [G loss: 0.8645]\n",
      "[Epoch 138/500] [Batch 200/469] [D loss: 0.5371] [G loss: 1.3380]\n",
      "[Epoch 138/500] [Batch 300/469] [D loss: 0.5538] [G loss: 0.8972]\n",
      "[Epoch 138/500] [Batch 400/469] [D loss: 0.6868] [G loss: 0.5661]\n",
      "[Epoch 139/500] [Batch 0/469] [D loss: 0.5463] [G loss: 1.2244]\n",
      "[Epoch 139/500] [Batch 100/469] [D loss: 0.5320] [G loss: 1.4311]\n",
      "[Epoch 139/500] [Batch 200/469] [D loss: 0.5200] [G loss: 1.2310]\n",
      "[Epoch 139/500] [Batch 300/469] [D loss: 0.5499] [G loss: 1.3259]\n",
      "[Epoch 139/500] [Batch 400/469] [D loss: 0.5641] [G loss: 0.9834]\n",
      "[Epoch 139/500] [FID score: 39.6884]\n",
      "[Epoch 140/500] [Batch 0/469] [D loss: 0.5230] [G loss: 1.3401]\n",
      "[Epoch 140/500] [Batch 100/469] [D loss: 0.5552] [G loss: 1.0865]\n",
      "[Epoch 140/500] [Batch 200/469] [D loss: 0.5655] [G loss: 0.8190]\n",
      "[Epoch 140/500] [Batch 300/469] [D loss: 0.5417] [G loss: 0.8922]\n",
      "[Epoch 140/500] [Batch 400/469] [D loss: 0.5640] [G loss: 0.9207]\n",
      "[Epoch 141/500] [Batch 0/469] [D loss: 0.5453] [G loss: 1.1013]\n",
      "[Epoch 141/500] [Batch 100/469] [D loss: 0.5139] [G loss: 1.0748]\n",
      "[Epoch 141/500] [Batch 200/469] [D loss: 0.5625] [G loss: 0.9574]\n",
      "[Epoch 141/500] [Batch 300/469] [D loss: 0.4885] [G loss: 1.2987]\n",
      "[Epoch 141/500] [Batch 400/469] [D loss: 0.5947] [G loss: 0.7193]\n",
      "[Epoch 142/500] [Batch 0/469] [D loss: 0.5371] [G loss: 1.1010]\n",
      "[Epoch 142/500] [Batch 100/469] [D loss: 0.5366] [G loss: 0.9298]\n",
      "[Epoch 142/500] [Batch 200/469] [D loss: 0.5802] [G loss: 0.9189]\n",
      "[Epoch 142/500] [Batch 300/469] [D loss: 0.5987] [G loss: 1.3035]\n",
      "[Epoch 142/500] [Batch 400/469] [D loss: 0.5318] [G loss: 1.2097]\n",
      "[Epoch 143/500] [Batch 0/469] [D loss: 0.5810] [G loss: 0.9032]\n",
      "[Epoch 143/500] [Batch 100/469] [D loss: 0.5865] [G loss: 1.1729]\n",
      "[Epoch 143/500] [Batch 200/469] [D loss: 0.5538] [G loss: 1.2801]\n",
      "[Epoch 143/500] [Batch 300/469] [D loss: 0.5319] [G loss: 1.0357]\n",
      "[Epoch 143/500] [Batch 400/469] [D loss: 0.6283] [G loss: 0.6624]\n",
      "[Epoch 144/500] [Batch 0/469] [D loss: 0.5079] [G loss: 1.1652]\n",
      "[Epoch 144/500] [Batch 100/469] [D loss: 0.5635] [G loss: 0.9042]\n",
      "[Epoch 144/500] [Batch 200/469] [D loss: 0.5703] [G loss: 1.2203]\n",
      "[Epoch 144/500] [Batch 300/469] [D loss: 0.5713] [G loss: 1.0645]\n",
      "[Epoch 144/500] [Batch 400/469] [D loss: 0.5235] [G loss: 1.3044]\n",
      "[Epoch 145/500] [Batch 0/469] [D loss: 0.6882] [G loss: 0.6031]\n",
      "[Epoch 145/500] [Batch 100/469] [D loss: 0.5536] [G loss: 1.0377]\n",
      "[Epoch 145/500] [Batch 200/469] [D loss: 0.5449] [G loss: 0.9423]\n",
      "[Epoch 145/500] [Batch 300/469] [D loss: 0.5379] [G loss: 1.1304]\n",
      "[Epoch 145/500] [Batch 400/469] [D loss: 0.5128] [G loss: 0.9945]\n",
      "[Epoch 146/500] [Batch 0/469] [D loss: 0.5452] [G loss: 0.9932]\n",
      "[Epoch 146/500] [Batch 100/469] [D loss: 0.5488] [G loss: 1.4013]\n",
      "[Epoch 146/500] [Batch 200/469] [D loss: 0.5577] [G loss: 1.1233]\n",
      "[Epoch 146/500] [Batch 300/469] [D loss: 0.5731] [G loss: 1.1511]\n",
      "[Epoch 146/500] [Batch 400/469] [D loss: 0.5496] [G loss: 0.7694]\n",
      "[Epoch 147/500] [Batch 0/469] [D loss: 0.5992] [G loss: 0.7525]\n",
      "[Epoch 147/500] [Batch 100/469] [D loss: 0.5580] [G loss: 0.9163]\n",
      "[Epoch 147/500] [Batch 200/469] [D loss: 0.5343] [G loss: 1.1637]\n",
      "[Epoch 147/500] [Batch 300/469] [D loss: 0.5730] [G loss: 0.9729]\n",
      "[Epoch 147/500] [Batch 400/469] [D loss: 0.5846] [G loss: 1.4091]\n",
      "[Epoch 148/500] [Batch 0/469] [D loss: 0.5791] [G loss: 1.5866]\n",
      "[Epoch 148/500] [Batch 100/469] [D loss: 0.5731] [G loss: 1.2804]\n",
      "[Epoch 148/500] [Batch 200/469] [D loss: 0.4999] [G loss: 1.3804]\n",
      "[Epoch 148/500] [Batch 300/469] [D loss: 0.5820] [G loss: 0.9033]\n",
      "[Epoch 148/500] [Batch 400/469] [D loss: 0.6396] [G loss: 1.8513]\n",
      "[Epoch 149/500] [Batch 0/469] [D loss: 0.6436] [G loss: 1.8438]\n",
      "[Epoch 149/500] [Batch 100/469] [D loss: 0.5162] [G loss: 1.3834]\n",
      "[Epoch 149/500] [Batch 200/469] [D loss: 0.5266] [G loss: 1.1547]\n",
      "[Epoch 149/500] [Batch 300/469] [D loss: 0.4870] [G loss: 1.1270]\n",
      "[Epoch 149/500] [Batch 400/469] [D loss: 0.5395] [G loss: 0.8277]\n",
      "[Epoch 149/500] [FID score: 36.8785]\n",
      "[Epoch 150/500] [Batch 0/469] [D loss: 0.5682] [G loss: 1.2506]\n",
      "[Epoch 150/500] [Batch 100/469] [D loss: 0.5420] [G loss: 0.8672]\n",
      "[Epoch 150/500] [Batch 200/469] [D loss: 0.5620] [G loss: 1.0203]\n",
      "[Epoch 150/500] [Batch 300/469] [D loss: 0.5624] [G loss: 0.7675]\n",
      "[Epoch 150/500] [Batch 400/469] [D loss: 0.5606] [G loss: 1.3042]\n",
      "[Epoch 151/500] [Batch 0/469] [D loss: 0.5745] [G loss: 1.0297]\n",
      "[Epoch 151/500] [Batch 100/469] [D loss: 0.5441] [G loss: 0.8868]\n",
      "[Epoch 151/500] [Batch 200/469] [D loss: 0.4897] [G loss: 1.1065]\n",
      "[Epoch 151/500] [Batch 300/469] [D loss: 0.5186] [G loss: 1.1518]\n",
      "[Epoch 151/500] [Batch 400/469] [D loss: 0.5437] [G loss: 1.4329]\n",
      "[Epoch 152/500] [Batch 0/469] [D loss: 0.5750] [G loss: 1.1530]\n",
      "[Epoch 152/500] [Batch 100/469] [D loss: 0.4835] [G loss: 1.4700]\n",
      "[Epoch 152/500] [Batch 200/469] [D loss: 0.5794] [G loss: 1.1126]\n",
      "[Epoch 152/500] [Batch 300/469] [D loss: 0.5836] [G loss: 0.8516]\n",
      "[Epoch 152/500] [Batch 400/469] [D loss: 0.5379] [G loss: 1.2444]\n",
      "[Epoch 153/500] [Batch 0/469] [D loss: 0.5776] [G loss: 1.7068]\n",
      "[Epoch 153/500] [Batch 100/469] [D loss: 0.5322] [G loss: 1.2704]\n",
      "[Epoch 153/500] [Batch 200/469] [D loss: 0.5350] [G loss: 1.1903]\n",
      "[Epoch 153/500] [Batch 300/469] [D loss: 0.5643] [G loss: 1.6007]\n",
      "[Epoch 153/500] [Batch 400/469] [D loss: 0.5646] [G loss: 0.8402]\n",
      "[Epoch 154/500] [Batch 0/469] [D loss: 0.5084] [G loss: 1.2233]\n",
      "[Epoch 154/500] [Batch 100/469] [D loss: 0.5444] [G loss: 1.5115]\n",
      "[Epoch 154/500] [Batch 200/469] [D loss: 0.5773] [G loss: 0.8004]\n",
      "[Epoch 154/500] [Batch 300/469] [D loss: 0.5553] [G loss: 0.8884]\n",
      "[Epoch 154/500] [Batch 400/469] [D loss: 0.6143] [G loss: 1.4265]\n",
      "[Epoch 155/500] [Batch 0/469] [D loss: 0.5472] [G loss: 1.5259]\n",
      "[Epoch 155/500] [Batch 100/469] [D loss: 0.5896] [G loss: 1.3084]\n",
      "[Epoch 155/500] [Batch 200/469] [D loss: 0.5103] [G loss: 1.2107]\n",
      "[Epoch 155/500] [Batch 300/469] [D loss: 0.5348] [G loss: 1.3844]\n",
      "[Epoch 155/500] [Batch 400/469] [D loss: 0.5180] [G loss: 0.9837]\n",
      "[Epoch 156/500] [Batch 0/469] [D loss: 0.5401] [G loss: 1.1700]\n",
      "[Epoch 156/500] [Batch 100/469] [D loss: 0.5260] [G loss: 0.8981]\n",
      "[Epoch 156/500] [Batch 200/469] [D loss: 0.5394] [G loss: 1.0115]\n",
      "[Epoch 156/500] [Batch 300/469] [D loss: 0.5180] [G loss: 1.1313]\n",
      "[Epoch 156/500] [Batch 400/469] [D loss: 0.6584] [G loss: 1.7799]\n",
      "[Epoch 157/500] [Batch 0/469] [D loss: 0.6080] [G loss: 0.7020]\n",
      "[Epoch 157/500] [Batch 100/469] [D loss: 0.5777] [G loss: 1.4004]\n",
      "[Epoch 157/500] [Batch 200/469] [D loss: 0.5362] [G loss: 1.3099]\n",
      "[Epoch 157/500] [Batch 300/469] [D loss: 0.5208] [G loss: 1.3214]\n",
      "[Epoch 157/500] [Batch 400/469] [D loss: 0.5669] [G loss: 1.2122]\n",
      "[Epoch 158/500] [Batch 0/469] [D loss: 0.6286] [G loss: 0.6251]\n",
      "[Epoch 158/500] [Batch 100/469] [D loss: 0.5035] [G loss: 1.1376]\n",
      "[Epoch 158/500] [Batch 200/469] [D loss: 0.5373] [G loss: 1.3717]\n",
      "[Epoch 158/500] [Batch 300/469] [D loss: 0.4979] [G loss: 1.1673]\n",
      "[Epoch 158/500] [Batch 400/469] [D loss: 0.5448] [G loss: 1.7156]\n",
      "[Epoch 159/500] [Batch 0/469] [D loss: 0.5003] [G loss: 1.1814]\n",
      "[Epoch 159/500] [Batch 100/469] [D loss: 0.5767] [G loss: 1.0100]\n",
      "[Epoch 159/500] [Batch 200/469] [D loss: 0.5521] [G loss: 1.2122]\n",
      "[Epoch 159/500] [Batch 300/469] [D loss: 0.5611] [G loss: 1.5013]\n",
      "[Epoch 159/500] [Batch 400/469] [D loss: 0.5333] [G loss: 1.5574]\n",
      "[Epoch 159/500] [FID score: 35.2266]\n",
      "[Epoch 160/500] [Batch 0/469] [D loss: 0.5173] [G loss: 1.0419]\n",
      "[Epoch 160/500] [Batch 100/469] [D loss: 0.5196] [G loss: 0.9585]\n",
      "[Epoch 160/500] [Batch 200/469] [D loss: 0.5934] [G loss: 0.7766]\n",
      "[Epoch 160/500] [Batch 300/469] [D loss: 0.5567] [G loss: 0.7927]\n",
      "[Epoch 160/500] [Batch 400/469] [D loss: 0.5719] [G loss: 1.0225]\n",
      "[Epoch 161/500] [Batch 0/469] [D loss: 0.5098] [G loss: 1.0580]\n",
      "[Epoch 161/500] [Batch 100/469] [D loss: 0.5220] [G loss: 1.0872]\n",
      "[Epoch 161/500] [Batch 200/469] [D loss: 0.4761] [G loss: 1.4568]\n",
      "[Epoch 161/500] [Batch 300/469] [D loss: 0.5394] [G loss: 1.3903]\n",
      "[Epoch 161/500] [Batch 400/469] [D loss: 0.5520] [G loss: 1.0011]\n",
      "[Epoch 162/500] [Batch 0/469] [D loss: 0.5616] [G loss: 0.8622]\n",
      "[Epoch 162/500] [Batch 100/469] [D loss: 0.5208] [G loss: 1.3851]\n",
      "[Epoch 162/500] [Batch 200/469] [D loss: 0.5462] [G loss: 0.8812]\n",
      "[Epoch 162/500] [Batch 300/469] [D loss: 0.5499] [G loss: 1.5280]\n",
      "[Epoch 162/500] [Batch 400/469] [D loss: 0.5799] [G loss: 1.0523]\n",
      "[Epoch 163/500] [Batch 0/469] [D loss: 0.5031] [G loss: 1.0390]\n",
      "[Epoch 163/500] [Batch 100/469] [D loss: 0.5061] [G loss: 1.0096]\n",
      "[Epoch 163/500] [Batch 200/469] [D loss: 0.5755] [G loss: 0.8014]\n",
      "[Epoch 163/500] [Batch 300/469] [D loss: 0.5255] [G loss: 0.8524]\n",
      "[Epoch 163/500] [Batch 400/469] [D loss: 0.5806] [G loss: 0.8138]\n",
      "[Epoch 164/500] [Batch 0/469] [D loss: 0.5477] [G loss: 1.4923]\n",
      "[Epoch 164/500] [Batch 100/469] [D loss: 0.5804] [G loss: 0.7573]\n",
      "[Epoch 164/500] [Batch 200/469] [D loss: 0.5127] [G loss: 1.3076]\n",
      "[Epoch 164/500] [Batch 300/469] [D loss: 0.5803] [G loss: 0.9034]\n",
      "[Epoch 164/500] [Batch 400/469] [D loss: 0.5307] [G loss: 1.3748]\n",
      "[Epoch 165/500] [Batch 0/469] [D loss: 0.5668] [G loss: 0.8135]\n",
      "[Epoch 165/500] [Batch 100/469] [D loss: 0.4795] [G loss: 1.2171]\n",
      "[Epoch 165/500] [Batch 200/469] [D loss: 0.5952] [G loss: 1.6817]\n",
      "[Epoch 165/500] [Batch 300/469] [D loss: 0.6139] [G loss: 1.2600]\n",
      "[Epoch 165/500] [Batch 400/469] [D loss: 0.4867] [G loss: 1.0859]\n",
      "[Epoch 166/500] [Batch 0/469] [D loss: 0.5571] [G loss: 0.8717]\n",
      "[Epoch 166/500] [Batch 100/469] [D loss: 0.5160] [G loss: 1.1225]\n",
      "[Epoch 166/500] [Batch 200/469] [D loss: 0.5614] [G loss: 1.3902]\n",
      "[Epoch 166/500] [Batch 300/469] [D loss: 0.5021] [G loss: 1.2296]\n",
      "[Epoch 166/500] [Batch 400/469] [D loss: 0.5595] [G loss: 1.5986]\n",
      "[Epoch 167/500] [Batch 0/469] [D loss: 0.5734] [G loss: 1.0624]\n",
      "[Epoch 167/500] [Batch 100/469] [D loss: 0.5484] [G loss: 1.2602]\n",
      "[Epoch 167/500] [Batch 200/469] [D loss: 0.5067] [G loss: 1.1700]\n",
      "[Epoch 167/500] [Batch 300/469] [D loss: 0.5286] [G loss: 0.9950]\n",
      "[Epoch 167/500] [Batch 400/469] [D loss: 0.5679] [G loss: 0.8628]\n",
      "[Epoch 168/500] [Batch 0/469] [D loss: 0.5331] [G loss: 1.1378]\n",
      "[Epoch 168/500] [Batch 100/469] [D loss: 0.5089] [G loss: 1.2272]\n",
      "[Epoch 168/500] [Batch 200/469] [D loss: 0.5736] [G loss: 0.7847]\n",
      "[Epoch 168/500] [Batch 300/469] [D loss: 0.5348] [G loss: 0.9203]\n",
      "[Epoch 168/500] [Batch 400/469] [D loss: 0.5303] [G loss: 0.9951]\n",
      "[Epoch 169/500] [Batch 0/469] [D loss: 0.4949] [G loss: 1.0346]\n",
      "[Epoch 169/500] [Batch 100/469] [D loss: 0.5442] [G loss: 0.8854]\n",
      "[Epoch 169/500] [Batch 200/469] [D loss: 0.5347] [G loss: 1.4736]\n",
      "[Epoch 169/500] [Batch 300/469] [D loss: 0.6572] [G loss: 0.6746]\n",
      "[Epoch 169/500] [Batch 400/469] [D loss: 0.5375] [G loss: 1.2941]\n",
      "[Epoch 169/500] [FID score: 36.7169]\n",
      "[Epoch 170/500] [Batch 0/469] [D loss: 0.5909] [G loss: 0.8274]\n",
      "[Epoch 170/500] [Batch 100/469] [D loss: 0.5620] [G loss: 0.7268]\n",
      "[Epoch 170/500] [Batch 200/469] [D loss: 0.5180] [G loss: 1.0250]\n",
      "[Epoch 170/500] [Batch 300/469] [D loss: 0.5428] [G loss: 1.0536]\n",
      "[Epoch 170/500] [Batch 400/469] [D loss: 0.5693] [G loss: 1.5318]\n",
      "[Epoch 171/500] [Batch 0/469] [D loss: 0.5398] [G loss: 0.9904]\n",
      "[Epoch 171/500] [Batch 100/469] [D loss: 0.5348] [G loss: 1.3000]\n",
      "[Epoch 171/500] [Batch 200/469] [D loss: 0.6165] [G loss: 1.5950]\n",
      "[Epoch 171/500] [Batch 300/469] [D loss: 0.5203] [G loss: 0.9910]\n",
      "[Epoch 171/500] [Batch 400/469] [D loss: 0.5721] [G loss: 1.4608]\n",
      "[Epoch 172/500] [Batch 0/469] [D loss: 0.4962] [G loss: 1.3180]\n",
      "[Epoch 172/500] [Batch 100/469] [D loss: 0.5480] [G loss: 1.4384]\n",
      "[Epoch 172/500] [Batch 200/469] [D loss: 0.5781] [G loss: 1.9055]\n",
      "[Epoch 172/500] [Batch 300/469] [D loss: 0.5189] [G loss: 1.0151]\n",
      "[Epoch 172/500] [Batch 400/469] [D loss: 0.5488] [G loss: 0.9813]\n",
      "[Epoch 173/500] [Batch 0/469] [D loss: 0.5751] [G loss: 0.8537]\n",
      "[Epoch 173/500] [Batch 100/469] [D loss: 0.5248] [G loss: 1.0191]\n",
      "[Epoch 173/500] [Batch 200/469] [D loss: 0.5233] [G loss: 1.0558]\n",
      "[Epoch 173/500] [Batch 300/469] [D loss: 0.5366] [G loss: 0.9012]\n",
      "[Epoch 173/500] [Batch 400/469] [D loss: 0.5313] [G loss: 1.6081]\n",
      "[Epoch 174/500] [Batch 0/469] [D loss: 0.5132] [G loss: 1.1726]\n",
      "[Epoch 174/500] [Batch 100/469] [D loss: 0.5169] [G loss: 1.2778]\n",
      "[Epoch 174/500] [Batch 200/469] [D loss: 0.5175] [G loss: 1.5721]\n",
      "[Epoch 174/500] [Batch 300/469] [D loss: 0.5351] [G loss: 1.0029]\n",
      "[Epoch 174/500] [Batch 400/469] [D loss: 0.5302] [G loss: 1.3797]\n",
      "[Epoch 175/500] [Batch 0/469] [D loss: 0.5253] [G loss: 1.1491]\n",
      "[Epoch 175/500] [Batch 100/469] [D loss: 0.4850] [G loss: 1.3014]\n",
      "[Epoch 175/500] [Batch 200/469] [D loss: 0.5725] [G loss: 0.8120]\n",
      "[Epoch 175/500] [Batch 300/469] [D loss: 0.5042] [G loss: 1.1747]\n",
      "[Epoch 175/500] [Batch 400/469] [D loss: 0.5197] [G loss: 1.0580]\n",
      "[Epoch 176/500] [Batch 0/469] [D loss: 0.5277] [G loss: 1.1454]\n",
      "[Epoch 176/500] [Batch 100/469] [D loss: 0.5607] [G loss: 1.0742]\n",
      "[Epoch 176/500] [Batch 200/469] [D loss: 0.5103] [G loss: 1.1389]\n",
      "[Epoch 176/500] [Batch 300/469] [D loss: 0.5259] [G loss: 1.4144]\n",
      "[Epoch 176/500] [Batch 400/469] [D loss: 0.5107] [G loss: 1.2080]\n",
      "[Epoch 177/500] [Batch 0/469] [D loss: 0.5307] [G loss: 1.3927]\n",
      "[Epoch 177/500] [Batch 100/469] [D loss: 0.5722] [G loss: 1.2490]\n",
      "[Epoch 177/500] [Batch 200/469] [D loss: 0.4861] [G loss: 1.0270]\n",
      "[Epoch 177/500] [Batch 300/469] [D loss: 0.5599] [G loss: 1.4600]\n",
      "[Epoch 177/500] [Batch 400/469] [D loss: 0.5734] [G loss: 1.5173]\n",
      "[Epoch 178/500] [Batch 0/469] [D loss: 0.5477] [G loss: 0.8562]\n",
      "[Epoch 178/500] [Batch 100/469] [D loss: 0.5648] [G loss: 0.7534]\n",
      "[Epoch 178/500] [Batch 200/469] [D loss: 0.5484] [G loss: 1.1542]\n",
      "[Epoch 178/500] [Batch 300/469] [D loss: 0.5638] [G loss: 0.9743]\n",
      "[Epoch 178/500] [Batch 400/469] [D loss: 0.5152] [G loss: 1.3401]\n",
      "[Epoch 179/500] [Batch 0/469] [D loss: 0.5068] [G loss: 1.4071]\n",
      "[Epoch 179/500] [Batch 100/469] [D loss: 0.5307] [G loss: 1.1453]\n",
      "[Epoch 179/500] [Batch 200/469] [D loss: 0.4767] [G loss: 1.0005]\n",
      "[Epoch 179/500] [Batch 300/469] [D loss: 0.5926] [G loss: 0.8842]\n",
      "[Epoch 179/500] [Batch 400/469] [D loss: 0.5225] [G loss: 1.0140]\n",
      "[Epoch 179/500] [FID score: 34.6021]\n",
      "[Epoch 180/500] [Batch 0/469] [D loss: 0.5863] [G loss: 0.8758]\n",
      "[Epoch 180/500] [Batch 100/469] [D loss: 0.5372] [G loss: 1.6768]\n",
      "[Epoch 180/500] [Batch 200/469] [D loss: 0.5268] [G loss: 1.2418]\n",
      "[Epoch 180/500] [Batch 300/469] [D loss: 0.5240] [G loss: 0.8863]\n",
      "[Epoch 180/500] [Batch 400/469] [D loss: 0.5328] [G loss: 1.4693]\n",
      "[Epoch 181/500] [Batch 0/469] [D loss: 0.5068] [G loss: 1.1027]\n",
      "[Epoch 181/500] [Batch 100/469] [D loss: 0.5248] [G loss: 1.0204]\n",
      "[Epoch 181/500] [Batch 200/469] [D loss: 0.5346] [G loss: 1.3673]\n",
      "[Epoch 181/500] [Batch 300/469] [D loss: 0.4979] [G loss: 1.2623]\n",
      "[Epoch 181/500] [Batch 400/469] [D loss: 0.5513] [G loss: 1.6347]\n",
      "[Epoch 182/500] [Batch 0/469] [D loss: 0.5010] [G loss: 1.1901]\n",
      "[Epoch 182/500] [Batch 100/469] [D loss: 0.5475] [G loss: 1.1322]\n",
      "[Epoch 182/500] [Batch 200/469] [D loss: 0.5650] [G loss: 0.8974]\n",
      "[Epoch 182/500] [Batch 300/469] [D loss: 0.5454] [G loss: 1.4443]\n",
      "[Epoch 182/500] [Batch 400/469] [D loss: 0.4738] [G loss: 1.4205]\n",
      "[Epoch 183/500] [Batch 0/469] [D loss: 0.5312] [G loss: 1.0190]\n",
      "[Epoch 183/500] [Batch 100/469] [D loss: 0.5024] [G loss: 1.2850]\n",
      "[Epoch 183/500] [Batch 200/469] [D loss: 0.5435] [G loss: 1.0601]\n",
      "[Epoch 183/500] [Batch 300/469] [D loss: 0.4860] [G loss: 1.0335]\n",
      "[Epoch 183/500] [Batch 400/469] [D loss: 0.4820] [G loss: 1.1324]\n",
      "[Epoch 184/500] [Batch 0/469] [D loss: 0.5128] [G loss: 1.2779]\n",
      "[Epoch 184/500] [Batch 100/469] [D loss: 0.5255] [G loss: 1.2105]\n",
      "[Epoch 184/500] [Batch 200/469] [D loss: 0.4728] [G loss: 1.1293]\n",
      "[Epoch 184/500] [Batch 300/469] [D loss: 0.5116] [G loss: 1.2074]\n",
      "[Epoch 184/500] [Batch 400/469] [D loss: 0.5218] [G loss: 1.2717]\n",
      "[Epoch 185/500] [Batch 0/469] [D loss: 0.5068] [G loss: 1.2327]\n",
      "[Epoch 185/500] [Batch 100/469] [D loss: 0.4972] [G loss: 0.9670]\n",
      "[Epoch 185/500] [Batch 200/469] [D loss: 0.5373] [G loss: 1.2082]\n",
      "[Epoch 185/500] [Batch 300/469] [D loss: 0.5302] [G loss: 1.5674]\n",
      "[Epoch 185/500] [Batch 400/469] [D loss: 0.5112] [G loss: 1.3768]\n",
      "[Epoch 186/500] [Batch 0/469] [D loss: 0.4588] [G loss: 1.0510]\n",
      "[Epoch 186/500] [Batch 100/469] [D loss: 0.5223] [G loss: 1.5009]\n",
      "[Epoch 186/500] [Batch 200/469] [D loss: 0.5622] [G loss: 1.3179]\n",
      "[Epoch 186/500] [Batch 300/469] [D loss: 0.5328] [G loss: 1.3041]\n",
      "[Epoch 186/500] [Batch 400/469] [D loss: 0.5098] [G loss: 0.8456]\n",
      "[Epoch 187/500] [Batch 0/469] [D loss: 0.5889] [G loss: 0.7084]\n",
      "[Epoch 187/500] [Batch 100/469] [D loss: 0.4979] [G loss: 1.2394]\n",
      "[Epoch 187/500] [Batch 200/469] [D loss: 0.5579] [G loss: 0.9269]\n",
      "[Epoch 187/500] [Batch 300/469] [D loss: 0.5376] [G loss: 0.9762]\n",
      "[Epoch 187/500] [Batch 400/469] [D loss: 0.5209] [G loss: 0.9582]\n",
      "[Epoch 188/500] [Batch 0/469] [D loss: 0.5232] [G loss: 0.9277]\n",
      "[Epoch 188/500] [Batch 100/469] [D loss: 0.5481] [G loss: 1.3198]\n",
      "[Epoch 188/500] [Batch 200/469] [D loss: 0.5302] [G loss: 1.1997]\n",
      "[Epoch 188/500] [Batch 300/469] [D loss: 0.5979] [G loss: 0.9776]\n",
      "[Epoch 188/500] [Batch 400/469] [D loss: 0.5120] [G loss: 0.9911]\n",
      "[Epoch 189/500] [Batch 0/469] [D loss: 0.5128] [G loss: 1.1379]\n",
      "[Epoch 189/500] [Batch 100/469] [D loss: 0.4996] [G loss: 1.1716]\n",
      "[Epoch 189/500] [Batch 200/469] [D loss: 0.5156] [G loss: 1.2728]\n",
      "[Epoch 189/500] [Batch 300/469] [D loss: 0.5522] [G loss: 1.4677]\n",
      "[Epoch 189/500] [Batch 400/469] [D loss: 0.5663] [G loss: 0.7313]\n",
      "[Epoch 189/500] [FID score: 34.4555]\n",
      "[Epoch 190/500] [Batch 0/469] [D loss: 0.5467] [G loss: 1.1036]\n",
      "[Epoch 190/500] [Batch 100/469] [D loss: 0.5310] [G loss: 0.9376]\n",
      "[Epoch 190/500] [Batch 200/469] [D loss: 0.5165] [G loss: 1.3527]\n",
      "[Epoch 190/500] [Batch 300/469] [D loss: 0.6171] [G loss: 0.6856]\n",
      "[Epoch 190/500] [Batch 400/469] [D loss: 0.5258] [G loss: 0.9177]\n",
      "[Epoch 191/500] [Batch 0/469] [D loss: 0.5046] [G loss: 1.6570]\n",
      "[Epoch 191/500] [Batch 100/469] [D loss: 0.6286] [G loss: 0.7137]\n",
      "[Epoch 191/500] [Batch 200/469] [D loss: 0.5029] [G loss: 1.4965]\n",
      "[Epoch 191/500] [Batch 300/469] [D loss: 0.5189] [G loss: 1.5287]\n",
      "[Epoch 191/500] [Batch 400/469] [D loss: 0.5166] [G loss: 1.1745]\n",
      "[Epoch 192/500] [Batch 0/469] [D loss: 0.6505] [G loss: 0.6233]\n",
      "[Epoch 192/500] [Batch 100/469] [D loss: 0.5659] [G loss: 1.8994]\n",
      "[Epoch 192/500] [Batch 200/469] [D loss: 0.4910] [G loss: 1.0187]\n",
      "[Epoch 192/500] [Batch 300/469] [D loss: 0.5292] [G loss: 1.2196]\n",
      "[Epoch 192/500] [Batch 400/469] [D loss: 0.5526] [G loss: 0.9422]\n",
      "[Epoch 193/500] [Batch 0/469] [D loss: 0.5283] [G loss: 1.1561]\n",
      "[Epoch 193/500] [Batch 100/469] [D loss: 0.5181] [G loss: 1.2645]\n",
      "[Epoch 193/500] [Batch 200/469] [D loss: 0.5326] [G loss: 1.3299]\n",
      "[Epoch 193/500] [Batch 300/469] [D loss: 0.5268] [G loss: 0.8997]\n",
      "[Epoch 193/500] [Batch 400/469] [D loss: 0.4647] [G loss: 1.1815]\n",
      "[Epoch 194/500] [Batch 0/469] [D loss: 0.5664] [G loss: 1.9495]\n",
      "[Epoch 194/500] [Batch 100/469] [D loss: 0.5528] [G loss: 1.5002]\n",
      "[Epoch 194/500] [Batch 200/469] [D loss: 0.5555] [G loss: 0.8741]\n",
      "[Epoch 194/500] [Batch 300/469] [D loss: 0.5096] [G loss: 1.4303]\n",
      "[Epoch 194/500] [Batch 400/469] [D loss: 0.5156] [G loss: 1.0785]\n",
      "[Epoch 195/500] [Batch 0/469] [D loss: 0.5251] [G loss: 1.0907]\n",
      "[Epoch 195/500] [Batch 100/469] [D loss: 0.4967] [G loss: 1.0617]\n",
      "[Epoch 195/500] [Batch 200/469] [D loss: 0.5027] [G loss: 1.3323]\n",
      "[Epoch 195/500] [Batch 300/469] [D loss: 0.7070] [G loss: 0.5527]\n",
      "[Epoch 195/500] [Batch 400/469] [D loss: 0.5124] [G loss: 1.4312]\n",
      "[Epoch 196/500] [Batch 0/469] [D loss: 0.4490] [G loss: 1.0976]\n",
      "[Epoch 196/500] [Batch 100/469] [D loss: 0.4907] [G loss: 1.2338]\n",
      "[Epoch 196/500] [Batch 200/469] [D loss: 0.4818] [G loss: 1.0213]\n",
      "[Epoch 196/500] [Batch 300/469] [D loss: 0.5027] [G loss: 1.6600]\n",
      "[Epoch 196/500] [Batch 400/469] [D loss: 0.4772] [G loss: 1.3973]\n",
      "[Epoch 197/500] [Batch 0/469] [D loss: 0.5062] [G loss: 1.1263]\n",
      "[Epoch 197/500] [Batch 100/469] [D loss: 0.6080] [G loss: 0.7673]\n",
      "[Epoch 197/500] [Batch 200/469] [D loss: 0.5005] [G loss: 1.0719]\n",
      "[Epoch 197/500] [Batch 300/469] [D loss: 0.4613] [G loss: 1.3201]\n",
      "[Epoch 197/500] [Batch 400/469] [D loss: 0.5156] [G loss: 1.3992]\n",
      "[Epoch 198/500] [Batch 0/469] [D loss: 0.5165] [G loss: 1.0285]\n",
      "[Epoch 198/500] [Batch 100/469] [D loss: 0.5362] [G loss: 1.4831]\n",
      "[Epoch 198/500] [Batch 200/469] [D loss: 0.5173] [G loss: 0.9933]\n",
      "[Epoch 198/500] [Batch 300/469] [D loss: 0.5315] [G loss: 1.2653]\n",
      "[Epoch 198/500] [Batch 400/469] [D loss: 0.5392] [G loss: 0.9818]\n",
      "[Epoch 199/500] [Batch 0/469] [D loss: 0.5432] [G loss: 1.0711]\n",
      "[Epoch 199/500] [Batch 100/469] [D loss: 0.5035] [G loss: 1.1040]\n",
      "[Epoch 199/500] [Batch 200/469] [D loss: 0.5461] [G loss: 0.9213]\n",
      "[Epoch 199/500] [Batch 300/469] [D loss: 0.4672] [G loss: 1.1480]\n",
      "[Epoch 199/500] [Batch 400/469] [D loss: 0.6179] [G loss: 0.7093]\n",
      "[Epoch 199/500] [FID score: 31.0082]\n",
      "[Epoch 200/500] [Batch 0/469] [D loss: 0.5231] [G loss: 1.0239]\n",
      "[Epoch 200/500] [Batch 100/469] [D loss: 0.5975] [G loss: 0.6644]\n",
      "[Epoch 200/500] [Batch 200/469] [D loss: 0.5268] [G loss: 0.9906]\n",
      "[Epoch 200/500] [Batch 300/469] [D loss: 0.5378] [G loss: 1.4798]\n",
      "[Epoch 200/500] [Batch 400/469] [D loss: 0.5349] [G loss: 1.3329]\n",
      "[Epoch 201/500] [Batch 0/469] [D loss: 0.5938] [G loss: 0.8371]\n",
      "[Epoch 201/500] [Batch 100/469] [D loss: 0.5288] [G loss: 0.9840]\n",
      "[Epoch 201/500] [Batch 200/469] [D loss: 0.6941] [G loss: 0.5772]\n",
      "[Epoch 201/500] [Batch 300/469] [D loss: 0.5216] [G loss: 1.1911]\n",
      "[Epoch 201/500] [Batch 400/469] [D loss: 0.5182] [G loss: 1.0606]\n",
      "[Epoch 202/500] [Batch 0/469] [D loss: 0.4841] [G loss: 1.1309]\n",
      "[Epoch 202/500] [Batch 100/469] [D loss: 0.5712] [G loss: 0.7846]\n",
      "[Epoch 202/500] [Batch 200/469] [D loss: 0.4827] [G loss: 1.2078]\n",
      "[Epoch 202/500] [Batch 300/469] [D loss: 0.4972] [G loss: 1.5877]\n",
      "[Epoch 202/500] [Batch 400/469] [D loss: 0.4909] [G loss: 1.5523]\n",
      "[Epoch 203/500] [Batch 0/469] [D loss: 0.5190] [G loss: 1.2341]\n",
      "[Epoch 203/500] [Batch 100/469] [D loss: 0.5398] [G loss: 1.1323]\n",
      "[Epoch 203/500] [Batch 200/469] [D loss: 0.4985] [G loss: 1.0844]\n",
      "[Epoch 203/500] [Batch 300/469] [D loss: 0.5695] [G loss: 1.3153]\n",
      "[Epoch 203/500] [Batch 400/469] [D loss: 0.5191] [G loss: 1.4527]\n",
      "[Epoch 204/500] [Batch 0/469] [D loss: 0.5931] [G loss: 0.8508]\n",
      "[Epoch 204/500] [Batch 100/469] [D loss: 0.5355] [G loss: 1.4509]\n",
      "[Epoch 204/500] [Batch 200/469] [D loss: 0.6068] [G loss: 1.4285]\n",
      "[Epoch 204/500] [Batch 300/469] [D loss: 0.4987] [G loss: 1.4757]\n",
      "[Epoch 204/500] [Batch 400/469] [D loss: 0.5089] [G loss: 1.1970]\n",
      "[Epoch 205/500] [Batch 0/469] [D loss: 0.5107] [G loss: 1.2447]\n",
      "[Epoch 205/500] [Batch 100/469] [D loss: 0.4945] [G loss: 1.3015]\n",
      "[Epoch 205/500] [Batch 200/469] [D loss: 0.5150] [G loss: 1.2525]\n",
      "[Epoch 205/500] [Batch 300/469] [D loss: 0.5199] [G loss: 0.9907]\n",
      "[Epoch 205/500] [Batch 400/469] [D loss: 0.5073] [G loss: 1.7014]\n",
      "[Epoch 206/500] [Batch 0/469] [D loss: 0.4934] [G loss: 1.2206]\n",
      "[Epoch 206/500] [Batch 100/469] [D loss: 0.5141] [G loss: 1.6779]\n",
      "[Epoch 206/500] [Batch 200/469] [D loss: 0.5147] [G loss: 1.6307]\n",
      "[Epoch 206/500] [Batch 300/469] [D loss: 0.4910] [G loss: 1.3665]\n",
      "[Epoch 206/500] [Batch 400/469] [D loss: 0.5030] [G loss: 1.0232]\n",
      "[Epoch 207/500] [Batch 0/469] [D loss: 0.4989] [G loss: 1.1704]\n",
      "[Epoch 207/500] [Batch 100/469] [D loss: 0.5112] [G loss: 1.5473]\n",
      "[Epoch 207/500] [Batch 200/469] [D loss: 0.5141] [G loss: 1.2982]\n",
      "[Epoch 207/500] [Batch 300/469] [D loss: 0.5062] [G loss: 1.5152]\n",
      "[Epoch 207/500] [Batch 400/469] [D loss: 0.5707] [G loss: 1.4948]\n",
      "[Epoch 208/500] [Batch 0/469] [D loss: 0.5031] [G loss: 1.4362]\n",
      "[Epoch 208/500] [Batch 100/469] [D loss: 0.5503] [G loss: 0.9957]\n",
      "[Epoch 208/500] [Batch 200/469] [D loss: 0.5031] [G loss: 1.1667]\n",
      "[Epoch 208/500] [Batch 300/469] [D loss: 0.5007] [G loss: 0.9735]\n",
      "[Epoch 208/500] [Batch 400/469] [D loss: 0.5093] [G loss: 1.6600]\n",
      "[Epoch 209/500] [Batch 0/469] [D loss: 0.5286] [G loss: 0.9236]\n",
      "[Epoch 209/500] [Batch 100/469] [D loss: 0.5222] [G loss: 1.1429]\n",
      "[Epoch 209/500] [Batch 200/469] [D loss: 0.5219] [G loss: 1.0255]\n",
      "[Epoch 209/500] [Batch 300/469] [D loss: 0.4579] [G loss: 1.2983]\n",
      "[Epoch 209/500] [Batch 400/469] [D loss: 0.5186] [G loss: 1.6849]\n",
      "[Epoch 209/500] [FID score: 29.2557]\n",
      "[Epoch 210/500] [Batch 0/469] [D loss: 0.5189] [G loss: 0.9026]\n",
      "[Epoch 210/500] [Batch 100/469] [D loss: 0.5265] [G loss: 0.9636]\n",
      "[Epoch 210/500] [Batch 200/469] [D loss: 0.5464] [G loss: 1.3107]\n",
      "[Epoch 210/500] [Batch 300/469] [D loss: 0.5532] [G loss: 0.8387]\n",
      "[Epoch 210/500] [Batch 400/469] [D loss: 0.5551] [G loss: 1.1981]\n",
      "[Epoch 211/500] [Batch 0/469] [D loss: 0.4643] [G loss: 1.4241]\n",
      "[Epoch 211/500] [Batch 100/469] [D loss: 0.5183] [G loss: 1.3346]\n",
      "[Epoch 211/500] [Batch 200/469] [D loss: 0.4924] [G loss: 1.0877]\n",
      "[Epoch 211/500] [Batch 300/469] [D loss: 0.5611] [G loss: 0.7724]\n",
      "[Epoch 211/500] [Batch 400/469] [D loss: 0.5177] [G loss: 1.1519]\n",
      "[Epoch 212/500] [Batch 0/469] [D loss: 0.5234] [G loss: 1.2121]\n",
      "[Epoch 212/500] [Batch 100/469] [D loss: 0.4868] [G loss: 1.0919]\n",
      "[Epoch 212/500] [Batch 200/469] [D loss: 0.6671] [G loss: 0.5670]\n",
      "[Epoch 212/500] [Batch 300/469] [D loss: 0.5147] [G loss: 1.3199]\n",
      "[Epoch 212/500] [Batch 400/469] [D loss: 0.5308] [G loss: 1.9404]\n",
      "[Epoch 213/500] [Batch 0/469] [D loss: 0.4899] [G loss: 1.2887]\n",
      "[Epoch 213/500] [Batch 100/469] [D loss: 0.5184] [G loss: 1.5939]\n",
      "[Epoch 213/500] [Batch 200/469] [D loss: 0.5088] [G loss: 1.3974]\n",
      "[Epoch 213/500] [Batch 300/469] [D loss: 0.5517] [G loss: 1.0255]\n",
      "[Epoch 213/500] [Batch 400/469] [D loss: 0.4994] [G loss: 1.0686]\n",
      "[Epoch 214/500] [Batch 0/469] [D loss: 0.4888] [G loss: 1.4144]\n",
      "[Epoch 214/500] [Batch 100/469] [D loss: 0.5288] [G loss: 1.3959]\n",
      "[Epoch 214/500] [Batch 200/469] [D loss: 0.5007] [G loss: 1.4122]\n",
      "[Epoch 214/500] [Batch 300/469] [D loss: 0.4629] [G loss: 1.6629]\n",
      "[Epoch 214/500] [Batch 400/469] [D loss: 0.5304] [G loss: 1.3788]\n",
      "[Epoch 215/500] [Batch 0/469] [D loss: 0.5035] [G loss: 1.3159]\n",
      "[Epoch 215/500] [Batch 100/469] [D loss: 0.4900] [G loss: 1.3400]\n",
      "[Epoch 215/500] [Batch 200/469] [D loss: 0.5154] [G loss: 1.2230]\n",
      "[Epoch 215/500] [Batch 300/469] [D loss: 0.5057] [G loss: 0.9913]\n",
      "[Epoch 215/500] [Batch 400/469] [D loss: 0.5247] [G loss: 1.4228]\n",
      "[Epoch 216/500] [Batch 0/469] [D loss: 0.5104] [G loss: 1.2479]\n",
      "[Epoch 216/500] [Batch 100/469] [D loss: 0.5832] [G loss: 0.6994]\n",
      "[Epoch 216/500] [Batch 200/469] [D loss: 0.5237] [G loss: 0.9611]\n",
      "[Epoch 216/500] [Batch 300/469] [D loss: 0.5489] [G loss: 1.3083]\n",
      "[Epoch 216/500] [Batch 400/469] [D loss: 0.4744] [G loss: 1.2300]\n",
      "[Epoch 217/500] [Batch 0/469] [D loss: 0.5111] [G loss: 1.6027]\n",
      "[Epoch 217/500] [Batch 100/469] [D loss: 0.6332] [G loss: 0.7583]\n",
      "[Epoch 217/500] [Batch 200/469] [D loss: 0.5034] [G loss: 1.2495]\n",
      "[Epoch 217/500] [Batch 300/469] [D loss: 0.4896] [G loss: 0.9792]\n",
      "[Epoch 217/500] [Batch 400/469] [D loss: 0.5029] [G loss: 1.2468]\n",
      "[Epoch 218/500] [Batch 0/469] [D loss: 0.5238] [G loss: 0.8631]\n",
      "[Epoch 218/500] [Batch 100/469] [D loss: 0.5054] [G loss: 1.4909]\n",
      "[Epoch 218/500] [Batch 200/469] [D loss: 0.4933] [G loss: 1.1562]\n",
      "[Epoch 218/500] [Batch 300/469] [D loss: 0.5201] [G loss: 1.1762]\n",
      "[Epoch 218/500] [Batch 400/469] [D loss: 0.5097] [G loss: 1.3243]\n",
      "[Epoch 219/500] [Batch 0/469] [D loss: 0.5489] [G loss: 0.9889]\n",
      "[Epoch 219/500] [Batch 100/469] [D loss: 0.4983] [G loss: 1.8902]\n",
      "[Epoch 219/500] [Batch 200/469] [D loss: 0.4930] [G loss: 1.1311]\n",
      "[Epoch 219/500] [Batch 300/469] [D loss: 0.5668] [G loss: 1.4954]\n",
      "[Epoch 219/500] [Batch 400/469] [D loss: 0.6062] [G loss: 0.8332]\n",
      "[Epoch 219/500] [FID score: 30.8069]\n",
      "[Epoch 220/500] [Batch 0/469] [D loss: 0.5475] [G loss: 1.6964]\n",
      "[Epoch 220/500] [Batch 100/469] [D loss: 0.4755] [G loss: 1.3767]\n",
      "[Epoch 220/500] [Batch 200/469] [D loss: 0.5084] [G loss: 1.2938]\n",
      "[Epoch 220/500] [Batch 300/469] [D loss: 0.5180] [G loss: 1.4978]\n",
      "[Epoch 220/500] [Batch 400/469] [D loss: 0.5505] [G loss: 1.0017]\n",
      "[Epoch 221/500] [Batch 0/469] [D loss: 0.5139] [G loss: 0.9275]\n",
      "[Epoch 221/500] [Batch 100/469] [D loss: 0.5020] [G loss: 1.4214]\n",
      "[Epoch 221/500] [Batch 200/469] [D loss: 0.5555] [G loss: 1.6316]\n",
      "[Epoch 221/500] [Batch 300/469] [D loss: 0.5810] [G loss: 0.8107]\n",
      "[Epoch 221/500] [Batch 400/469] [D loss: 0.5551] [G loss: 1.5345]\n",
      "[Epoch 222/500] [Batch 0/469] [D loss: 0.5816] [G loss: 0.8101]\n",
      "[Epoch 222/500] [Batch 100/469] [D loss: 0.4706] [G loss: 1.0884]\n",
      "[Epoch 222/500] [Batch 200/469] [D loss: 0.4832] [G loss: 1.1119]\n",
      "[Epoch 222/500] [Batch 300/469] [D loss: 0.5412] [G loss: 1.8800]\n",
      "[Epoch 222/500] [Batch 400/469] [D loss: 0.5164] [G loss: 1.3355]\n",
      "[Epoch 223/500] [Batch 0/469] [D loss: 0.4865] [G loss: 1.3934]\n",
      "[Epoch 223/500] [Batch 100/469] [D loss: 0.5305] [G loss: 1.5341]\n",
      "[Epoch 223/500] [Batch 200/469] [D loss: 0.4871] [G loss: 1.2606]\n",
      "[Epoch 223/500] [Batch 300/469] [D loss: 0.4809] [G loss: 1.3443]\n",
      "[Epoch 223/500] [Batch 400/469] [D loss: 0.4838] [G loss: 1.6154]\n",
      "[Epoch 224/500] [Batch 0/469] [D loss: 0.5225] [G loss: 1.1702]\n",
      "[Epoch 224/500] [Batch 100/469] [D loss: 0.4838] [G loss: 1.5783]\n",
      "[Epoch 224/500] [Batch 200/469] [D loss: 0.5524] [G loss: 1.1681]\n",
      "[Epoch 224/500] [Batch 300/469] [D loss: 0.4952] [G loss: 1.2909]\n",
      "[Epoch 224/500] [Batch 400/469] [D loss: 0.5502] [G loss: 0.8992]\n",
      "[Epoch 225/500] [Batch 0/469] [D loss: 0.4916] [G loss: 1.0628]\n",
      "[Epoch 225/500] [Batch 100/469] [D loss: 0.5441] [G loss: 0.8245]\n",
      "[Epoch 225/500] [Batch 200/469] [D loss: 0.4679] [G loss: 1.2946]\n",
      "[Epoch 225/500] [Batch 300/469] [D loss: 0.4672] [G loss: 1.1616]\n",
      "[Epoch 225/500] [Batch 400/469] [D loss: 0.5405] [G loss: 0.9334]\n",
      "[Epoch 226/500] [Batch 0/469] [D loss: 0.4580] [G loss: 1.2045]\n",
      "[Epoch 226/500] [Batch 100/469] [D loss: 0.5055] [G loss: 1.2153]\n",
      "[Epoch 226/500] [Batch 200/469] [D loss: 0.4503] [G loss: 1.5020]\n",
      "[Epoch 226/500] [Batch 300/469] [D loss: 0.5873] [G loss: 0.7608]\n",
      "[Epoch 226/500] [Batch 400/469] [D loss: 0.4802] [G loss: 1.3929]\n",
      "[Epoch 227/500] [Batch 0/469] [D loss: 0.4841] [G loss: 1.5545]\n",
      "[Epoch 227/500] [Batch 100/469] [D loss: 0.4398] [G loss: 1.4604]\n",
      "[Epoch 227/500] [Batch 200/469] [D loss: 0.4935] [G loss: 1.5391]\n",
      "[Epoch 227/500] [Batch 300/469] [D loss: 0.5243] [G loss: 1.2111]\n",
      "[Epoch 227/500] [Batch 400/469] [D loss: 0.5148] [G loss: 1.7418]\n",
      "[Epoch 228/500] [Batch 0/469] [D loss: 0.4963] [G loss: 1.2946]\n",
      "[Epoch 228/500] [Batch 100/469] [D loss: 0.5343] [G loss: 0.8503]\n",
      "[Epoch 228/500] [Batch 200/469] [D loss: 0.4805] [G loss: 1.3328]\n",
      "[Epoch 228/500] [Batch 300/469] [D loss: 0.5787] [G loss: 2.0614]\n",
      "[Epoch 228/500] [Batch 400/469] [D loss: 0.5789] [G loss: 0.8370]\n",
      "[Epoch 229/500] [Batch 0/469] [D loss: 0.5054] [G loss: 1.2180]\n",
      "[Epoch 229/500] [Batch 100/469] [D loss: 0.6182] [G loss: 0.7030]\n",
      "[Epoch 229/500] [Batch 200/469] [D loss: 0.4895] [G loss: 0.9475]\n",
      "[Epoch 229/500] [Batch 300/469] [D loss: 0.5916] [G loss: 0.8427]\n",
      "[Epoch 229/500] [Batch 400/469] [D loss: 0.5433] [G loss: 1.6082]\n",
      "[Epoch 229/500] [FID score: 29.1831]\n",
      "[Epoch 230/500] [Batch 0/469] [D loss: 0.5133] [G loss: 1.0049]\n",
      "[Epoch 230/500] [Batch 100/469] [D loss: 0.4726] [G loss: 1.3333]\n",
      "[Epoch 230/500] [Batch 200/469] [D loss: 0.5048] [G loss: 0.9896]\n",
      "[Epoch 230/500] [Batch 300/469] [D loss: 0.4609] [G loss: 1.4769]\n",
      "[Epoch 230/500] [Batch 400/469] [D loss: 0.5069] [G loss: 1.3975]\n",
      "[Epoch 231/500] [Batch 0/469] [D loss: 0.4988] [G loss: 1.5855]\n",
      "[Epoch 231/500] [Batch 100/469] [D loss: 0.4987] [G loss: 1.0222]\n",
      "[Epoch 231/500] [Batch 200/469] [D loss: 0.5262] [G loss: 0.9847]\n",
      "[Epoch 231/500] [Batch 300/469] [D loss: 0.5244] [G loss: 1.2455]\n",
      "[Epoch 231/500] [Batch 400/469] [D loss: 0.4934] [G loss: 1.2030]\n",
      "[Epoch 232/500] [Batch 0/469] [D loss: 0.4626] [G loss: 1.3862]\n",
      "[Epoch 232/500] [Batch 100/469] [D loss: 0.4824] [G loss: 1.1809]\n",
      "[Epoch 232/500] [Batch 200/469] [D loss: 0.4936] [G loss: 1.4598]\n",
      "[Epoch 232/500] [Batch 300/469] [D loss: 0.4595] [G loss: 1.3049]\n",
      "[Epoch 232/500] [Batch 400/469] [D loss: 0.5161] [G loss: 1.1473]\n",
      "[Epoch 233/500] [Batch 0/469] [D loss: 0.4682] [G loss: 1.2815]\n",
      "[Epoch 233/500] [Batch 100/469] [D loss: 0.5200] [G loss: 0.9320]\n",
      "[Epoch 233/500] [Batch 200/469] [D loss: 0.5345] [G loss: 0.9460]\n",
      "[Epoch 233/500] [Batch 300/469] [D loss: 0.4985] [G loss: 1.0805]\n",
      "[Epoch 233/500] [Batch 400/469] [D loss: 0.4716] [G loss: 1.4224]\n",
      "[Epoch 234/500] [Batch 0/469] [D loss: 0.5545] [G loss: 0.7470]\n",
      "[Epoch 234/500] [Batch 100/469] [D loss: 0.5799] [G loss: 1.9764]\n",
      "[Epoch 234/500] [Batch 200/469] [D loss: 0.5434] [G loss: 0.7359]\n",
      "[Epoch 234/500] [Batch 300/469] [D loss: 0.5630] [G loss: 0.8530]\n",
      "[Epoch 234/500] [Batch 400/469] [D loss: 0.4387] [G loss: 1.2954]\n",
      "[Epoch 235/500] [Batch 0/469] [D loss: 0.5004] [G loss: 1.3465]\n",
      "[Epoch 235/500] [Batch 100/469] [D loss: 0.4748] [G loss: 1.0486]\n",
      "[Epoch 235/500] [Batch 200/469] [D loss: 0.5122] [G loss: 0.9889]\n",
      "[Epoch 235/500] [Batch 300/469] [D loss: 0.4887] [G loss: 1.3282]\n",
      "[Epoch 235/500] [Batch 400/469] [D loss: 0.5605] [G loss: 0.8547]\n",
      "[Epoch 236/500] [Batch 0/469] [D loss: 0.5558] [G loss: 1.9229]\n",
      "[Epoch 236/500] [Batch 100/469] [D loss: 0.4899] [G loss: 1.7315]\n",
      "[Epoch 236/500] [Batch 200/469] [D loss: 0.4292] [G loss: 1.4387]\n",
      "[Epoch 236/500] [Batch 300/469] [D loss: 0.4701] [G loss: 1.4809]\n",
      "[Epoch 236/500] [Batch 400/469] [D loss: 0.4685] [G loss: 1.4665]\n",
      "[Epoch 237/500] [Batch 0/469] [D loss: 0.6036] [G loss: 2.0189]\n",
      "[Epoch 237/500] [Batch 100/469] [D loss: 0.4803] [G loss: 1.4205]\n",
      "[Epoch 237/500] [Batch 200/469] [D loss: 0.4956] [G loss: 1.1652]\n",
      "[Epoch 237/500] [Batch 300/469] [D loss: 0.4836] [G loss: 1.3140]\n",
      "[Epoch 237/500] [Batch 400/469] [D loss: 0.5696] [G loss: 1.5185]\n",
      "[Epoch 238/500] [Batch 0/469] [D loss: 0.4751] [G loss: 1.3886]\n",
      "[Epoch 238/500] [Batch 100/469] [D loss: 0.4813] [G loss: 1.1943]\n",
      "[Epoch 238/500] [Batch 200/469] [D loss: 0.5223] [G loss: 0.9972]\n",
      "[Epoch 238/500] [Batch 300/469] [D loss: 0.5547] [G loss: 1.6860]\n",
      "[Epoch 238/500] [Batch 400/469] [D loss: 0.5174] [G loss: 1.5009]\n",
      "[Epoch 239/500] [Batch 0/469] [D loss: 0.5149] [G loss: 1.1296]\n",
      "[Epoch 239/500] [Batch 100/469] [D loss: 0.4850] [G loss: 1.4293]\n",
      "[Epoch 239/500] [Batch 200/469] [D loss: 0.5138] [G loss: 1.5171]\n",
      "[Epoch 239/500] [Batch 300/469] [D loss: 0.5069] [G loss: 1.7303]\n",
      "[Epoch 239/500] [Batch 400/469] [D loss: 0.5397] [G loss: 1.6056]\n",
      "[Epoch 239/500] [FID score: 29.2054]\n",
      "[Epoch 240/500] [Batch 0/469] [D loss: 0.4960] [G loss: 1.1583]\n",
      "[Epoch 240/500] [Batch 100/469] [D loss: 0.4993] [G loss: 1.0228]\n",
      "[Epoch 240/500] [Batch 200/469] [D loss: 0.5032] [G loss: 1.3499]\n",
      "[Epoch 240/500] [Batch 300/469] [D loss: 0.5391] [G loss: 1.2787]\n",
      "[Epoch 240/500] [Batch 400/469] [D loss: 0.5132] [G loss: 1.2040]\n",
      "[Epoch 241/500] [Batch 0/469] [D loss: 0.5343] [G loss: 1.5096]\n",
      "[Epoch 241/500] [Batch 100/469] [D loss: 0.4871] [G loss: 1.1232]\n",
      "[Epoch 241/500] [Batch 200/469] [D loss: 0.4295] [G loss: 1.4896]\n",
      "[Epoch 241/500] [Batch 300/469] [D loss: 0.5171] [G loss: 1.2866]\n",
      "[Epoch 241/500] [Batch 400/469] [D loss: 0.4755] [G loss: 1.2167]\n",
      "[Epoch 242/500] [Batch 0/469] [D loss: 0.5356] [G loss: 0.9424]\n",
      "[Epoch 242/500] [Batch 100/469] [D loss: 0.4890] [G loss: 1.3045]\n",
      "[Epoch 242/500] [Batch 200/469] [D loss: 0.5477] [G loss: 0.8377]\n",
      "[Epoch 242/500] [Batch 300/469] [D loss: 0.4918] [G loss: 1.2863]\n",
      "[Epoch 242/500] [Batch 400/469] [D loss: 0.4839] [G loss: 1.1155]\n",
      "[Epoch 243/500] [Batch 0/469] [D loss: 0.4758] [G loss: 1.0280]\n",
      "[Epoch 243/500] [Batch 100/469] [D loss: 0.4776] [G loss: 1.2381]\n",
      "[Epoch 243/500] [Batch 200/469] [D loss: 0.4878] [G loss: 1.3557]\n",
      "[Epoch 243/500] [Batch 300/469] [D loss: 0.5236] [G loss: 1.6666]\n",
      "[Epoch 243/500] [Batch 400/469] [D loss: 0.5073] [G loss: 0.8788]\n",
      "[Epoch 244/500] [Batch 0/469] [D loss: 0.4737] [G loss: 1.2951]\n",
      "[Epoch 244/500] [Batch 100/469] [D loss: 0.5135] [G loss: 1.3624]\n",
      "[Epoch 244/500] [Batch 200/469] [D loss: 0.5305] [G loss: 1.4475]\n",
      "[Epoch 244/500] [Batch 300/469] [D loss: 0.5092] [G loss: 1.2176]\n",
      "[Epoch 244/500] [Batch 400/469] [D loss: 0.4991] [G loss: 1.4586]\n",
      "[Epoch 245/500] [Batch 0/469] [D loss: 0.5114] [G loss: 1.0078]\n",
      "[Epoch 245/500] [Batch 100/469] [D loss: 0.5219] [G loss: 1.0697]\n",
      "[Epoch 245/500] [Batch 200/469] [D loss: 0.5429] [G loss: 1.5252]\n",
      "[Epoch 245/500] [Batch 300/469] [D loss: 0.4693] [G loss: 1.0875]\n",
      "[Epoch 245/500] [Batch 400/469] [D loss: 0.4879] [G loss: 1.3687]\n",
      "[Epoch 246/500] [Batch 0/469] [D loss: 0.4826] [G loss: 1.1669]\n",
      "[Epoch 246/500] [Batch 100/469] [D loss: 0.5050] [G loss: 1.5233]\n",
      "[Epoch 246/500] [Batch 200/469] [D loss: 0.5361] [G loss: 1.5905]\n",
      "[Epoch 246/500] [Batch 300/469] [D loss: 0.5110] [G loss: 1.1412]\n",
      "[Epoch 246/500] [Batch 400/469] [D loss: 0.4820] [G loss: 1.2129]\n",
      "[Epoch 247/500] [Batch 0/469] [D loss: 0.5129] [G loss: 1.3481]\n",
      "[Epoch 247/500] [Batch 100/469] [D loss: 0.6252] [G loss: 0.6420]\n",
      "[Epoch 247/500] [Batch 200/469] [D loss: 0.5082] [G loss: 1.3304]\n",
      "[Epoch 247/500] [Batch 300/469] [D loss: 0.5670] [G loss: 1.4779]\n",
      "[Epoch 247/500] [Batch 400/469] [D loss: 0.5036] [G loss: 1.3070]\n",
      "[Epoch 248/500] [Batch 0/469] [D loss: 0.5209] [G loss: 2.0257]\n",
      "[Epoch 248/500] [Batch 100/469] [D loss: 0.4995] [G loss: 1.0704]\n",
      "[Epoch 248/500] [Batch 200/469] [D loss: 0.5156] [G loss: 1.4344]\n",
      "[Epoch 248/500] [Batch 300/469] [D loss: 0.5022] [G loss: 1.1125]\n",
      "[Epoch 248/500] [Batch 400/469] [D loss: 0.5406] [G loss: 1.8315]\n",
      "[Epoch 249/500] [Batch 0/469] [D loss: 0.4642] [G loss: 1.5074]\n",
      "[Epoch 249/500] [Batch 100/469] [D loss: 0.4906] [G loss: 1.5624]\n",
      "[Epoch 249/500] [Batch 200/469] [D loss: 0.4867] [G loss: 1.5080]\n",
      "[Epoch 249/500] [Batch 300/469] [D loss: 0.4920] [G loss: 0.9781]\n",
      "[Epoch 249/500] [Batch 400/469] [D loss: 0.5039] [G loss: 1.6840]\n",
      "[Epoch 249/500] [FID score: 29.0220]\n",
      "[Epoch 250/500] [Batch 0/469] [D loss: 0.5182] [G loss: 1.6029]\n",
      "[Epoch 250/500] [Batch 100/469] [D loss: 0.5222] [G loss: 1.5214]\n",
      "[Epoch 250/500] [Batch 200/469] [D loss: 0.4926] [G loss: 1.1559]\n",
      "[Epoch 250/500] [Batch 300/469] [D loss: 0.4478] [G loss: 1.8917]\n",
      "[Epoch 250/500] [Batch 400/469] [D loss: 0.5069] [G loss: 1.0425]\n",
      "[Epoch 251/500] [Batch 0/469] [D loss: 0.5130] [G loss: 1.0674]\n",
      "[Epoch 251/500] [Batch 100/469] [D loss: 0.4596] [G loss: 1.4381]\n",
      "[Epoch 251/500] [Batch 200/469] [D loss: 0.4832] [G loss: 1.3785]\n",
      "[Epoch 251/500] [Batch 300/469] [D loss: 0.4842] [G loss: 1.5174]\n",
      "[Epoch 251/500] [Batch 400/469] [D loss: 0.5076] [G loss: 1.5991]\n",
      "[Epoch 252/500] [Batch 0/469] [D loss: 0.4829] [G loss: 1.2484]\n",
      "[Epoch 252/500] [Batch 100/469] [D loss: 0.5021] [G loss: 1.6613]\n",
      "[Epoch 252/500] [Batch 200/469] [D loss: 0.5453] [G loss: 1.0073]\n",
      "[Epoch 252/500] [Batch 300/469] [D loss: 0.4731] [G loss: 1.1587]\n",
      "[Epoch 252/500] [Batch 400/469] [D loss: 0.5747] [G loss: 0.8549]\n",
      "[Epoch 253/500] [Batch 0/469] [D loss: 0.4951] [G loss: 1.4109]\n",
      "[Epoch 253/500] [Batch 100/469] [D loss: 0.5074] [G loss: 1.1510]\n",
      "[Epoch 253/500] [Batch 200/469] [D loss: 0.5336] [G loss: 0.8656]\n",
      "[Epoch 253/500] [Batch 300/469] [D loss: 0.4915] [G loss: 1.2319]\n",
      "[Epoch 253/500] [Batch 400/469] [D loss: 0.4512] [G loss: 1.2262]\n",
      "[Epoch 254/500] [Batch 0/469] [D loss: 0.4872] [G loss: 1.2273]\n",
      "[Epoch 254/500] [Batch 100/469] [D loss: 0.4918] [G loss: 1.0289]\n",
      "[Epoch 254/500] [Batch 200/469] [D loss: 0.4800] [G loss: 1.1175]\n",
      "[Epoch 254/500] [Batch 300/469] [D loss: 0.4769] [G loss: 1.4471]\n",
      "[Epoch 254/500] [Batch 400/469] [D loss: 0.5930] [G loss: 0.8157]\n",
      "[Epoch 255/500] [Batch 0/469] [D loss: 0.5510] [G loss: 0.8840]\n",
      "[Epoch 255/500] [Batch 100/469] [D loss: 0.5108] [G loss: 0.9719]\n",
      "[Epoch 255/500] [Batch 200/469] [D loss: 0.4437] [G loss: 1.5480]\n",
      "[Epoch 255/500] [Batch 300/469] [D loss: 0.4977] [G loss: 1.7091]\n",
      "[Epoch 255/500] [Batch 400/469] [D loss: 0.5039] [G loss: 1.3886]\n",
      "[Epoch 256/500] [Batch 0/469] [D loss: 0.4368] [G loss: 1.4299]\n",
      "[Epoch 256/500] [Batch 100/469] [D loss: 0.5040] [G loss: 1.1778]\n",
      "[Epoch 256/500] [Batch 200/469] [D loss: 0.5163] [G loss: 1.0228]\n",
      "[Epoch 256/500] [Batch 300/469] [D loss: 0.4920] [G loss: 1.4784]\n",
      "[Epoch 256/500] [Batch 400/469] [D loss: 0.5930] [G loss: 0.8320]\n",
      "[Epoch 257/500] [Batch 0/469] [D loss: 0.4658] [G loss: 1.0881]\n",
      "[Epoch 257/500] [Batch 100/469] [D loss: 0.4998] [G loss: 1.5723]\n",
      "[Epoch 257/500] [Batch 200/469] [D loss: 0.4830] [G loss: 1.4053]\n",
      "[Epoch 257/500] [Batch 300/469] [D loss: 0.5888] [G loss: 0.7683]\n",
      "[Epoch 257/500] [Batch 400/469] [D loss: 0.4615] [G loss: 1.2399]\n",
      "[Epoch 258/500] [Batch 0/469] [D loss: 0.4531] [G loss: 1.4825]\n",
      "[Epoch 258/500] [Batch 100/469] [D loss: 0.5054] [G loss: 1.1170]\n",
      "[Epoch 258/500] [Batch 200/469] [D loss: 0.5657] [G loss: 0.8006]\n",
      "[Epoch 258/500] [Batch 300/469] [D loss: 0.4959] [G loss: 1.4395]\n",
      "[Epoch 258/500] [Batch 400/469] [D loss: 0.5085] [G loss: 1.1640]\n",
      "[Epoch 259/500] [Batch 0/469] [D loss: 0.5684] [G loss: 1.0553]\n",
      "[Epoch 259/500] [Batch 100/469] [D loss: 0.4618] [G loss: 1.2243]\n",
      "[Epoch 259/500] [Batch 200/469] [D loss: 0.4688] [G loss: 1.4798]\n",
      "[Epoch 259/500] [Batch 300/469] [D loss: 0.4663] [G loss: 1.2719]\n",
      "[Epoch 259/500] [Batch 400/469] [D loss: 0.4960] [G loss: 1.0588]\n",
      "[Epoch 259/500] [FID score: 28.8878]\n",
      "[Epoch 260/500] [Batch 0/469] [D loss: 0.4789] [G loss: 1.5223]\n",
      "[Epoch 260/500] [Batch 100/469] [D loss: 0.4552] [G loss: 1.6954]\n",
      "[Epoch 260/500] [Batch 200/469] [D loss: 0.5155] [G loss: 1.0337]\n",
      "[Epoch 260/500] [Batch 300/469] [D loss: 0.4732] [G loss: 1.2879]\n",
      "[Epoch 260/500] [Batch 400/469] [D loss: 0.4781] [G loss: 0.9954]\n",
      "[Epoch 261/500] [Batch 0/469] [D loss: 0.5006] [G loss: 1.0439]\n",
      "[Epoch 261/500] [Batch 100/469] [D loss: 0.4727] [G loss: 1.7275]\n",
      "[Epoch 261/500] [Batch 200/469] [D loss: 0.4877] [G loss: 1.6154]\n",
      "[Epoch 261/500] [Batch 300/469] [D loss: 0.4998] [G loss: 1.5753]\n",
      "[Epoch 261/500] [Batch 400/469] [D loss: 0.4149] [G loss: 1.4478]\n",
      "[Epoch 262/500] [Batch 0/469] [D loss: 0.4917] [G loss: 1.5514]\n",
      "[Epoch 262/500] [Batch 100/469] [D loss: 0.5003] [G loss: 1.2120]\n",
      "[Epoch 262/500] [Batch 200/469] [D loss: 0.4435] [G loss: 1.5011]\n",
      "[Epoch 262/500] [Batch 300/469] [D loss: 0.5389] [G loss: 1.1203]\n",
      "[Epoch 262/500] [Batch 400/469] [D loss: 0.6320] [G loss: 0.6772]\n",
      "[Epoch 263/500] [Batch 0/469] [D loss: 0.4928] [G loss: 1.4991]\n",
      "[Epoch 263/500] [Batch 100/469] [D loss: 0.4791] [G loss: 1.8011]\n",
      "[Epoch 263/500] [Batch 200/469] [D loss: 0.5173] [G loss: 1.0282]\n",
      "[Epoch 263/500] [Batch 300/469] [D loss: 0.4865] [G loss: 1.6388]\n",
      "[Epoch 263/500] [Batch 400/469] [D loss: 0.5079] [G loss: 1.1871]\n",
      "[Epoch 264/500] [Batch 0/469] [D loss: 0.5308] [G loss: 2.0179]\n",
      "[Epoch 264/500] [Batch 100/469] [D loss: 0.4726] [G loss: 1.4024]\n",
      "[Epoch 264/500] [Batch 200/469] [D loss: 0.4669] [G loss: 1.5044]\n",
      "[Epoch 264/500] [Batch 300/469] [D loss: 0.4566] [G loss: 1.3569]\n",
      "[Epoch 264/500] [Batch 400/469] [D loss: 0.4579] [G loss: 1.5988]\n",
      "[Epoch 265/500] [Batch 0/469] [D loss: 0.4827] [G loss: 1.8554]\n",
      "[Epoch 265/500] [Batch 100/469] [D loss: 0.5200] [G loss: 1.1871]\n",
      "[Epoch 265/500] [Batch 200/469] [D loss: 0.4853] [G loss: 1.5020]\n",
      "[Epoch 265/500] [Batch 300/469] [D loss: 0.5105] [G loss: 0.8496]\n",
      "[Epoch 265/500] [Batch 400/469] [D loss: 0.4618] [G loss: 1.2944]\n",
      "[Epoch 266/500] [Batch 0/469] [D loss: 0.4462] [G loss: 1.3712]\n",
      "[Epoch 266/500] [Batch 100/469] [D loss: 0.4888] [G loss: 1.0318]\n",
      "[Epoch 266/500] [Batch 200/469] [D loss: 0.5207] [G loss: 0.8916]\n",
      "[Epoch 266/500] [Batch 300/469] [D loss: 0.4659] [G loss: 1.1722]\n",
      "[Epoch 266/500] [Batch 400/469] [D loss: 0.5233] [G loss: 1.5546]\n",
      "[Epoch 267/500] [Batch 0/469] [D loss: 0.4862] [G loss: 1.1498]\n",
      "[Epoch 267/500] [Batch 100/469] [D loss: 0.4707] [G loss: 1.4022]\n",
      "[Epoch 267/500] [Batch 200/469] [D loss: 0.4439] [G loss: 1.4037]\n",
      "[Epoch 267/500] [Batch 300/469] [D loss: 0.4654] [G loss: 1.5337]\n",
      "[Epoch 267/500] [Batch 400/469] [D loss: 0.4719] [G loss: 0.9895]\n",
      "[Epoch 268/500] [Batch 0/469] [D loss: 0.5349] [G loss: 0.9848]\n",
      "[Epoch 268/500] [Batch 100/469] [D loss: 0.4914] [G loss: 1.1621]\n",
      "[Epoch 268/500] [Batch 200/469] [D loss: 0.4456] [G loss: 1.6311]\n",
      "[Epoch 268/500] [Batch 300/469] [D loss: 0.4154] [G loss: 1.4920]\n",
      "[Epoch 268/500] [Batch 400/469] [D loss: 0.5172] [G loss: 1.4919]\n",
      "[Epoch 269/500] [Batch 0/469] [D loss: 0.4780] [G loss: 1.0002]\n",
      "[Epoch 269/500] [Batch 100/469] [D loss: 0.4724] [G loss: 1.4387]\n",
      "[Epoch 269/500] [Batch 200/469] [D loss: 0.4332] [G loss: 1.4423]\n",
      "[Epoch 269/500] [Batch 300/469] [D loss: 0.5205] [G loss: 1.7265]\n",
      "[Epoch 269/500] [Batch 400/469] [D loss: 0.5762] [G loss: 0.8779]\n",
      "[Epoch 269/500] [FID score: 28.2923]\n",
      "[Epoch 270/500] [Batch 0/469] [D loss: 0.4372] [G loss: 1.2676]\n",
      "[Epoch 270/500] [Batch 100/469] [D loss: 0.4715] [G loss: 1.3874]\n",
      "[Epoch 270/500] [Batch 200/469] [D loss: 0.4878] [G loss: 1.0831]\n",
      "[Epoch 270/500] [Batch 300/469] [D loss: 0.5025] [G loss: 1.1959]\n",
      "[Epoch 270/500] [Batch 400/469] [D loss: 0.4650] [G loss: 1.5778]\n",
      "[Epoch 271/500] [Batch 0/469] [D loss: 0.5066] [G loss: 1.4262]\n",
      "[Epoch 271/500] [Batch 100/469] [D loss: 0.4463] [G loss: 1.3537]\n",
      "[Epoch 271/500] [Batch 200/469] [D loss: 0.5007] [G loss: 1.2861]\n",
      "[Epoch 271/500] [Batch 300/469] [D loss: 0.5575] [G loss: 1.1684]\n",
      "[Epoch 271/500] [Batch 400/469] [D loss: 0.5176] [G loss: 1.1947]\n",
      "[Epoch 272/500] [Batch 0/469] [D loss: 0.4342] [G loss: 1.7018]\n",
      "[Epoch 272/500] [Batch 100/469] [D loss: 0.4725] [G loss: 1.5746]\n",
      "[Epoch 272/500] [Batch 200/469] [D loss: 0.4870] [G loss: 1.3574]\n",
      "[Epoch 272/500] [Batch 300/469] [D loss: 0.4957] [G loss: 1.2620]\n",
      "[Epoch 272/500] [Batch 400/469] [D loss: 0.4653] [G loss: 1.4647]\n",
      "[Epoch 273/500] [Batch 0/469] [D loss: 0.5481] [G loss: 0.9030]\n",
      "[Epoch 273/500] [Batch 100/469] [D loss: 0.5207] [G loss: 1.1433]\n",
      "[Epoch 273/500] [Batch 200/469] [D loss: 0.4845] [G loss: 1.6743]\n",
      "[Epoch 273/500] [Batch 300/469] [D loss: 0.4941] [G loss: 1.0029]\n",
      "[Epoch 273/500] [Batch 400/469] [D loss: 0.4737] [G loss: 1.0683]\n",
      "[Epoch 274/500] [Batch 0/469] [D loss: 0.4563] [G loss: 1.4054]\n",
      "[Epoch 274/500] [Batch 100/469] [D loss: 0.5078] [G loss: 1.1125]\n",
      "[Epoch 274/500] [Batch 200/469] [D loss: 0.4163] [G loss: 1.4430]\n",
      "[Epoch 274/500] [Batch 300/469] [D loss: 0.5166] [G loss: 1.6714]\n",
      "[Epoch 274/500] [Batch 400/469] [D loss: 0.5563] [G loss: 1.0365]\n",
      "[Epoch 275/500] [Batch 0/469] [D loss: 0.4512] [G loss: 1.4363]\n",
      "[Epoch 275/500] [Batch 100/469] [D loss: 0.5198] [G loss: 1.2104]\n",
      "[Epoch 275/500] [Batch 200/469] [D loss: 0.4665] [G loss: 1.0724]\n",
      "[Epoch 275/500] [Batch 300/469] [D loss: 0.4604] [G loss: 1.5015]\n",
      "[Epoch 275/500] [Batch 400/469] [D loss: 0.4792] [G loss: 1.0828]\n",
      "[Epoch 276/500] [Batch 0/469] [D loss: 0.4985] [G loss: 1.0903]\n",
      "[Epoch 276/500] [Batch 100/469] [D loss: 0.4785] [G loss: 1.7605]\n",
      "[Epoch 276/500] [Batch 200/469] [D loss: 0.4593] [G loss: 1.3902]\n",
      "[Epoch 276/500] [Batch 300/469] [D loss: 0.5279] [G loss: 1.3865]\n",
      "[Epoch 276/500] [Batch 400/469] [D loss: 0.5240] [G loss: 1.9383]\n",
      "[Epoch 277/500] [Batch 0/469] [D loss: 0.4803] [G loss: 1.4507]\n",
      "[Epoch 277/500] [Batch 100/469] [D loss: 0.4291] [G loss: 1.4264]\n",
      "[Epoch 277/500] [Batch 200/469] [D loss: 0.4544] [G loss: 1.1508]\n",
      "[Epoch 277/500] [Batch 300/469] [D loss: 0.4834] [G loss: 1.1944]\n",
      "[Epoch 277/500] [Batch 400/469] [D loss: 0.4564] [G loss: 1.1588]\n",
      "[Epoch 278/500] [Batch 0/469] [D loss: 0.4089] [G loss: 1.3678]\n",
      "[Epoch 278/500] [Batch 100/469] [D loss: 0.4913] [G loss: 1.6106]\n",
      "[Epoch 278/500] [Batch 200/469] [D loss: 0.4828] [G loss: 1.2186]\n",
      "[Epoch 278/500] [Batch 300/469] [D loss: 0.5189] [G loss: 1.2369]\n",
      "[Epoch 278/500] [Batch 400/469] [D loss: 0.5849] [G loss: 1.8656]\n",
      "[Epoch 279/500] [Batch 0/469] [D loss: 0.4513] [G loss: 1.3179]\n",
      "[Epoch 279/500] [Batch 100/469] [D loss: 0.5897] [G loss: 1.1764]\n",
      "[Epoch 279/500] [Batch 200/469] [D loss: 0.4839] [G loss: 1.2295]\n",
      "[Epoch 279/500] [Batch 300/469] [D loss: 0.4109] [G loss: 1.4998]\n",
      "[Epoch 279/500] [Batch 400/469] [D loss: 0.5082] [G loss: 1.8585]\n",
      "[Epoch 279/500] [FID score: 27.5910]\n",
      "[Epoch 280/500] [Batch 0/469] [D loss: 0.4518] [G loss: 1.1789]\n",
      "[Epoch 280/500] [Batch 100/469] [D loss: 0.4582] [G loss: 1.3422]\n",
      "[Epoch 280/500] [Batch 200/469] [D loss: 0.5341] [G loss: 1.9024]\n",
      "[Epoch 280/500] [Batch 300/469] [D loss: 0.4858] [G loss: 1.8019]\n",
      "[Epoch 280/500] [Batch 400/469] [D loss: 0.5120] [G loss: 1.1255]\n",
      "[Epoch 281/500] [Batch 0/469] [D loss: 0.4737] [G loss: 1.9411]\n",
      "[Epoch 281/500] [Batch 100/469] [D loss: 0.4284] [G loss: 1.5521]\n",
      "[Epoch 281/500] [Batch 200/469] [D loss: 0.5314] [G loss: 1.8685]\n",
      "[Epoch 281/500] [Batch 300/469] [D loss: 0.5215] [G loss: 0.9984]\n",
      "[Epoch 281/500] [Batch 400/469] [D loss: 0.4733] [G loss: 1.7167]\n",
      "[Epoch 282/500] [Batch 0/469] [D loss: 0.5355] [G loss: 1.7139]\n",
      "[Epoch 282/500] [Batch 100/469] [D loss: 0.4539] [G loss: 1.1885]\n",
      "[Epoch 282/500] [Batch 200/469] [D loss: 0.5458] [G loss: 1.0141]\n",
      "[Epoch 282/500] [Batch 300/469] [D loss: 0.4516] [G loss: 1.5145]\n",
      "[Epoch 282/500] [Batch 400/469] [D loss: 0.4993] [G loss: 1.4945]\n",
      "[Epoch 283/500] [Batch 0/469] [D loss: 0.5222] [G loss: 1.8614]\n",
      "[Epoch 283/500] [Batch 100/469] [D loss: 0.4818] [G loss: 1.7666]\n",
      "[Epoch 283/500] [Batch 200/469] [D loss: 0.4952] [G loss: 1.5712]\n",
      "[Epoch 283/500] [Batch 300/469] [D loss: 0.4431] [G loss: 1.6283]\n",
      "[Epoch 283/500] [Batch 400/469] [D loss: 0.5114] [G loss: 1.6085]\n",
      "[Epoch 284/500] [Batch 0/469] [D loss: 0.4596] [G loss: 1.1716]\n",
      "[Epoch 284/500] [Batch 100/469] [D loss: 0.4786] [G loss: 1.6190]\n",
      "[Epoch 284/500] [Batch 200/469] [D loss: 0.4860] [G loss: 1.1083]\n",
      "[Epoch 284/500] [Batch 300/469] [D loss: 0.4758] [G loss: 1.1386]\n",
      "[Epoch 284/500] [Batch 400/469] [D loss: 0.4130] [G loss: 1.1410]\n",
      "[Epoch 285/500] [Batch 0/469] [D loss: 0.5476] [G loss: 0.8268]\n",
      "[Epoch 285/500] [Batch 100/469] [D loss: 0.4873] [G loss: 0.9879]\n",
      "[Epoch 285/500] [Batch 200/469] [D loss: 0.4830] [G loss: 1.1967]\n",
      "[Epoch 285/500] [Batch 300/469] [D loss: 0.5066] [G loss: 1.5518]\n",
      "[Epoch 285/500] [Batch 400/469] [D loss: 0.4291] [G loss: 1.3800]\n",
      "[Epoch 286/500] [Batch 0/469] [D loss: 0.4599] [G loss: 1.1928]\n",
      "[Epoch 286/500] [Batch 100/469] [D loss: 0.4875] [G loss: 1.7277]\n",
      "[Epoch 286/500] [Batch 200/469] [D loss: 0.4645] [G loss: 1.5944]\n",
      "[Epoch 286/500] [Batch 300/469] [D loss: 0.4494] [G loss: 1.3887]\n",
      "[Epoch 286/500] [Batch 400/469] [D loss: 0.5024] [G loss: 1.4963]\n",
      "[Epoch 287/500] [Batch 0/469] [D loss: 0.4408] [G loss: 1.0606]\n",
      "[Epoch 287/500] [Batch 100/469] [D loss: 0.4940] [G loss: 1.8483]\n",
      "[Epoch 287/500] [Batch 200/469] [D loss: 0.4696] [G loss: 1.6196]\n",
      "[Epoch 287/500] [Batch 300/469] [D loss: 0.4682] [G loss: 1.1545]\n",
      "[Epoch 287/500] [Batch 400/469] [D loss: 0.4353] [G loss: 1.4284]\n",
      "[Epoch 288/500] [Batch 0/469] [D loss: 0.4928] [G loss: 1.0746]\n",
      "[Epoch 288/500] [Batch 100/469] [D loss: 0.4694] [G loss: 1.3828]\n",
      "[Epoch 288/500] [Batch 200/469] [D loss: 0.4891] [G loss: 1.2187]\n",
      "[Epoch 288/500] [Batch 300/469] [D loss: 0.5074] [G loss: 0.9916]\n",
      "[Epoch 288/500] [Batch 400/469] [D loss: 0.4818] [G loss: 1.4145]\n",
      "[Epoch 289/500] [Batch 0/469] [D loss: 0.4726] [G loss: 1.1930]\n",
      "[Epoch 289/500] [Batch 100/469] [D loss: 0.5777] [G loss: 2.0837]\n",
      "[Epoch 289/500] [Batch 200/469] [D loss: 0.4959] [G loss: 1.3466]\n",
      "[Epoch 289/500] [Batch 300/469] [D loss: 0.4289] [G loss: 1.3661]\n",
      "[Epoch 289/500] [Batch 400/469] [D loss: 0.4089] [G loss: 1.6921]\n",
      "[Epoch 289/500] [FID score: 28.8311]\n",
      "[Epoch 290/500] [Batch 0/469] [D loss: 0.4645] [G loss: 1.2406]\n",
      "[Epoch 290/500] [Batch 100/469] [D loss: 0.5042] [G loss: 0.9233]\n",
      "[Epoch 290/500] [Batch 200/469] [D loss: 0.4886] [G loss: 1.4503]\n",
      "[Epoch 290/500] [Batch 300/469] [D loss: 0.4518] [G loss: 1.6437]\n",
      "[Epoch 290/500] [Batch 400/469] [D loss: 0.4883] [G loss: 1.3204]\n",
      "[Epoch 291/500] [Batch 0/469] [D loss: 0.5024] [G loss: 1.2539]\n",
      "[Epoch 291/500] [Batch 100/469] [D loss: 0.4765] [G loss: 1.2893]\n",
      "[Epoch 291/500] [Batch 200/469] [D loss: 0.4720] [G loss: 1.0735]\n",
      "[Epoch 291/500] [Batch 300/469] [D loss: 0.4675] [G loss: 1.1581]\n",
      "[Epoch 291/500] [Batch 400/469] [D loss: 0.4965] [G loss: 1.3911]\n",
      "[Epoch 292/500] [Batch 0/469] [D loss: 0.5083] [G loss: 1.2103]\n",
      "[Epoch 292/500] [Batch 100/469] [D loss: 0.4823] [G loss: 1.3534]\n",
      "[Epoch 292/500] [Batch 200/469] [D loss: 0.4392] [G loss: 1.3093]\n",
      "[Epoch 292/500] [Batch 300/469] [D loss: 0.4457] [G loss: 1.4059]\n",
      "[Epoch 292/500] [Batch 400/469] [D loss: 0.5100] [G loss: 1.8711]\n",
      "[Epoch 293/500] [Batch 0/469] [D loss: 0.4549] [G loss: 1.1922]\n",
      "[Epoch 293/500] [Batch 100/469] [D loss: 0.4395] [G loss: 1.2511]\n",
      "[Epoch 293/500] [Batch 200/469] [D loss: 0.4467] [G loss: 1.2821]\n",
      "[Epoch 293/500] [Batch 300/469] [D loss: 0.5044] [G loss: 1.0713]\n",
      "[Epoch 293/500] [Batch 400/469] [D loss: 0.4705] [G loss: 1.6078]\n",
      "[Epoch 294/500] [Batch 0/469] [D loss: 0.4529] [G loss: 1.3850]\n",
      "[Epoch 294/500] [Batch 100/469] [D loss: 0.4423] [G loss: 1.2065]\n",
      "[Epoch 294/500] [Batch 200/469] [D loss: 0.4804] [G loss: 1.5866]\n",
      "[Epoch 294/500] [Batch 300/469] [D loss: 0.4102] [G loss: 1.5465]\n",
      "[Epoch 294/500] [Batch 400/469] [D loss: 0.4906] [G loss: 1.6689]\n",
      "[Epoch 295/500] [Batch 0/469] [D loss: 0.4944] [G loss: 1.0926]\n",
      "[Epoch 295/500] [Batch 100/469] [D loss: 0.4754] [G loss: 1.5280]\n",
      "[Epoch 295/500] [Batch 200/469] [D loss: 0.4651] [G loss: 1.5409]\n",
      "[Epoch 295/500] [Batch 300/469] [D loss: 0.4723] [G loss: 1.2467]\n",
      "[Epoch 295/500] [Batch 400/469] [D loss: 0.4641] [G loss: 1.5318]\n",
      "[Epoch 296/500] [Batch 0/469] [D loss: 0.4792] [G loss: 1.1667]\n",
      "[Epoch 296/500] [Batch 100/469] [D loss: 0.4678] [G loss: 1.6900]\n",
      "[Epoch 296/500] [Batch 200/469] [D loss: 0.5276] [G loss: 1.1757]\n",
      "[Epoch 296/500] [Batch 300/469] [D loss: 0.5012] [G loss: 2.0810]\n",
      "[Epoch 296/500] [Batch 400/469] [D loss: 0.4585] [G loss: 1.2676]\n",
      "[Epoch 297/500] [Batch 0/469] [D loss: 0.4532] [G loss: 1.6064]\n",
      "[Epoch 297/500] [Batch 100/469] [D loss: 0.4843] [G loss: 1.8994]\n",
      "[Epoch 297/500] [Batch 200/469] [D loss: 0.4895] [G loss: 1.0595]\n",
      "[Epoch 297/500] [Batch 300/469] [D loss: 0.5405] [G loss: 2.0696]\n",
      "[Epoch 297/500] [Batch 400/469] [D loss: 0.4921] [G loss: 0.9960]\n",
      "[Epoch 298/500] [Batch 0/469] [D loss: 0.4398] [G loss: 1.2803]\n",
      "[Epoch 298/500] [Batch 100/469] [D loss: 0.4843] [G loss: 1.7592]\n",
      "[Epoch 298/500] [Batch 200/469] [D loss: 0.4766] [G loss: 1.3363]\n",
      "[Epoch 298/500] [Batch 300/469] [D loss: 0.5106] [G loss: 1.0871]\n",
      "[Epoch 298/500] [Batch 400/469] [D loss: 0.4934] [G loss: 1.2655]\n",
      "[Epoch 299/500] [Batch 0/469] [D loss: 0.4771] [G loss: 0.9796]\n",
      "[Epoch 299/500] [Batch 100/469] [D loss: 0.5062] [G loss: 1.1722]\n",
      "[Epoch 299/500] [Batch 200/469] [D loss: 0.4800] [G loss: 1.6212]\n",
      "[Epoch 299/500] [Batch 300/469] [D loss: 0.4352] [G loss: 1.3053]\n",
      "[Epoch 299/500] [Batch 400/469] [D loss: 0.4933] [G loss: 1.5292]\n",
      "[Epoch 299/500] [FID score: 29.6187]\n",
      "[Epoch 300/500] [Batch 0/469] [D loss: 0.3891] [G loss: 1.5261]\n",
      "[Epoch 300/500] [Batch 100/469] [D loss: 0.4466] [G loss: 1.4701]\n",
      "[Epoch 300/500] [Batch 200/469] [D loss: 0.4394] [G loss: 1.7365]\n",
      "[Epoch 300/500] [Batch 300/469] [D loss: 0.4554] [G loss: 1.5301]\n",
      "[Epoch 300/500] [Batch 400/469] [D loss: 0.4765] [G loss: 1.9345]\n",
      "[Epoch 301/500] [Batch 0/469] [D loss: 0.5089] [G loss: 1.0403]\n",
      "[Epoch 301/500] [Batch 100/469] [D loss: 0.4240] [G loss: 1.8673]\n",
      "[Epoch 301/500] [Batch 200/469] [D loss: 0.4631] [G loss: 1.7108]\n",
      "[Epoch 301/500] [Batch 300/469] [D loss: 0.4500] [G loss: 1.5983]\n",
      "[Epoch 301/500] [Batch 400/469] [D loss: 0.4465] [G loss: 1.6112]\n",
      "[Epoch 302/500] [Batch 0/469] [D loss: 0.4324] [G loss: 1.1735]\n",
      "[Epoch 302/500] [Batch 100/469] [D loss: 0.5622] [G loss: 0.8511]\n",
      "[Epoch 302/500] [Batch 200/469] [D loss: 0.4898] [G loss: 1.4577]\n",
      "[Epoch 302/500] [Batch 300/469] [D loss: 0.4608] [G loss: 1.0662]\n",
      "[Epoch 302/500] [Batch 400/469] [D loss: 0.4677] [G loss: 1.3797]\n",
      "[Epoch 303/500] [Batch 0/469] [D loss: 0.4695] [G loss: 1.2028]\n",
      "[Epoch 303/500] [Batch 100/469] [D loss: 0.4702] [G loss: 1.3576]\n",
      "[Epoch 303/500] [Batch 200/469] [D loss: 0.4650] [G loss: 1.8234]\n",
      "[Epoch 303/500] [Batch 300/469] [D loss: 0.4422] [G loss: 1.2033]\n",
      "[Epoch 303/500] [Batch 400/469] [D loss: 0.4635] [G loss: 1.9885]\n",
      "[Epoch 304/500] [Batch 0/469] [D loss: 0.4227] [G loss: 1.5688]\n",
      "[Epoch 304/500] [Batch 100/469] [D loss: 0.4742] [G loss: 2.0249]\n",
      "[Epoch 304/500] [Batch 200/469] [D loss: 0.4951] [G loss: 1.1059]\n",
      "[Epoch 304/500] [Batch 300/469] [D loss: 0.4747] [G loss: 1.3194]\n",
      "[Epoch 304/500] [Batch 400/469] [D loss: 0.5053] [G loss: 1.1216]\n",
      "[Epoch 305/500] [Batch 0/469] [D loss: 0.4356] [G loss: 1.7056]\n",
      "[Epoch 305/500] [Batch 100/469] [D loss: 0.4504] [G loss: 1.2541]\n",
      "[Epoch 305/500] [Batch 200/469] [D loss: 0.5185] [G loss: 1.5643]\n",
      "[Epoch 305/500] [Batch 300/469] [D loss: 0.4415] [G loss: 1.5396]\n",
      "[Epoch 305/500] [Batch 400/469] [D loss: 0.4253] [G loss: 1.4882]\n",
      "[Epoch 306/500] [Batch 0/469] [D loss: 0.4652] [G loss: 1.4604]\n",
      "[Epoch 306/500] [Batch 100/469] [D loss: 0.4915] [G loss: 1.2936]\n",
      "[Epoch 306/500] [Batch 200/469] [D loss: 0.4548] [G loss: 1.2826]\n",
      "[Epoch 306/500] [Batch 300/469] [D loss: 0.4811] [G loss: 1.2974]\n",
      "[Epoch 306/500] [Batch 400/469] [D loss: 0.4456] [G loss: 1.6428]\n",
      "[Epoch 307/500] [Batch 0/469] [D loss: 0.4511] [G loss: 1.2071]\n",
      "[Epoch 307/500] [Batch 100/469] [D loss: 0.4482] [G loss: 1.3751]\n",
      "[Epoch 307/500] [Batch 200/469] [D loss: 0.4323] [G loss: 1.5779]\n",
      "[Epoch 307/500] [Batch 300/469] [D loss: 0.4467] [G loss: 1.9417]\n",
      "[Epoch 307/500] [Batch 400/469] [D loss: 0.3906] [G loss: 1.3529]\n",
      "[Epoch 308/500] [Batch 0/469] [D loss: 0.4992] [G loss: 1.0828]\n",
      "[Epoch 308/500] [Batch 100/469] [D loss: 0.5222] [G loss: 1.8687]\n",
      "[Epoch 308/500] [Batch 200/469] [D loss: 0.4490] [G loss: 1.2387]\n",
      "[Epoch 308/500] [Batch 300/469] [D loss: 0.4652] [G loss: 1.1536]\n",
      "[Epoch 308/500] [Batch 400/469] [D loss: 0.5178] [G loss: 1.9498]\n",
      "[Epoch 309/500] [Batch 0/469] [D loss: 0.4946] [G loss: 1.4790]\n",
      "[Epoch 309/500] [Batch 100/469] [D loss: 0.5037] [G loss: 1.0681]\n",
      "[Epoch 309/500] [Batch 200/469] [D loss: 0.4892] [G loss: 1.0539]\n",
      "[Epoch 309/500] [Batch 300/469] [D loss: 0.4306] [G loss: 1.4549]\n",
      "[Epoch 309/500] [Batch 400/469] [D loss: 0.5244] [G loss: 1.2787]\n",
      "[Epoch 309/500] [FID score: 29.0571]\n",
      "[Epoch 310/500] [Batch 0/469] [D loss: 0.4249] [G loss: 1.2235]\n",
      "[Epoch 310/500] [Batch 100/469] [D loss: 0.4204] [G loss: 1.3836]\n",
      "[Epoch 310/500] [Batch 200/469] [D loss: 0.4344] [G loss: 1.4637]\n",
      "[Epoch 310/500] [Batch 300/469] [D loss: 0.4295] [G loss: 1.3927]\n",
      "[Epoch 310/500] [Batch 400/469] [D loss: 0.5334] [G loss: 0.9324]\n",
      "[Epoch 311/500] [Batch 0/469] [D loss: 0.4904] [G loss: 1.3369]\n",
      "[Epoch 311/500] [Batch 100/469] [D loss: 0.4810] [G loss: 1.0948]\n",
      "[Epoch 311/500] [Batch 200/469] [D loss: 0.4569] [G loss: 1.4458]\n",
      "[Epoch 311/500] [Batch 300/469] [D loss: 0.5175] [G loss: 1.6492]\n",
      "[Epoch 311/500] [Batch 400/469] [D loss: 0.4422] [G loss: 1.5940]\n",
      "[Epoch 312/500] [Batch 0/469] [D loss: 0.4527] [G loss: 1.1576]\n",
      "[Epoch 312/500] [Batch 100/469] [D loss: 0.4978] [G loss: 2.0033]\n",
      "[Epoch 312/500] [Batch 200/469] [D loss: 0.4435] [G loss: 1.6633]\n",
      "[Epoch 312/500] [Batch 300/469] [D loss: 0.4507] [G loss: 1.6629]\n",
      "[Epoch 312/500] [Batch 400/469] [D loss: 0.4414] [G loss: 1.1935]\n",
      "[Epoch 313/500] [Batch 0/469] [D loss: 0.4636] [G loss: 1.5048]\n",
      "[Epoch 313/500] [Batch 100/469] [D loss: 0.5892] [G loss: 0.7329]\n",
      "[Epoch 313/500] [Batch 200/469] [D loss: 0.4035] [G loss: 1.4198]\n",
      "[Epoch 313/500] [Batch 300/469] [D loss: 0.4224] [G loss: 1.1199]\n",
      "[Epoch 313/500] [Batch 400/469] [D loss: 0.4869] [G loss: 1.1675]\n",
      "[Epoch 314/500] [Batch 0/469] [D loss: 0.4786] [G loss: 1.3809]\n",
      "[Epoch 314/500] [Batch 100/469] [D loss: 0.5333] [G loss: 0.9520]\n",
      "[Epoch 314/500] [Batch 200/469] [D loss: 0.5152] [G loss: 0.9789]\n",
      "[Epoch 314/500] [Batch 300/469] [D loss: 0.4364] [G loss: 1.4396]\n",
      "[Epoch 314/500] [Batch 400/469] [D loss: 0.4373] [G loss: 1.3862]\n",
      "[Epoch 315/500] [Batch 0/469] [D loss: 0.4526] [G loss: 1.4679]\n",
      "[Epoch 315/500] [Batch 100/469] [D loss: 0.5452] [G loss: 1.5703]\n",
      "[Epoch 315/500] [Batch 200/469] [D loss: 0.4635] [G loss: 1.7175]\n",
      "[Epoch 315/500] [Batch 300/469] [D loss: 0.5165] [G loss: 2.0458]\n",
      "[Epoch 315/500] [Batch 400/469] [D loss: 0.5231] [G loss: 1.0152]\n",
      "[Epoch 316/500] [Batch 0/469] [D loss: 0.4460] [G loss: 1.2780]\n",
      "[Epoch 316/500] [Batch 100/469] [D loss: 0.4443] [G loss: 1.7651]\n",
      "[Epoch 316/500] [Batch 200/469] [D loss: 0.4716] [G loss: 1.8267]\n",
      "[Epoch 316/500] [Batch 300/469] [D loss: 0.4864] [G loss: 1.4458]\n",
      "[Epoch 316/500] [Batch 400/469] [D loss: 0.4299] [G loss: 1.4898]\n",
      "[Epoch 317/500] [Batch 0/469] [D loss: 0.4346] [G loss: 1.2817]\n",
      "[Epoch 317/500] [Batch 100/469] [D loss: 0.4492] [G loss: 1.3885]\n",
      "[Epoch 317/500] [Batch 200/469] [D loss: 0.4564] [G loss: 1.5580]\n",
      "[Epoch 317/500] [Batch 300/469] [D loss: 0.5285] [G loss: 0.9325]\n",
      "[Epoch 317/500] [Batch 400/469] [D loss: 0.5481] [G loss: 0.8833]\n",
      "[Epoch 318/500] [Batch 0/469] [D loss: 0.4572] [G loss: 1.7873]\n",
      "[Epoch 318/500] [Batch 100/469] [D loss: 0.4420] [G loss: 1.4628]\n",
      "[Epoch 318/500] [Batch 200/469] [D loss: 0.4369] [G loss: 1.6957]\n",
      "[Epoch 318/500] [Batch 300/469] [D loss: 0.6070] [G loss: 0.7345]\n",
      "[Epoch 318/500] [Batch 400/469] [D loss: 0.4838] [G loss: 1.4256]\n",
      "[Epoch 319/500] [Batch 0/469] [D loss: 0.5007] [G loss: 1.1417]\n",
      "[Epoch 319/500] [Batch 100/469] [D loss: 0.4562] [G loss: 1.6110]\n",
      "[Epoch 319/500] [Batch 200/469] [D loss: 0.5000] [G loss: 2.0084]\n",
      "[Epoch 319/500] [Batch 300/469] [D loss: 0.4195] [G loss: 1.6845]\n",
      "[Epoch 319/500] [Batch 400/469] [D loss: 0.5212] [G loss: 2.0019]\n",
      "[Epoch 319/500] [FID score: 28.0909]\n",
      "[Epoch 320/500] [Batch 0/469] [D loss: 0.4992] [G loss: 1.0611]\n",
      "[Epoch 320/500] [Batch 100/469] [D loss: 0.5395] [G loss: 0.8390]\n",
      "[Epoch 320/500] [Batch 200/469] [D loss: 0.4507] [G loss: 1.2571]\n",
      "[Epoch 320/500] [Batch 300/469] [D loss: 0.4190] [G loss: 1.8576]\n",
      "[Epoch 320/500] [Batch 400/469] [D loss: 0.4711] [G loss: 1.3957]\n",
      "[Epoch 321/500] [Batch 0/469] [D loss: 0.3986] [G loss: 1.6561]\n",
      "[Epoch 321/500] [Batch 100/469] [D loss: 0.4755] [G loss: 1.8252]\n",
      "[Epoch 321/500] [Batch 200/469] [D loss: 0.4516] [G loss: 1.7131]\n",
      "[Epoch 321/500] [Batch 300/469] [D loss: 0.5081] [G loss: 1.5920]\n",
      "[Epoch 321/500] [Batch 400/469] [D loss: 0.4773] [G loss: 1.4005]\n",
      "[Epoch 322/500] [Batch 0/469] [D loss: 0.4579] [G loss: 1.5612]\n",
      "[Epoch 322/500] [Batch 100/469] [D loss: 0.5504] [G loss: 1.0418]\n",
      "[Epoch 322/500] [Batch 200/469] [D loss: 0.4683] [G loss: 1.2881]\n",
      "[Epoch 322/500] [Batch 300/469] [D loss: 0.4233] [G loss: 1.2358]\n",
      "[Epoch 322/500] [Batch 400/469] [D loss: 0.4046] [G loss: 1.5317]\n",
      "[Epoch 323/500] [Batch 0/469] [D loss: 0.5136] [G loss: 1.0076]\n",
      "[Epoch 323/500] [Batch 100/469] [D loss: 0.4446] [G loss: 1.6978]\n",
      "[Epoch 323/500] [Batch 200/469] [D loss: 0.4689] [G loss: 1.4767]\n",
      "[Epoch 323/500] [Batch 300/469] [D loss: 0.4842] [G loss: 1.8279]\n",
      "[Epoch 323/500] [Batch 400/469] [D loss: 0.4116] [G loss: 1.3784]\n",
      "[Epoch 324/500] [Batch 0/469] [D loss: 0.4255] [G loss: 1.2062]\n",
      "[Epoch 324/500] [Batch 100/469] [D loss: 0.4400] [G loss: 1.5482]\n",
      "[Epoch 324/500] [Batch 200/469] [D loss: 0.5711] [G loss: 0.8819]\n",
      "[Epoch 324/500] [Batch 300/469] [D loss: 0.4451] [G loss: 1.3149]\n",
      "[Epoch 324/500] [Batch 400/469] [D loss: 0.4795] [G loss: 1.5977]\n",
      "[Epoch 325/500] [Batch 0/469] [D loss: 0.4786] [G loss: 2.0015]\n",
      "[Epoch 325/500] [Batch 100/469] [D loss: 0.4460] [G loss: 1.4793]\n",
      "[Epoch 325/500] [Batch 200/469] [D loss: 0.4479] [G loss: 1.2049]\n",
      "[Epoch 325/500] [Batch 300/469] [D loss: 0.4333] [G loss: 1.3008]\n",
      "[Epoch 325/500] [Batch 400/469] [D loss: 0.3990] [G loss: 1.4985]\n",
      "[Epoch 326/500] [Batch 0/469] [D loss: 0.4858] [G loss: 2.2780]\n",
      "[Epoch 326/500] [Batch 100/469] [D loss: 0.4164] [G loss: 1.4657]\n",
      "[Epoch 326/500] [Batch 200/469] [D loss: 0.4655] [G loss: 1.2232]\n",
      "[Epoch 326/500] [Batch 300/469] [D loss: 0.5013] [G loss: 1.9595]\n",
      "[Epoch 326/500] [Batch 400/469] [D loss: 0.5019] [G loss: 1.2876]\n",
      "[Epoch 327/500] [Batch 0/469] [D loss: 0.4306] [G loss: 1.2286]\n",
      "[Epoch 327/500] [Batch 100/469] [D loss: 0.4523] [G loss: 1.7574]\n",
      "[Epoch 327/500] [Batch 200/469] [D loss: 0.5055] [G loss: 1.1684]\n",
      "[Epoch 327/500] [Batch 300/469] [D loss: 0.4985] [G loss: 1.8576]\n",
      "[Epoch 327/500] [Batch 400/469] [D loss: 0.5018] [G loss: 1.2284]\n",
      "[Epoch 328/500] [Batch 0/469] [D loss: 0.4920] [G loss: 1.1647]\n",
      "[Epoch 328/500] [Batch 100/469] [D loss: 0.4639] [G loss: 1.8446]\n",
      "[Epoch 328/500] [Batch 200/469] [D loss: 0.6177] [G loss: 2.6803]\n",
      "[Epoch 328/500] [Batch 300/469] [D loss: 0.4916] [G loss: 1.1266]\n",
      "[Epoch 328/500] [Batch 400/469] [D loss: 0.4197] [G loss: 1.5750]\n",
      "[Epoch 329/500] [Batch 0/469] [D loss: 0.4319] [G loss: 1.6150]\n",
      "[Epoch 329/500] [Batch 100/469] [D loss: 0.4263] [G loss: 1.5336]\n",
      "[Epoch 329/500] [Batch 200/469] [D loss: 0.5290] [G loss: 2.0685]\n",
      "[Epoch 329/500] [Batch 300/469] [D loss: 0.4720] [G loss: 1.5391]\n",
      "[Epoch 329/500] [Batch 400/469] [D loss: 0.4426] [G loss: 1.5245]\n",
      "[Epoch 329/500] [FID score: 28.2438]\n",
      "[Epoch 330/500] [Batch 0/469] [D loss: 0.4466] [G loss: 1.3007]\n",
      "[Epoch 330/500] [Batch 100/469] [D loss: 0.4614] [G loss: 1.6605]\n",
      "[Epoch 330/500] [Batch 200/469] [D loss: 0.4318] [G loss: 1.2741]\n",
      "[Epoch 330/500] [Batch 300/469] [D loss: 0.4412] [G loss: 1.4329]\n",
      "[Epoch 330/500] [Batch 400/469] [D loss: 0.5207] [G loss: 1.5698]\n",
      "[Epoch 331/500] [Batch 0/469] [D loss: 0.4471] [G loss: 1.0715]\n",
      "[Epoch 331/500] [Batch 100/469] [D loss: 0.4799] [G loss: 1.1034]\n",
      "[Epoch 331/500] [Batch 200/469] [D loss: 0.4447] [G loss: 1.7423]\n",
      "[Epoch 331/500] [Batch 300/469] [D loss: 0.4664] [G loss: 1.3946]\n",
      "[Epoch 331/500] [Batch 400/469] [D loss: 0.4615] [G loss: 1.7574]\n",
      "[Epoch 332/500] [Batch 0/469] [D loss: 0.4800] [G loss: 1.6882]\n",
      "[Epoch 332/500] [Batch 100/469] [D loss: 0.4599] [G loss: 1.5609]\n",
      "[Epoch 332/500] [Batch 200/469] [D loss: 0.4741] [G loss: 1.8494]\n",
      "[Epoch 332/500] [Batch 300/469] [D loss: 0.4393] [G loss: 1.2727]\n",
      "[Epoch 332/500] [Batch 400/469] [D loss: 0.4995] [G loss: 1.2979]\n",
      "[Epoch 333/500] [Batch 0/469] [D loss: 0.4641] [G loss: 1.1882]\n",
      "[Epoch 333/500] [Batch 100/469] [D loss: 0.5096] [G loss: 1.7628]\n",
      "[Epoch 333/500] [Batch 200/469] [D loss: 0.4173] [G loss: 1.5719]\n",
      "[Epoch 333/500] [Batch 300/469] [D loss: 0.4475] [G loss: 1.4885]\n",
      "[Epoch 333/500] [Batch 400/469] [D loss: 0.5408] [G loss: 1.5951]\n",
      "[Epoch 334/500] [Batch 0/469] [D loss: 0.4574] [G loss: 1.3222]\n",
      "[Epoch 334/500] [Batch 100/469] [D loss: 0.4921] [G loss: 1.3133]\n",
      "[Epoch 334/500] [Batch 200/469] [D loss: 0.5142] [G loss: 0.9024]\n",
      "[Epoch 334/500] [Batch 300/469] [D loss: 0.5134] [G loss: 1.6098]\n",
      "[Epoch 334/500] [Batch 400/469] [D loss: 0.4345] [G loss: 1.3157]\n",
      "[Epoch 335/500] [Batch 0/469] [D loss: 0.5193] [G loss: 1.1251]\n",
      "[Epoch 335/500] [Batch 100/469] [D loss: 0.4333] [G loss: 1.5495]\n",
      "[Epoch 335/500] [Batch 200/469] [D loss: 0.4601] [G loss: 1.5451]\n",
      "[Epoch 335/500] [Batch 300/469] [D loss: 0.4471] [G loss: 1.4127]\n",
      "[Epoch 335/500] [Batch 400/469] [D loss: 0.4860] [G loss: 1.9757]\n",
      "[Epoch 336/500] [Batch 0/469] [D loss: 0.3946] [G loss: 1.4494]\n",
      "[Epoch 336/500] [Batch 100/469] [D loss: 0.4885] [G loss: 1.7756]\n",
      "[Epoch 336/500] [Batch 200/469] [D loss: 0.4950] [G loss: 1.3798]\n",
      "[Epoch 336/500] [Batch 300/469] [D loss: 0.5238] [G loss: 1.6869]\n",
      "[Epoch 336/500] [Batch 400/469] [D loss: 0.4303] [G loss: 1.7553]\n",
      "[Epoch 337/500] [Batch 0/469] [D loss: 0.6130] [G loss: 2.3636]\n",
      "[Epoch 337/500] [Batch 100/469] [D loss: 0.4490] [G loss: 1.9993]\n",
      "[Epoch 337/500] [Batch 200/469] [D loss: 0.4645] [G loss: 1.1990]\n",
      "[Epoch 337/500] [Batch 300/469] [D loss: 0.4526] [G loss: 1.1483]\n",
      "[Epoch 337/500] [Batch 400/469] [D loss: 0.4307] [G loss: 1.4025]\n",
      "[Epoch 338/500] [Batch 0/469] [D loss: 0.4243] [G loss: 1.6121]\n",
      "[Epoch 338/500] [Batch 100/469] [D loss: 0.4336] [G loss: 1.7182]\n",
      "[Epoch 338/500] [Batch 200/469] [D loss: 0.4741] [G loss: 1.3189]\n",
      "[Epoch 338/500] [Batch 300/469] [D loss: 0.5031] [G loss: 1.6317]\n",
      "[Epoch 338/500] [Batch 400/469] [D loss: 0.4086] [G loss: 1.7319]\n",
      "[Epoch 339/500] [Batch 0/469] [D loss: 0.4459] [G loss: 1.9933]\n",
      "[Epoch 339/500] [Batch 100/469] [D loss: 0.4802] [G loss: 1.3126]\n",
      "[Epoch 339/500] [Batch 200/469] [D loss: 0.4371] [G loss: 1.3505]\n",
      "[Epoch 339/500] [Batch 300/469] [D loss: 0.5341] [G loss: 1.8841]\n",
      "[Epoch 339/500] [Batch 400/469] [D loss: 0.4176] [G loss: 1.2123]\n",
      "[Epoch 339/500] [FID score: 27.9024]\n",
      "[Epoch 340/500] [Batch 0/469] [D loss: 0.4914] [G loss: 1.4492]\n",
      "[Epoch 340/500] [Batch 100/469] [D loss: 0.4250] [G loss: 1.3589]\n",
      "[Epoch 340/500] [Batch 200/469] [D loss: 0.4536] [G loss: 1.7143]\n",
      "[Epoch 340/500] [Batch 300/469] [D loss: 0.4566] [G loss: 1.6010]\n",
      "[Epoch 340/500] [Batch 400/469] [D loss: 0.5089] [G loss: 2.1840]\n",
      "[Epoch 341/500] [Batch 0/469] [D loss: 0.4397] [G loss: 1.4488]\n",
      "[Epoch 341/500] [Batch 100/469] [D loss: 0.5121] [G loss: 0.9412]\n",
      "[Epoch 341/500] [Batch 200/469] [D loss: 0.4322] [G loss: 1.5750]\n",
      "[Epoch 341/500] [Batch 300/469] [D loss: 0.4475] [G loss: 1.3137]\n",
      "[Epoch 341/500] [Batch 400/469] [D loss: 0.5042] [G loss: 1.4842]\n",
      "[Epoch 342/500] [Batch 0/469] [D loss: 0.4991] [G loss: 2.2719]\n",
      "[Epoch 342/500] [Batch 100/469] [D loss: 0.4364] [G loss: 1.4831]\n",
      "[Epoch 342/500] [Batch 200/469] [D loss: 0.4809] [G loss: 1.3787]\n",
      "[Epoch 342/500] [Batch 300/469] [D loss: 0.4581] [G loss: 1.1758]\n",
      "[Epoch 342/500] [Batch 400/469] [D loss: 0.4392] [G loss: 1.6411]\n",
      "[Epoch 343/500] [Batch 0/469] [D loss: 0.4258] [G loss: 1.4470]\n",
      "[Epoch 343/500] [Batch 100/469] [D loss: 0.4586] [G loss: 1.4891]\n",
      "[Epoch 343/500] [Batch 200/469] [D loss: 0.4548] [G loss: 1.6251]\n",
      "[Epoch 343/500] [Batch 300/469] [D loss: 0.4645] [G loss: 1.0787]\n",
      "[Epoch 343/500] [Batch 400/469] [D loss: 0.4711] [G loss: 1.6345]\n",
      "[Epoch 344/500] [Batch 0/469] [D loss: 0.4770] [G loss: 1.1948]\n",
      "[Epoch 344/500] [Batch 100/469] [D loss: 0.4372] [G loss: 1.6357]\n",
      "[Epoch 344/500] [Batch 200/469] [D loss: 0.4822] [G loss: 1.0542]\n",
      "[Epoch 344/500] [Batch 300/469] [D loss: 0.4043] [G loss: 1.5487]\n",
      "[Epoch 344/500] [Batch 400/469] [D loss: 0.4850] [G loss: 1.7066]\n",
      "[Epoch 345/500] [Batch 0/469] [D loss: 0.4626] [G loss: 1.4685]\n",
      "[Epoch 345/500] [Batch 100/469] [D loss: 0.4419] [G loss: 1.2629]\n",
      "[Epoch 345/500] [Batch 200/469] [D loss: 0.4527] [G loss: 1.9333]\n",
      "[Epoch 345/500] [Batch 300/469] [D loss: 0.4701] [G loss: 1.1461]\n",
      "[Epoch 345/500] [Batch 400/469] [D loss: 0.4331] [G loss: 1.9803]\n",
      "[Epoch 346/500] [Batch 0/469] [D loss: 0.4704] [G loss: 1.6271]\n",
      "[Epoch 346/500] [Batch 100/469] [D loss: 0.4983] [G loss: 1.0144]\n",
      "[Epoch 346/500] [Batch 200/469] [D loss: 0.4586] [G loss: 1.0900]\n",
      "[Epoch 346/500] [Batch 300/469] [D loss: 0.4108] [G loss: 1.5531]\n",
      "[Epoch 346/500] [Batch 400/469] [D loss: 0.4392] [G loss: 1.4966]\n",
      "[Epoch 347/500] [Batch 0/469] [D loss: 0.4569] [G loss: 2.0354]\n",
      "[Epoch 347/500] [Batch 100/469] [D loss: 0.4567] [G loss: 1.7244]\n",
      "[Epoch 347/500] [Batch 200/469] [D loss: 0.4450] [G loss: 1.2684]\n",
      "[Epoch 347/500] [Batch 300/469] [D loss: 0.4472] [G loss: 1.5243]\n",
      "[Epoch 347/500] [Batch 400/469] [D loss: 0.4620] [G loss: 1.2912]\n",
      "[Epoch 348/500] [Batch 0/469] [D loss: 0.4914] [G loss: 1.6506]\n",
      "[Epoch 348/500] [Batch 100/469] [D loss: 0.4850] [G loss: 1.5610]\n",
      "[Epoch 348/500] [Batch 200/469] [D loss: 0.4262] [G loss: 1.8774]\n",
      "[Epoch 348/500] [Batch 300/469] [D loss: 0.5461] [G loss: 2.1139]\n",
      "[Epoch 348/500] [Batch 400/469] [D loss: 0.4167] [G loss: 1.6752]\n",
      "[Epoch 349/500] [Batch 0/469] [D loss: 0.4837] [G loss: 1.0067]\n",
      "[Epoch 349/500] [Batch 100/469] [D loss: 0.4676] [G loss: 1.9918]\n",
      "[Epoch 349/500] [Batch 200/469] [D loss: 0.4135] [G loss: 1.8313]\n",
      "[Epoch 349/500] [Batch 300/469] [D loss: 0.3921] [G loss: 1.7347]\n",
      "[Epoch 349/500] [Batch 400/469] [D loss: 0.4798] [G loss: 1.3720]\n",
      "[Epoch 349/500] [FID score: 28.5554]\n",
      "[Epoch 350/500] [Batch 0/469] [D loss: 0.4845] [G loss: 1.1213]\n",
      "[Epoch 350/500] [Batch 100/469] [D loss: 0.4601] [G loss: 1.6249]\n",
      "[Epoch 350/500] [Batch 200/469] [D loss: 0.4379] [G loss: 1.8676]\n",
      "[Epoch 350/500] [Batch 300/469] [D loss: 0.4395] [G loss: 1.9285]\n",
      "[Epoch 350/500] [Batch 400/469] [D loss: 0.4786] [G loss: 1.6299]\n",
      "[Epoch 351/500] [Batch 0/469] [D loss: 0.4744] [G loss: 1.8534]\n",
      "[Epoch 351/500] [Batch 100/469] [D loss: 0.4928] [G loss: 1.1833]\n",
      "[Epoch 351/500] [Batch 200/469] [D loss: 0.4396] [G loss: 1.6523]\n",
      "[Epoch 351/500] [Batch 300/469] [D loss: 0.4463] [G loss: 1.2968]\n",
      "[Epoch 351/500] [Batch 400/469] [D loss: 0.4948] [G loss: 1.1971]\n",
      "[Epoch 352/500] [Batch 0/469] [D loss: 0.4611] [G loss: 1.9778]\n",
      "[Epoch 352/500] [Batch 100/469] [D loss: 0.4080] [G loss: 1.5086]\n",
      "[Epoch 352/500] [Batch 200/469] [D loss: 0.4498] [G loss: 1.5131]\n",
      "[Epoch 352/500] [Batch 300/469] [D loss: 0.4213] [G loss: 1.3289]\n",
      "[Epoch 352/500] [Batch 400/469] [D loss: 0.4808] [G loss: 1.5509]\n",
      "[Epoch 353/500] [Batch 0/469] [D loss: 0.4851] [G loss: 1.1755]\n",
      "[Epoch 353/500] [Batch 100/469] [D loss: 0.4618] [G loss: 1.5104]\n",
      "[Epoch 353/500] [Batch 200/469] [D loss: 0.5316] [G loss: 2.2746]\n",
      "[Epoch 353/500] [Batch 300/469] [D loss: 0.4591] [G loss: 1.0776]\n",
      "[Epoch 353/500] [Batch 400/469] [D loss: 0.4425] [G loss: 1.3282]\n",
      "[Epoch 354/500] [Batch 0/469] [D loss: 0.5563] [G loss: 0.8555]\n",
      "[Epoch 354/500] [Batch 100/469] [D loss: 0.4194] [G loss: 1.4739]\n",
      "[Epoch 354/500] [Batch 200/469] [D loss: 0.5398] [G loss: 2.1342]\n",
      "[Epoch 354/500] [Batch 300/469] [D loss: 0.3782] [G loss: 1.6587]\n",
      "[Epoch 354/500] [Batch 400/469] [D loss: 0.4345] [G loss: 1.3916]\n",
      "[Epoch 355/500] [Batch 0/469] [D loss: 0.4061] [G loss: 1.5790]\n",
      "[Epoch 355/500] [Batch 100/469] [D loss: 0.4465] [G loss: 1.4015]\n",
      "[Epoch 355/500] [Batch 200/469] [D loss: 0.4470] [G loss: 1.3348]\n",
      "[Epoch 355/500] [Batch 300/469] [D loss: 0.4319] [G loss: 1.3622]\n",
      "[Epoch 355/500] [Batch 400/469] [D loss: 0.4822] [G loss: 1.4573]\n",
      "[Epoch 356/500] [Batch 0/469] [D loss: 0.4561] [G loss: 1.4671]\n",
      "[Epoch 356/500] [Batch 100/469] [D loss: 0.4129] [G loss: 1.4549]\n",
      "[Epoch 356/500] [Batch 200/469] [D loss: 0.4452] [G loss: 1.6143]\n",
      "[Epoch 356/500] [Batch 300/469] [D loss: 0.4510] [G loss: 1.0703]\n",
      "[Epoch 356/500] [Batch 400/469] [D loss: 0.4565] [G loss: 1.1476]\n",
      "[Epoch 357/500] [Batch 0/469] [D loss: 0.4310] [G loss: 1.2617]\n",
      "[Epoch 357/500] [Batch 100/469] [D loss: 0.5552] [G loss: 0.9634]\n",
      "[Epoch 357/500] [Batch 200/469] [D loss: 0.5184] [G loss: 1.0059]\n",
      "[Epoch 357/500] [Batch 300/469] [D loss: 0.4479] [G loss: 1.8467]\n",
      "[Epoch 357/500] [Batch 400/469] [D loss: 0.4314] [G loss: 1.6190]\n",
      "[Epoch 358/500] [Batch 0/469] [D loss: 0.4198] [G loss: 1.7768]\n",
      "[Epoch 358/500] [Batch 100/469] [D loss: 0.4352] [G loss: 1.4534]\n",
      "[Epoch 358/500] [Batch 200/469] [D loss: 0.5622] [G loss: 2.0434]\n",
      "[Epoch 358/500] [Batch 300/469] [D loss: 0.4737] [G loss: 0.9872]\n",
      "[Epoch 358/500] [Batch 400/469] [D loss: 0.4440] [G loss: 1.5854]\n",
      "[Epoch 359/500] [Batch 0/469] [D loss: 0.4500] [G loss: 1.6251]\n",
      "[Epoch 359/500] [Batch 100/469] [D loss: 0.4609] [G loss: 1.2453]\n",
      "[Epoch 359/500] [Batch 200/469] [D loss: 0.4240] [G loss: 1.4379]\n",
      "[Epoch 359/500] [Batch 300/469] [D loss: 0.4108] [G loss: 1.4725]\n",
      "[Epoch 359/500] [Batch 400/469] [D loss: 0.4672] [G loss: 1.3509]\n",
      "[Epoch 359/500] [FID score: 28.5792]\n",
      "[Epoch 360/500] [Batch 0/469] [D loss: 0.4192] [G loss: 1.6804]\n",
      "[Epoch 360/500] [Batch 100/469] [D loss: 0.4325] [G loss: 1.4278]\n",
      "[Epoch 360/500] [Batch 200/469] [D loss: 0.4619] [G loss: 1.3277]\n",
      "[Epoch 360/500] [Batch 300/469] [D loss: 0.5363] [G loss: 1.0213]\n",
      "[Epoch 360/500] [Batch 400/469] [D loss: 0.4232] [G loss: 1.7824]\n",
      "[Epoch 361/500] [Batch 0/469] [D loss: 0.4327] [G loss: 1.8564]\n",
      "[Epoch 361/500] [Batch 100/469] [D loss: 0.4109] [G loss: 1.5940]\n",
      "[Epoch 361/500] [Batch 200/469] [D loss: 0.4323] [G loss: 1.2344]\n",
      "[Epoch 361/500] [Batch 300/469] [D loss: 0.4318] [G loss: 1.3763]\n",
      "[Epoch 361/500] [Batch 400/469] [D loss: 0.4157] [G loss: 1.5501]\n",
      "[Epoch 362/500] [Batch 0/469] [D loss: 0.5019] [G loss: 1.5587]\n",
      "[Epoch 362/500] [Batch 100/469] [D loss: 0.4384] [G loss: 1.7355]\n",
      "[Epoch 362/500] [Batch 200/469] [D loss: 0.4871] [G loss: 1.1005]\n",
      "[Epoch 362/500] [Batch 300/469] [D loss: 0.4005] [G loss: 1.9498]\n",
      "[Epoch 362/500] [Batch 400/469] [D loss: 0.4978] [G loss: 1.6242]\n",
      "[Epoch 363/500] [Batch 0/469] [D loss: 0.4238] [G loss: 1.2975]\n",
      "[Epoch 363/500] [Batch 100/469] [D loss: 0.3929] [G loss: 1.4742]\n",
      "[Epoch 363/500] [Batch 200/469] [D loss: 0.4314] [G loss: 1.5746]\n",
      "[Epoch 363/500] [Batch 300/469] [D loss: 0.3970] [G loss: 1.2931]\n",
      "[Epoch 363/500] [Batch 400/469] [D loss: 0.4447] [G loss: 1.2525]\n",
      "[Epoch 364/500] [Batch 0/469] [D loss: 0.4633] [G loss: 1.3698]\n",
      "[Epoch 364/500] [Batch 100/469] [D loss: 0.4004] [G loss: 1.5290]\n",
      "[Epoch 364/500] [Batch 200/469] [D loss: 0.4577] [G loss: 1.1572]\n",
      "[Epoch 364/500] [Batch 300/469] [D loss: 0.4310] [G loss: 1.2758]\n",
      "[Epoch 364/500] [Batch 400/469] [D loss: 0.4457] [G loss: 1.6930]\n",
      "[Epoch 365/500] [Batch 0/469] [D loss: 0.4555] [G loss: 1.7575]\n",
      "[Epoch 365/500] [Batch 100/469] [D loss: 0.4981] [G loss: 1.8402]\n",
      "[Epoch 365/500] [Batch 200/469] [D loss: 0.3997] [G loss: 1.6886]\n",
      "[Epoch 365/500] [Batch 300/469] [D loss: 0.4857] [G loss: 2.0131]\n",
      "[Epoch 365/500] [Batch 400/469] [D loss: 0.3822] [G loss: 1.3689]\n",
      "[Epoch 366/500] [Batch 0/469] [D loss: 0.3982] [G loss: 1.5621]\n",
      "[Epoch 366/500] [Batch 100/469] [D loss: 0.4420] [G loss: 1.3789]\n",
      "[Epoch 366/500] [Batch 200/469] [D loss: 0.4754] [G loss: 1.6678]\n",
      "[Epoch 366/500] [Batch 300/469] [D loss: 0.3704] [G loss: 1.6192]\n",
      "[Epoch 366/500] [Batch 400/469] [D loss: 0.4479] [G loss: 1.7312]\n",
      "[Epoch 367/500] [Batch 0/469] [D loss: 0.4435] [G loss: 1.7873]\n",
      "[Epoch 367/500] [Batch 100/469] [D loss: 0.4963] [G loss: 1.4103]\n",
      "[Epoch 367/500] [Batch 200/469] [D loss: 0.5256] [G loss: 2.0009]\n",
      "[Epoch 367/500] [Batch 300/469] [D loss: 0.5649] [G loss: 1.1902]\n",
      "[Epoch 367/500] [Batch 400/469] [D loss: 0.4125] [G loss: 1.4261]\n",
      "[Epoch 368/500] [Batch 0/469] [D loss: 0.4786] [G loss: 1.0765]\n",
      "[Epoch 368/500] [Batch 100/469] [D loss: 0.4088] [G loss: 1.8438]\n",
      "[Epoch 368/500] [Batch 200/469] [D loss: 0.4251] [G loss: 1.7350]\n",
      "[Epoch 368/500] [Batch 300/469] [D loss: 0.4713] [G loss: 1.2614]\n",
      "[Epoch 368/500] [Batch 400/469] [D loss: 0.4661] [G loss: 1.8218]\n",
      "[Epoch 369/500] [Batch 0/469] [D loss: 0.4922] [G loss: 1.5939]\n",
      "[Epoch 369/500] [Batch 100/469] [D loss: 0.3752] [G loss: 1.5056]\n",
      "[Epoch 369/500] [Batch 200/469] [D loss: 0.5877] [G loss: 0.8869]\n",
      "[Epoch 369/500] [Batch 300/469] [D loss: 0.5474] [G loss: 2.3321]\n",
      "[Epoch 369/500] [Batch 400/469] [D loss: 0.5178] [G loss: 1.3171]\n",
      "[Epoch 369/500] [FID score: 29.0790]\n",
      "[Epoch 370/500] [Batch 0/469] [D loss: 0.4165] [G loss: 1.8056]\n",
      "[Epoch 370/500] [Batch 100/469] [D loss: 0.3900] [G loss: 1.4773]\n",
      "[Epoch 370/500] [Batch 200/469] [D loss: 0.3897] [G loss: 1.7228]\n",
      "[Epoch 370/500] [Batch 300/469] [D loss: 0.4868] [G loss: 2.0094]\n",
      "[Epoch 370/500] [Batch 400/469] [D loss: 0.4977] [G loss: 1.1863]\n",
      "[Epoch 371/500] [Batch 0/469] [D loss: 0.4966] [G loss: 1.1714]\n",
      "[Epoch 371/500] [Batch 100/469] [D loss: 0.4709] [G loss: 1.5799]\n",
      "[Epoch 371/500] [Batch 200/469] [D loss: 0.4672] [G loss: 1.3366]\n",
      "[Epoch 371/500] [Batch 300/469] [D loss: 0.4630] [G loss: 1.9644]\n",
      "[Epoch 371/500] [Batch 400/469] [D loss: 0.5049] [G loss: 0.9345]\n",
      "[Epoch 372/500] [Batch 0/469] [D loss: 0.4308] [G loss: 1.5028]\n",
      "[Epoch 372/500] [Batch 100/469] [D loss: 0.5496] [G loss: 0.8631]\n",
      "[Epoch 372/500] [Batch 200/469] [D loss: 0.4096] [G loss: 1.7495]\n",
      "[Epoch 372/500] [Batch 300/469] [D loss: 0.5316] [G loss: 1.8252]\n",
      "[Epoch 372/500] [Batch 400/469] [D loss: 0.4758] [G loss: 2.0719]\n",
      "[Epoch 373/500] [Batch 0/469] [D loss: 0.4718] [G loss: 1.1798]\n",
      "[Epoch 373/500] [Batch 100/469] [D loss: 0.4539] [G loss: 1.7585]\n",
      "[Epoch 373/500] [Batch 200/469] [D loss: 0.4405] [G loss: 1.6989]\n",
      "[Epoch 373/500] [Batch 300/469] [D loss: 0.4475] [G loss: 1.5292]\n",
      "[Epoch 373/500] [Batch 400/469] [D loss: 0.4801] [G loss: 1.4113]\n",
      "[Epoch 374/500] [Batch 0/469] [D loss: 0.4381] [G loss: 1.3223]\n",
      "[Epoch 374/500] [Batch 100/469] [D loss: 0.4212] [G loss: 1.6992]\n",
      "[Epoch 374/500] [Batch 200/469] [D loss: 0.4394] [G loss: 1.7493]\n",
      "[Epoch 374/500] [Batch 300/469] [D loss: 0.4983] [G loss: 1.0434]\n",
      "[Epoch 374/500] [Batch 400/469] [D loss: 0.4355] [G loss: 2.1625]\n",
      "[Epoch 375/500] [Batch 0/469] [D loss: 0.3801] [G loss: 1.8116]\n",
      "[Epoch 375/500] [Batch 100/469] [D loss: 0.4154] [G loss: 1.7969]\n",
      "[Epoch 375/500] [Batch 200/469] [D loss: 0.4475] [G loss: 1.6898]\n",
      "[Epoch 375/500] [Batch 300/469] [D loss: 0.4657] [G loss: 1.7863]\n",
      "[Epoch 375/500] [Batch 400/469] [D loss: 0.4465] [G loss: 1.5119]\n",
      "[Epoch 376/500] [Batch 0/469] [D loss: 0.4369] [G loss: 1.9311]\n",
      "[Epoch 376/500] [Batch 100/469] [D loss: 0.4116] [G loss: 1.4754]\n",
      "[Epoch 376/500] [Batch 200/469] [D loss: 0.4332] [G loss: 1.2033]\n",
      "[Epoch 376/500] [Batch 300/469] [D loss: 0.3704] [G loss: 1.3734]\n",
      "[Epoch 376/500] [Batch 400/469] [D loss: 0.4677] [G loss: 1.5989]\n",
      "[Epoch 377/500] [Batch 0/469] [D loss: 0.4332] [G loss: 1.1577]\n",
      "[Epoch 377/500] [Batch 100/469] [D loss: 0.4377] [G loss: 1.2972]\n",
      "[Epoch 377/500] [Batch 200/469] [D loss: 0.4485] [G loss: 1.9015]\n",
      "[Epoch 377/500] [Batch 300/469] [D loss: 0.4346] [G loss: 1.7222]\n",
      "[Epoch 377/500] [Batch 400/469] [D loss: 0.4663] [G loss: 1.5044]\n",
      "[Epoch 378/500] [Batch 0/469] [D loss: 0.3981] [G loss: 1.5737]\n",
      "[Epoch 378/500] [Batch 100/469] [D loss: 0.4719] [G loss: 1.1726]\n",
      "[Epoch 378/500] [Batch 200/469] [D loss: 0.4468] [G loss: 1.4011]\n",
      "[Epoch 378/500] [Batch 300/469] [D loss: 0.4304] [G loss: 2.1429]\n",
      "[Epoch 378/500] [Batch 400/469] [D loss: 0.4993] [G loss: 1.2565]\n",
      "[Epoch 379/500] [Batch 0/469] [D loss: 0.4218] [G loss: 1.6141]\n",
      "[Epoch 379/500] [Batch 100/469] [D loss: 0.4396] [G loss: 1.4128]\n",
      "[Epoch 379/500] [Batch 200/469] [D loss: 0.4939] [G loss: 1.1302]\n",
      "[Epoch 379/500] [Batch 300/469] [D loss: 0.4056] [G loss: 1.4361]\n",
      "[Epoch 379/500] [Batch 400/469] [D loss: 0.4879] [G loss: 1.1929]\n",
      "[Epoch 379/500] [FID score: 27.7532]\n",
      "[Epoch 380/500] [Batch 0/469] [D loss: 0.3603] [G loss: 1.9498]\n",
      "[Epoch 380/500] [Batch 100/469] [D loss: 0.4612] [G loss: 1.3120]\n",
      "[Epoch 380/500] [Batch 200/469] [D loss: 0.4441] [G loss: 1.7206]\n",
      "[Epoch 380/500] [Batch 300/469] [D loss: 0.3986] [G loss: 1.5312]\n",
      "[Epoch 380/500] [Batch 400/469] [D loss: 0.4064] [G loss: 2.0899]\n",
      "[Epoch 381/500] [Batch 0/469] [D loss: 0.4992] [G loss: 1.1157]\n",
      "[Epoch 381/500] [Batch 100/469] [D loss: 0.4309] [G loss: 1.9717]\n",
      "[Epoch 381/500] [Batch 200/469] [D loss: 0.4246] [G loss: 1.4870]\n",
      "[Epoch 381/500] [Batch 300/469] [D loss: 0.4683] [G loss: 1.5577]\n",
      "[Epoch 381/500] [Batch 400/469] [D loss: 0.4321] [G loss: 1.5504]\n",
      "[Epoch 382/500] [Batch 0/469] [D loss: 0.4223] [G loss: 1.3678]\n",
      "[Epoch 382/500] [Batch 100/469] [D loss: 0.3821] [G loss: 1.6178]\n",
      "[Epoch 382/500] [Batch 200/469] [D loss: 0.4672] [G loss: 1.2379]\n",
      "[Epoch 382/500] [Batch 300/469] [D loss: 0.4405] [G loss: 1.8261]\n",
      "[Epoch 382/500] [Batch 400/469] [D loss: 0.4717] [G loss: 1.9372]\n",
      "[Epoch 383/500] [Batch 0/469] [D loss: 0.4289] [G loss: 2.2252]\n",
      "[Epoch 383/500] [Batch 100/469] [D loss: 0.4075] [G loss: 1.7607]\n",
      "[Epoch 383/500] [Batch 200/469] [D loss: 0.4656] [G loss: 1.2719]\n",
      "[Epoch 383/500] [Batch 300/469] [D loss: 0.4276] [G loss: 1.3751]\n",
      "[Epoch 383/500] [Batch 400/469] [D loss: 0.5318] [G loss: 1.2272]\n",
      "[Epoch 384/500] [Batch 0/469] [D loss: 0.4945] [G loss: 2.1569]\n",
      "[Epoch 384/500] [Batch 100/469] [D loss: 0.4662] [G loss: 1.7897]\n",
      "[Epoch 384/500] [Batch 200/469] [D loss: 0.4315] [G loss: 1.8055]\n",
      "[Epoch 384/500] [Batch 300/469] [D loss: 0.5378] [G loss: 1.0036]\n",
      "[Epoch 384/500] [Batch 400/469] [D loss: 0.4191] [G loss: 1.5699]\n",
      "[Epoch 385/500] [Batch 0/469] [D loss: 0.4688] [G loss: 1.2572]\n",
      "[Epoch 385/500] [Batch 100/469] [D loss: 0.4052] [G loss: 1.9558]\n",
      "[Epoch 385/500] [Batch 200/469] [D loss: 0.4307] [G loss: 1.5677]\n",
      "[Epoch 385/500] [Batch 300/469] [D loss: 0.4232] [G loss: 1.2108]\n",
      "[Epoch 385/500] [Batch 400/469] [D loss: 0.3623] [G loss: 1.7999]\n",
      "[Epoch 386/500] [Batch 0/469] [D loss: 0.4053] [G loss: 1.5941]\n",
      "[Epoch 386/500] [Batch 100/469] [D loss: 0.4569] [G loss: 1.4056]\n",
      "[Epoch 386/500] [Batch 200/469] [D loss: 0.4488] [G loss: 1.1614]\n",
      "[Epoch 386/500] [Batch 300/469] [D loss: 0.4663] [G loss: 1.4171]\n",
      "[Epoch 386/500] [Batch 400/469] [D loss: 0.5073] [G loss: 1.3199]\n",
      "[Epoch 387/500] [Batch 0/469] [D loss: 0.4257] [G loss: 1.7055]\n",
      "[Epoch 387/500] [Batch 100/469] [D loss: 0.5078] [G loss: 1.7259]\n",
      "[Epoch 387/500] [Batch 200/469] [D loss: 0.4335] [G loss: 1.4224]\n",
      "[Epoch 387/500] [Batch 300/469] [D loss: 0.4543] [G loss: 1.2065]\n",
      "[Epoch 387/500] [Batch 400/469] [D loss: 0.3804] [G loss: 1.6007]\n",
      "[Epoch 388/500] [Batch 0/469] [D loss: 0.4201] [G loss: 1.9275]\n",
      "[Epoch 388/500] [Batch 100/469] [D loss: 0.4220] [G loss: 1.5683]\n",
      "[Epoch 388/500] [Batch 200/469] [D loss: 0.4354] [G loss: 2.1694]\n",
      "[Epoch 388/500] [Batch 300/469] [D loss: 0.4573] [G loss: 1.3770]\n",
      "[Epoch 388/500] [Batch 400/469] [D loss: 0.5034] [G loss: 2.0677]\n",
      "[Epoch 389/500] [Batch 0/469] [D loss: 0.4643] [G loss: 1.9146]\n",
      "[Epoch 389/500] [Batch 100/469] [D loss: 0.4298] [G loss: 1.5299]\n",
      "[Epoch 389/500] [Batch 200/469] [D loss: 0.4422] [G loss: 1.3459]\n",
      "[Epoch 389/500] [Batch 300/469] [D loss: 0.5324] [G loss: 0.9837]\n",
      "[Epoch 389/500] [Batch 400/469] [D loss: 0.4416] [G loss: 1.5942]\n",
      "[Epoch 389/500] [FID score: 29.2475]\n",
      "[Epoch 390/500] [Batch 0/469] [D loss: 0.5023] [G loss: 1.0817]\n",
      "[Epoch 390/500] [Batch 100/469] [D loss: 0.4515] [G loss: 1.2515]\n",
      "[Epoch 390/500] [Batch 200/469] [D loss: 0.4160] [G loss: 1.4928]\n",
      "[Epoch 390/500] [Batch 300/469] [D loss: 0.3928] [G loss: 1.3945]\n",
      "[Epoch 390/500] [Batch 400/469] [D loss: 0.4261] [G loss: 1.1885]\n",
      "[Epoch 391/500] [Batch 0/469] [D loss: 0.4302] [G loss: 1.2422]\n",
      "[Epoch 391/500] [Batch 100/469] [D loss: 0.4416] [G loss: 1.7694]\n",
      "[Epoch 391/500] [Batch 200/469] [D loss: 0.4233] [G loss: 1.6941]\n",
      "[Epoch 391/500] [Batch 300/469] [D loss: 0.4479] [G loss: 1.4045]\n",
      "[Epoch 391/500] [Batch 400/469] [D loss: 0.4488] [G loss: 1.5852]\n",
      "[Epoch 392/500] [Batch 0/469] [D loss: 0.4173] [G loss: 1.2851]\n",
      "[Epoch 392/500] [Batch 100/469] [D loss: 0.4337] [G loss: 1.7806]\n",
      "[Epoch 392/500] [Batch 200/469] [D loss: 0.4697] [G loss: 1.2116]\n",
      "[Epoch 392/500] [Batch 300/469] [D loss: 0.4743] [G loss: 1.8837]\n",
      "[Epoch 392/500] [Batch 400/469] [D loss: 0.4526] [G loss: 1.2952]\n",
      "[Epoch 393/500] [Batch 0/469] [D loss: 0.4139] [G loss: 1.4314]\n",
      "[Epoch 393/500] [Batch 100/469] [D loss: 0.3974] [G loss: 1.8978]\n",
      "[Epoch 393/500] [Batch 200/469] [D loss: 0.5037] [G loss: 1.3077]\n",
      "[Epoch 393/500] [Batch 300/469] [D loss: 0.5131] [G loss: 1.8194]\n",
      "[Epoch 393/500] [Batch 400/469] [D loss: 0.4316] [G loss: 1.4540]\n",
      "[Epoch 394/500] [Batch 0/469] [D loss: 0.5223] [G loss: 1.2247]\n",
      "[Epoch 394/500] [Batch 100/469] [D loss: 0.4460] [G loss: 1.7769]\n",
      "[Epoch 394/500] [Batch 200/469] [D loss: 0.4220] [G loss: 2.1457]\n",
      "[Epoch 394/500] [Batch 300/469] [D loss: 0.3926] [G loss: 1.9632]\n",
      "[Epoch 394/500] [Batch 400/469] [D loss: 0.4324] [G loss: 1.4201]\n",
      "[Epoch 395/500] [Batch 0/469] [D loss: 0.4047] [G loss: 1.7239]\n",
      "[Epoch 395/500] [Batch 100/469] [D loss: 0.3907] [G loss: 1.3185]\n",
      "[Epoch 395/500] [Batch 200/469] [D loss: 0.4141] [G loss: 1.8751]\n",
      "[Epoch 395/500] [Batch 300/469] [D loss: 0.4571] [G loss: 1.4280]\n",
      "[Epoch 395/500] [Batch 400/469] [D loss: 0.4565] [G loss: 1.5652]\n",
      "[Epoch 396/500] [Batch 0/469] [D loss: 0.4905] [G loss: 1.9280]\n",
      "[Epoch 396/500] [Batch 100/469] [D loss: 0.4518] [G loss: 1.7236]\n",
      "[Epoch 396/500] [Batch 200/469] [D loss: 0.4417] [G loss: 2.1394]\n",
      "[Epoch 396/500] [Batch 300/469] [D loss: 0.4765] [G loss: 1.8998]\n",
      "[Epoch 396/500] [Batch 400/469] [D loss: 0.4092] [G loss: 1.9097]\n",
      "[Epoch 397/500] [Batch 0/469] [D loss: 0.5110] [G loss: 1.1402]\n",
      "[Epoch 397/500] [Batch 100/469] [D loss: 0.4312] [G loss: 2.2604]\n",
      "[Epoch 397/500] [Batch 200/469] [D loss: 0.3638] [G loss: 1.9293]\n",
      "[Epoch 397/500] [Batch 300/469] [D loss: 0.4001] [G loss: 1.3085]\n",
      "[Epoch 397/500] [Batch 400/469] [D loss: 0.4424] [G loss: 1.5096]\n",
      "[Epoch 398/500] [Batch 0/469] [D loss: 0.4083] [G loss: 1.4990]\n",
      "[Epoch 398/500] [Batch 100/469] [D loss: 0.4154] [G loss: 1.5832]\n",
      "[Epoch 398/500] [Batch 200/469] [D loss: 0.3907] [G loss: 1.5241]\n",
      "[Epoch 398/500] [Batch 300/469] [D loss: 0.4181] [G loss: 1.6580]\n",
      "[Epoch 398/500] [Batch 400/469] [D loss: 0.4273] [G loss: 1.9438]\n",
      "[Epoch 399/500] [Batch 0/469] [D loss: 0.3671] [G loss: 1.8371]\n",
      "[Epoch 399/500] [Batch 100/469] [D loss: 0.4432] [G loss: 1.4447]\n",
      "[Epoch 399/500] [Batch 200/469] [D loss: 0.4378] [G loss: 1.2127]\n",
      "[Epoch 399/500] [Batch 300/469] [D loss: 0.3705] [G loss: 1.7403]\n",
      "[Epoch 399/500] [Batch 400/469] [D loss: 0.4320] [G loss: 1.0601]\n",
      "[Epoch 399/500] [FID score: 28.3707]\n",
      "[Epoch 400/500] [Batch 0/469] [D loss: 0.3962] [G loss: 1.8288]\n",
      "[Epoch 400/500] [Batch 100/469] [D loss: 0.4629] [G loss: 1.9997]\n",
      "[Epoch 400/500] [Batch 200/469] [D loss: 0.5388] [G loss: 1.3002]\n",
      "[Epoch 400/500] [Batch 300/469] [D loss: 0.4463] [G loss: 1.9025]\n",
      "[Epoch 400/500] [Batch 400/469] [D loss: 0.4697] [G loss: 1.3656]\n",
      "[Epoch 401/500] [Batch 0/469] [D loss: 0.3811] [G loss: 1.4898]\n",
      "[Epoch 401/500] [Batch 100/469] [D loss: 0.5597] [G loss: 2.4009]\n",
      "[Epoch 401/500] [Batch 200/469] [D loss: 0.4202] [G loss: 1.2598]\n",
      "[Epoch 401/500] [Batch 300/469] [D loss: 0.4788] [G loss: 1.3460]\n",
      "[Epoch 401/500] [Batch 400/469] [D loss: 0.3934] [G loss: 1.5305]\n",
      "[Epoch 402/500] [Batch 0/469] [D loss: 0.4576] [G loss: 1.6514]\n",
      "[Epoch 402/500] [Batch 100/469] [D loss: 0.4053] [G loss: 1.8277]\n",
      "[Epoch 402/500] [Batch 200/469] [D loss: 0.4182] [G loss: 1.5785]\n",
      "[Epoch 402/500] [Batch 300/469] [D loss: 0.4051] [G loss: 1.6972]\n",
      "[Epoch 402/500] [Batch 400/469] [D loss: 0.4402] [G loss: 1.6281]\n",
      "[Epoch 403/500] [Batch 0/469] [D loss: 0.4316] [G loss: 1.7305]\n",
      "[Epoch 403/500] [Batch 100/469] [D loss: 0.3756] [G loss: 1.7337]\n",
      "[Epoch 403/500] [Batch 200/469] [D loss: 0.3716] [G loss: 1.7345]\n",
      "[Epoch 403/500] [Batch 300/469] [D loss: 0.4385] [G loss: 1.5046]\n",
      "[Epoch 403/500] [Batch 400/469] [D loss: 0.4954] [G loss: 1.3080]\n",
      "[Epoch 404/500] [Batch 0/469] [D loss: 0.4135] [G loss: 1.4972]\n",
      "[Epoch 404/500] [Batch 100/469] [D loss: 0.4507] [G loss: 1.2234]\n",
      "[Epoch 404/500] [Batch 200/469] [D loss: 0.4825] [G loss: 0.9715]\n",
      "[Epoch 404/500] [Batch 300/469] [D loss: 0.4611] [G loss: 1.2844]\n",
      "[Epoch 404/500] [Batch 400/469] [D loss: 0.4794] [G loss: 1.0781]\n",
      "[Epoch 405/500] [Batch 0/469] [D loss: 0.4342] [G loss: 1.8844]\n",
      "[Epoch 405/500] [Batch 100/469] [D loss: 0.4679] [G loss: 1.7430]\n",
      "[Epoch 405/500] [Batch 200/469] [D loss: 0.4113] [G loss: 1.2809]\n",
      "[Epoch 405/500] [Batch 300/469] [D loss: 0.4950] [G loss: 1.2666]\n",
      "[Epoch 405/500] [Batch 400/469] [D loss: 0.5316] [G loss: 1.1261]\n",
      "[Epoch 406/500] [Batch 0/469] [D loss: 0.4593] [G loss: 1.9649]\n",
      "[Epoch 406/500] [Batch 100/469] [D loss: 0.4049] [G loss: 1.8362]\n",
      "[Epoch 406/500] [Batch 200/469] [D loss: 0.4596] [G loss: 1.5870]\n",
      "[Epoch 406/500] [Batch 300/469] [D loss: 0.4359] [G loss: 2.1515]\n",
      "[Epoch 406/500] [Batch 400/469] [D loss: 0.4042] [G loss: 1.2908]\n",
      "[Epoch 407/500] [Batch 0/469] [D loss: 0.5034] [G loss: 1.0028]\n",
      "[Epoch 407/500] [Batch 100/469] [D loss: 0.4275] [G loss: 1.3861]\n",
      "[Epoch 407/500] [Batch 200/469] [D loss: 0.4256] [G loss: 2.1031]\n",
      "[Epoch 407/500] [Batch 300/469] [D loss: 0.4770] [G loss: 2.1885]\n",
      "[Epoch 407/500] [Batch 400/469] [D loss: 0.6081] [G loss: 2.6821]\n",
      "[Epoch 408/500] [Batch 0/469] [D loss: 0.4435] [G loss: 1.1666]\n",
      "[Epoch 408/500] [Batch 100/469] [D loss: 0.3977] [G loss: 1.8515]\n",
      "[Epoch 408/500] [Batch 200/469] [D loss: 0.4532] [G loss: 1.6566]\n",
      "[Epoch 408/500] [Batch 300/469] [D loss: 0.3780] [G loss: 1.6617]\n",
      "[Epoch 408/500] [Batch 400/469] [D loss: 0.4042] [G loss: 1.9818]\n",
      "[Epoch 409/500] [Batch 0/469] [D loss: 0.4801] [G loss: 1.5473]\n",
      "[Epoch 409/500] [Batch 100/469] [D loss: 0.4480] [G loss: 1.1624]\n",
      "[Epoch 409/500] [Batch 200/469] [D loss: 0.4761] [G loss: 1.3813]\n",
      "[Epoch 409/500] [Batch 300/469] [D loss: 0.4124] [G loss: 1.8995]\n",
      "[Epoch 409/500] [Batch 400/469] [D loss: 0.4236] [G loss: 1.7709]\n",
      "[Epoch 409/500] [FID score: 29.8004]\n",
      "[Epoch 410/500] [Batch 0/469] [D loss: 0.4275] [G loss: 1.7503]\n",
      "[Epoch 410/500] [Batch 100/469] [D loss: 0.4078] [G loss: 1.6364]\n",
      "[Epoch 410/500] [Batch 200/469] [D loss: 0.3749] [G loss: 2.0476]\n",
      "[Epoch 410/500] [Batch 300/469] [D loss: 0.5160] [G loss: 1.1512]\n",
      "[Epoch 410/500] [Batch 400/469] [D loss: 0.3640] [G loss: 1.9663]\n",
      "[Epoch 411/500] [Batch 0/469] [D loss: 0.4520] [G loss: 1.0267]\n",
      "[Epoch 411/500] [Batch 100/469] [D loss: 0.4184] [G loss: 1.3015]\n",
      "[Epoch 411/500] [Batch 200/469] [D loss: 0.4340] [G loss: 1.8854]\n",
      "[Epoch 411/500] [Batch 300/469] [D loss: 0.4629] [G loss: 2.1432]\n",
      "[Epoch 411/500] [Batch 400/469] [D loss: 0.4446] [G loss: 1.3072]\n",
      "[Epoch 412/500] [Batch 0/469] [D loss: 0.3995] [G loss: 2.1807]\n",
      "[Epoch 412/500] [Batch 100/469] [D loss: 0.4332] [G loss: 1.9244]\n",
      "[Epoch 412/500] [Batch 200/469] [D loss: 0.3660] [G loss: 2.0591]\n",
      "[Epoch 412/500] [Batch 300/469] [D loss: 0.4135] [G loss: 1.8010]\n",
      "[Epoch 412/500] [Batch 400/469] [D loss: 0.4312] [G loss: 2.0108]\n",
      "[Epoch 413/500] [Batch 0/469] [D loss: 0.4083] [G loss: 1.9057]\n",
      "[Epoch 413/500] [Batch 100/469] [D loss: 0.4481] [G loss: 1.3447]\n",
      "[Epoch 413/500] [Batch 200/469] [D loss: 0.4214] [G loss: 1.6728]\n",
      "[Epoch 413/500] [Batch 300/469] [D loss: 0.3818] [G loss: 1.9913]\n",
      "[Epoch 413/500] [Batch 400/469] [D loss: 0.3961] [G loss: 1.5552]\n",
      "[Epoch 414/500] [Batch 0/469] [D loss: 0.3820] [G loss: 1.5709]\n",
      "[Epoch 414/500] [Batch 100/469] [D loss: 0.3866] [G loss: 1.6166]\n",
      "[Epoch 414/500] [Batch 200/469] [D loss: 0.4315] [G loss: 1.3832]\n",
      "[Epoch 414/500] [Batch 300/469] [D loss: 0.5185] [G loss: 2.4412]\n",
      "[Epoch 414/500] [Batch 400/469] [D loss: 0.4877] [G loss: 1.9255]\n",
      "[Epoch 415/500] [Batch 0/469] [D loss: 0.3891] [G loss: 1.4923]\n",
      "[Epoch 415/500] [Batch 100/469] [D loss: 0.4617] [G loss: 1.8059]\n",
      "[Epoch 415/500] [Batch 200/469] [D loss: 0.3926] [G loss: 1.3237]\n",
      "[Epoch 415/500] [Batch 300/469] [D loss: 0.3936] [G loss: 1.5107]\n",
      "[Epoch 415/500] [Batch 400/469] [D loss: 0.4062] [G loss: 1.5555]\n",
      "[Epoch 416/500] [Batch 0/469] [D loss: 0.3651] [G loss: 1.5768]\n",
      "[Epoch 416/500] [Batch 100/469] [D loss: 0.4217] [G loss: 1.5838]\n",
      "[Epoch 416/500] [Batch 200/469] [D loss: 0.4888] [G loss: 2.1625]\n",
      "[Epoch 416/500] [Batch 300/469] [D loss: 0.4705] [G loss: 1.5493]\n",
      "[Epoch 416/500] [Batch 400/469] [D loss: 0.4451] [G loss: 1.5997]\n",
      "[Epoch 417/500] [Batch 0/469] [D loss: 0.4396] [G loss: 1.7333]\n",
      "[Epoch 417/500] [Batch 100/469] [D loss: 0.4205] [G loss: 2.0502]\n",
      "[Epoch 417/500] [Batch 200/469] [D loss: 0.4231] [G loss: 1.4881]\n",
      "[Epoch 417/500] [Batch 300/469] [D loss: 0.4274] [G loss: 1.5455]\n",
      "[Epoch 417/500] [Batch 400/469] [D loss: 0.3776] [G loss: 1.7620]\n",
      "[Epoch 418/500] [Batch 0/469] [D loss: 0.4405] [G loss: 2.0612]\n",
      "[Epoch 418/500] [Batch 100/469] [D loss: 0.4535] [G loss: 1.3516]\n",
      "[Epoch 418/500] [Batch 200/469] [D loss: 0.4617] [G loss: 1.3758]\n",
      "[Epoch 418/500] [Batch 300/469] [D loss: 0.4176] [G loss: 1.3968]\n",
      "[Epoch 418/500] [Batch 400/469] [D loss: 0.3801] [G loss: 1.8069]\n",
      "[Epoch 419/500] [Batch 0/469] [D loss: 0.4559] [G loss: 1.7797]\n",
      "[Epoch 419/500] [Batch 100/469] [D loss: 0.3957] [G loss: 1.8761]\n",
      "[Epoch 419/500] [Batch 200/469] [D loss: 0.4875] [G loss: 2.3467]\n",
      "[Epoch 419/500] [Batch 300/469] [D loss: 0.3897] [G loss: 1.4862]\n",
      "[Epoch 419/500] [Batch 400/469] [D loss: 0.3967] [G loss: 1.7303]\n",
      "[Epoch 419/500] [FID score: 28.7109]\n",
      "[Epoch 420/500] [Batch 0/469] [D loss: 0.4105] [G loss: 1.4673]\n",
      "[Epoch 420/500] [Batch 100/469] [D loss: 0.4623] [G loss: 1.6035]\n",
      "[Epoch 420/500] [Batch 200/469] [D loss: 0.4324] [G loss: 1.6366]\n",
      "[Epoch 420/500] [Batch 300/469] [D loss: 0.4418] [G loss: 1.4218]\n",
      "[Epoch 420/500] [Batch 400/469] [D loss: 0.5230] [G loss: 1.0661]\n",
      "[Epoch 421/500] [Batch 0/469] [D loss: 0.4457] [G loss: 1.4614]\n",
      "[Epoch 421/500] [Batch 100/469] [D loss: 0.3815] [G loss: 1.7607]\n",
      "[Epoch 421/500] [Batch 200/469] [D loss: 0.3769] [G loss: 1.3459]\n",
      "[Epoch 421/500] [Batch 300/469] [D loss: 0.4267] [G loss: 1.7159]\n",
      "[Epoch 421/500] [Batch 400/469] [D loss: 0.4172] [G loss: 1.5325]\n",
      "[Epoch 422/500] [Batch 0/469] [D loss: 0.4103] [G loss: 1.6067]\n",
      "[Epoch 422/500] [Batch 100/469] [D loss: 0.3755] [G loss: 1.7542]\n",
      "[Epoch 422/500] [Batch 200/469] [D loss: 0.4097] [G loss: 1.4540]\n",
      "[Epoch 422/500] [Batch 300/469] [D loss: 0.3415] [G loss: 1.6709]\n",
      "[Epoch 422/500] [Batch 400/469] [D loss: 0.4228] [G loss: 1.9352]\n",
      "[Epoch 423/500] [Batch 0/469] [D loss: 0.4197] [G loss: 1.6501]\n",
      "[Epoch 423/500] [Batch 100/469] [D loss: 0.3685] [G loss: 1.5122]\n",
      "[Epoch 423/500] [Batch 200/469] [D loss: 0.4235] [G loss: 1.6024]\n",
      "[Epoch 423/500] [Batch 300/469] [D loss: 0.4210] [G loss: 1.5513]\n",
      "[Epoch 423/500] [Batch 400/469] [D loss: 0.4134] [G loss: 1.5151]\n",
      "[Epoch 424/500] [Batch 0/469] [D loss: 0.4310] [G loss: 1.4737]\n",
      "[Epoch 424/500] [Batch 100/469] [D loss: 0.4213] [G loss: 1.6332]\n",
      "[Epoch 424/500] [Batch 200/469] [D loss: 0.5050] [G loss: 0.9724]\n",
      "[Epoch 424/500] [Batch 300/469] [D loss: 0.4452] [G loss: 1.6898]\n",
      "[Epoch 424/500] [Batch 400/469] [D loss: 0.5165] [G loss: 2.5786]\n",
      "[Epoch 425/500] [Batch 0/469] [D loss: 0.4422] [G loss: 1.9463]\n",
      "[Epoch 425/500] [Batch 100/469] [D loss: 0.3991] [G loss: 1.6248]\n",
      "[Epoch 425/500] [Batch 200/469] [D loss: 0.4051] [G loss: 2.2023]\n",
      "[Epoch 425/500] [Batch 300/469] [D loss: 0.3603] [G loss: 1.6864]\n",
      "[Epoch 425/500] [Batch 400/469] [D loss: 0.3739] [G loss: 1.5036]\n",
      "[Epoch 426/500] [Batch 0/469] [D loss: 0.5172] [G loss: 1.1153]\n",
      "[Epoch 426/500] [Batch 100/469] [D loss: 0.5265] [G loss: 0.9153]\n",
      "[Epoch 426/500] [Batch 200/469] [D loss: 0.4271] [G loss: 2.1270]\n",
      "[Epoch 426/500] [Batch 300/469] [D loss: 0.3886] [G loss: 1.6151]\n",
      "[Epoch 426/500] [Batch 400/469] [D loss: 0.5381] [G loss: 1.0965]\n",
      "[Epoch 427/500] [Batch 0/469] [D loss: 0.4303] [G loss: 1.9153]\n",
      "[Epoch 427/500] [Batch 100/469] [D loss: 0.4375] [G loss: 2.3005]\n",
      "[Epoch 427/500] [Batch 200/469] [D loss: 0.5330] [G loss: 2.3536]\n",
      "[Epoch 427/500] [Batch 300/469] [D loss: 0.3796] [G loss: 1.9686]\n",
      "[Epoch 427/500] [Batch 400/469] [D loss: 0.4431] [G loss: 1.6235]\n",
      "[Epoch 428/500] [Batch 0/469] [D loss: 0.3611] [G loss: 1.7205]\n",
      "[Epoch 428/500] [Batch 100/469] [D loss: 0.4652] [G loss: 1.1856]\n",
      "[Epoch 428/500] [Batch 200/469] [D loss: 0.4011] [G loss: 1.5712]\n",
      "[Epoch 428/500] [Batch 300/469] [D loss: 0.4901] [G loss: 1.8411]\n",
      "[Epoch 428/500] [Batch 400/469] [D loss: 0.4347] [G loss: 1.9111]\n",
      "[Epoch 429/500] [Batch 0/469] [D loss: 0.4736] [G loss: 1.2459]\n",
      "[Epoch 429/500] [Batch 100/469] [D loss: 0.4362] [G loss: 1.2795]\n",
      "[Epoch 429/500] [Batch 200/469] [D loss: 0.4736] [G loss: 1.4213]\n",
      "[Epoch 429/500] [Batch 300/469] [D loss: 0.4255] [G loss: 1.6793]\n",
      "[Epoch 429/500] [Batch 400/469] [D loss: 0.3811] [G loss: 1.6512]\n",
      "[Epoch 429/500] [FID score: 29.1396]\n",
      "[Epoch 430/500] [Batch 0/469] [D loss: 0.3660] [G loss: 1.8028]\n",
      "[Epoch 430/500] [Batch 100/469] [D loss: 0.4621] [G loss: 1.2637]\n",
      "[Epoch 430/500] [Batch 200/469] [D loss: 0.4330] [G loss: 1.4032]\n",
      "[Epoch 430/500] [Batch 300/469] [D loss: 0.4060] [G loss: 1.7023]\n",
      "[Epoch 430/500] [Batch 400/469] [D loss: 0.3708] [G loss: 1.7007]\n",
      "[Epoch 431/500] [Batch 0/469] [D loss: 0.3712] [G loss: 1.4105]\n",
      "[Epoch 431/500] [Batch 100/469] [D loss: 0.4188] [G loss: 1.4791]\n",
      "[Epoch 431/500] [Batch 200/469] [D loss: 0.3996] [G loss: 2.0353]\n",
      "[Epoch 431/500] [Batch 300/469] [D loss: 0.4307] [G loss: 1.7445]\n",
      "[Epoch 431/500] [Batch 400/469] [D loss: 0.5224] [G loss: 2.3618]\n",
      "[Epoch 432/500] [Batch 0/469] [D loss: 0.5321] [G loss: 1.0928]\n",
      "[Epoch 432/500] [Batch 100/469] [D loss: 0.4140] [G loss: 1.5263]\n",
      "[Epoch 432/500] [Batch 200/469] [D loss: 0.3906] [G loss: 1.5671]\n",
      "[Epoch 432/500] [Batch 300/469] [D loss: 0.3960] [G loss: 2.2472]\n",
      "[Epoch 432/500] [Batch 400/469] [D loss: 0.3801] [G loss: 1.6590]\n",
      "[Epoch 433/500] [Batch 0/469] [D loss: 0.5006] [G loss: 1.0494]\n",
      "[Epoch 433/500] [Batch 100/469] [D loss: 0.4225] [G loss: 1.4813]\n",
      "[Epoch 433/500] [Batch 200/469] [D loss: 0.4518] [G loss: 2.0168]\n",
      "[Epoch 433/500] [Batch 300/469] [D loss: 0.3897] [G loss: 1.4821]\n",
      "[Epoch 433/500] [Batch 400/469] [D loss: 0.4010] [G loss: 1.6707]\n",
      "[Epoch 434/500] [Batch 0/469] [D loss: 0.4301] [G loss: 1.3560]\n",
      "[Epoch 434/500] [Batch 100/469] [D loss: 0.4939] [G loss: 1.1417]\n",
      "[Epoch 434/500] [Batch 200/469] [D loss: 0.3985] [G loss: 1.6690]\n"
     ]
    }
   ],
   "source": [
    "# 主函数\n",
    "if __name__ == \"__main__\":\n",
    "    train_gan(epochs=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
